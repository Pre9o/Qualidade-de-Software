{"Id": 70810857, "PostTypeId": 1, "Title": "split geometric progression efficiently in Python (Pythonic way)", "Body": "<p>I am trying to achieve a calculation involving geometric progression (split). Is there any effective/efficient way of doing it. The data set has millions of rows.\nI need the column &quot;Traded_quantity&quot;</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th>Marker</th>\n<th>Action</th>\n<th>Traded_quantity</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2019-11-05</td>\n<td>09:25</td>\n<td>0</td>\n<td></td>\n<td>0</td>\n</tr>\n<tr>\n<td></td>\n<td>09:35</td>\n<td>2</td>\n<td>BUY</td>\n<td>3</td>\n</tr>\n<tr>\n<td></td>\n<td>09:45</td>\n<td>0</td>\n<td></td>\n<td>0</td>\n</tr>\n<tr>\n<td></td>\n<td>09:55</td>\n<td>1</td>\n<td>BUY</td>\n<td>4</td>\n</tr>\n<tr>\n<td></td>\n<td>10:05</td>\n<td>0</td>\n<td></td>\n<td>0</td>\n</tr>\n<tr>\n<td></td>\n<td>10:15</td>\n<td>3</td>\n<td>BUY</td>\n<td>56</td>\n</tr>\n<tr>\n<td></td>\n<td>10:24</td>\n<td>6</td>\n<td>BUY</td>\n<td>8128</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>turtle = 2\n(User defined)</p>\n<p>base_quantity = 1\n(User defined)</p>\n<pre><code>    def turtle_split(row):\n        if row['Action'] == 'BUY':\n            return base_quantity * (turtle ** row['Marker'] - 1) // (turtle - 1)\n        else:\n            return 0\n    df['Traded_quantity'] = df.apply(turtle_split, axis=1).round(0).astype(int)\n</code></pre>\n<h2>Calculation</h2>\n<p>For 0th Row, Traded_quantity should be zero (because the Marker is zero)</p>\n<p>For 1st Row, Traded_quantity should be (1x1) + (1x2) = 3 (Marker 2 will be split into 1 and 1, First 1 will be multiplied with the base_quantity&gt;&gt;1x1, Second 1 will be multiplied with the result from first 1 times turtle&gt;&gt;1x2), then we make a sum of these two numbers)</p>\n<p>For 2nd Row, Traded_quantity should be zero (because the Marker is zero)</p>\n<p>For 3rd Row, Traded_quantity should be (2x2) = 4(Marker 1 will be multiplied with the last split from row 1 time turtle i.e 2x2)</p>\n<p>For 4th Row, Traded_quantity should be zero(because the Marker is zero)</p>\n<p>For 5th Row, Traded_quantity should be (4x2)+(4x2x2)+(4x2x2x2) = 56(Marker 3 will be split into 1,1 and 1, First 1 will be multiplied with the last split from row3 times turtle &gt;&gt;4x2, Second 1 will be multiplied with the result from first 1 with turtle&gt;&gt;8x2), third 1 will be multiplied with the result from second 1 with turtle&gt;&gt;16x2) then we make a sum of these three numbers)</p>\n<p>For 6th Row, Traded_quantity should be (32x2)+(32x2x2)+(32x2x2x2)+(32x2x2x2x2)+(32x2x2x2x2x2) = 8128</p>\n<p>Whenever there will be a BUY, the traded quantity will be calculated using the last batch from Traded_quantity times turtle.</p>\n<p>Turns out the code is generating correct Traded_quantity when there is no zero in Marker. Once there is a gap with a couple of zeros geometric progression will not help, I would require the previous fig(from Cache) to recalculate Traded_q. tried with lru_cache for recursion, didn't work.</p>\n", "AcceptedAnswerId": 70811799, "AcceptedAnswer": "<p>This should work</p>\n<pre><code>def turtle_split(row):\n        global base_quantity\n        if row['Action'] == 'BUY':\n            summation = base_quantity * (turtle ** row['Marker'] - 1) // (turtle - 1)\n            base_quantity = base_quantity * (turtle ** (row['Marker'] - 1))*turtle\n            return summation\n        else:\n            return 0\n</code></pre>\n"}
{"Id": 70552775, "PostTypeId": 1, "Title": "Multiprocess inherently shared memory in no longer working on python 3.10 (coming from 3.6)", "Body": "<p>I understand there are a variety of techniques for sharing memory and data structures between processes in python. This question is specifically about this inherently shared memory in python scripts that existed in python 3.6 but seems to no longer exist in 3.10.  <strong>Does anyone know why and if it's possible to bring this back in 3.10?  Or what this change that I'm observing is?</strong>  I've upgraded my Mac to Monterey and it no longer supports python 3.6, so I'm forced to upgrade to either 3.9 or 3.10+.</p>\n<p>Note:  I tend to develop on Mac and run production on Ubuntu.  Not sure if that factors in here.  Historically with 3.6, everything behaved the same regardless of OS.</p>\n<p>Make a simple project with the following python files</p>\n<p><strong>myLibrary.py</strong></p>\n<pre><code>MyDict = {}\n</code></pre>\n<p><strong>test.py</strong></p>\n<pre><code>import threading\nimport time\nimport multiprocessing\n\nimport myLibrary\n\n\ndef InitMyDict():\n    myLibrary.MyDict = {'woot': 1, 'sauce': 2}\n    print('initialized myLibrary.MyDict to ', myLibrary.MyDict)\n\n\ndef MainLoop():\n    numOfSubProcessesToStart = 3\n    for i in range(numOfSubProcessesToStart):\n        t = threading.Thread(\n            target=CoolFeature(),\n            args=())\n        t.start()\n\n    while True:\n        time.sleep(1)\n\n\ndef CoolFeature():\n    MyProcess = multiprocessing.Process(\n        target=SubProcessFunction,\n        args=())\n    MyProcess.start()\n\n\ndef SubProcessFunction():\n    print('SubProcessFunction: ', myLibrary.MyDict)\n\n\nif __name__ == '__main__':\n    InitMyDict()\n    MainLoop()\n</code></pre>\n<p>When I run this on 3.6 it has a significantly different behavior than 3.10.  I do understand that a subprocess cannot modify the memory of the main process, but it is still super convenient to access the main process' data structure that was previously set up as opposed to moving every little tiny thing into shared memory just to read a simple dictionary/int/string/etc.</p>\n<p><strong>Python 3.10 output:</strong></p>\n<pre><code>python3.10 test.py \ninitialized myLibrary.MyDict to  {'woot': 1, 'sauce': 2}\nSubProcessFunction:  {}\nSubProcessFunction:  {}\nSubProcessFunction:  {}\n</code></pre>\n<p><strong>Python 3.6 output:</strong></p>\n<pre><code>python3.6 test.py \ninitialized myLibrary.MyDict to  {'woot': 1, 'sauce': 2}\nSubProcessFunction:  {'woot': 1, 'sauce': 2}\nSubProcessFunction:  {'woot': 1, 'sauce': 2}\nSubProcessFunction:  {'woot': 1, 'sauce': 2}\n</code></pre>\n<p>Observation:</p>\n<p>Notice that in 3.6, the subprocess can view the value that was set from the main process.  But in 3.10, the subprocess sees an empty dictionary.</p>\n", "AcceptedAnswerId": 70552892, "AcceptedAnswer": "<p>In short, since 3.8, CPython uses the <em>spawn</em> start method on MacOs. Before it used the <em>fork</em> method.</p>\n<p>On UNIX platforms, the <em>fork</em> start method is used which means that every new <code>multiprocessing</code> process is an exact copy of the parent at the time of the fork.</p>\n<p>The <em>spawn</em> method means that it starts a new Python interpreter for each new <code>multiprocessing</code> process. According to the documentation:</p>\n<blockquote>\n<p>The child process will only inherit those resources necessary to run the process object\u2019s <code>run()</code> method.</p>\n</blockquote>\n<p>It will <em>import</em> your program into this new interpreter, so starting processes et cetera sould only be done from within the <code>if __name__ == '__main__':</code>-block!</p>\n<p>This means you cannot count on variables from the parent process being available in the children, <em>unless they are module level constants which would be imported</em>.</p>\n<p>So the change is significant.</p>\n<p><strong>What can be done?</strong></p>\n<p>If the required information <em>could</em> be a module-level constant, that would solve the problem in the simplest way.</p>\n<p>If that is not possible (e.g. because the data needs to be generated at runtime) you could have the parent write the information to be shared to a file. E.g. in JSON format and before it starts other processes. Then the children could simply read this. That is probably the next simplest solution.</p>\n<p>Using a <code>multiprocessing.Manager</code> would allow you to share a <code>dict</code> between processes. There is however a certain amount of overhead associated with this.</p>\n<p>Or you could try calling <code>multiprocessing.set_start_method(&quot;fork&quot;)</code> before creating processes or pools and see if it doesn't crash in your case. That would revert to the pre-3.8 method on MacOs. But as documented <a href=\"https://bugs.python.org/issue33725\" rel=\"nofollow noreferrer\">in this bug</a>, there are real problems with using the <code>fork</code> method on MacOs.\nReading the issue indicates that <code>fork</code> <strong>might</strong> be OK <em>as long as you don't use threads</em>.</p>\n"}
{"Id": 70596809, "PostTypeId": 1, "Title": "Can a class attribute shadow a built-in in Python?", "Body": "<p>If have some code like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Foo():\n   def open(self, bar):\n       # Doing some fancy stuff here, i.e. opening &quot;bar&quot;\n       pass\n</code></pre>\n<p>When I run <a href=\"https://flake8.pycqa.org/\" rel=\"noreferrer\"><code>flake8</code></a> with the <a href=\"https://pypi.org/project/flake8-builtins/\" rel=\"noreferrer\">flake8-builtins</a> plug-in I get the error</p>\n<pre><code>A003 class attribute &quot;open&quot; is shadowing a python builtin\n</code></pre>\n<p>I don't understand how the method could possibly shadow the built-in<code> open</code>-function, because the method can only be called using an instance (i.e. <code>self.open(&quot;&quot;)</code> or <code>someFoo.open(&quot;&quot;)</code>). Is there some other way code expecting to call the built-in ends up calling the method? Or is this a false positive of the <code>flake8-builtins</code> plug-in?</p>\n", "AcceptedAnswerId": 70597023, "AcceptedAnswer": "<p>Not really a practical case, but your code would fail if you wanted to use the built-it functions on the class level after your shadowed function has been initialized:</p>\n<pre><code>class Foo:\n    def open(self, bar):\n        pass\n\n    with open('myfile.txt'):\n        print('did I get here?')\n\n&gt;&gt;&gt; TypeError: open() missing 1 required positional argument: 'bar'\n</code></pre>\n<p>The same would also be true with other built-in functions, such as <code>print</code></p>\n<pre><code>class Foo:\n    def print(self, bar):\n        pass\n\n    print('did I get here?')\n\n&gt;&gt;&gt; TypeError: print() missing 1 required positional argument: 'bar'\n</code></pre>\n"}
{"Id": 70587271, "PostTypeId": 1, "Title": "Is there a Pythonic way of filtering substrings of strings in a list?", "Body": "<p>I have a list with strings as below.</p>\n<pre class=\"lang-py prettyprint-override\"><code>candidates = [&quot;Hello&quot;, &quot;World&quot;, &quot;HelloWorld&quot;, &quot;Foo&quot;, &quot;bar&quot;, &quot;ar&quot;]\n</code></pre>\n<p>And I want the list to be filtered as <code>[&quot;HelloWorld&quot;, &quot;Foo&quot;, &quot;Bar&quot;]</code>, because others are substrings. I can do it like this, but don't think it's fast or elegant.</p>\n<pre class=\"lang-py prettyprint-override\"><code>def filter_not_substring(candidates):\n    survive = []\n    for a in candidates:\n        for b in candidates:\n            if a == b:\n                continue\n            if a in b:\n                break\n        else:\n            survive.append(a)\n    return survive\n</code></pre>\n<p>Is there any fast way to do it?</p>\n", "AcceptedAnswerId": 70587308, "AcceptedAnswer": "<p>How about:</p>\n<pre><code>candidates = [&quot;Hello&quot;, &quot;World&quot;, &quot;HelloWorld&quot;, &quot;Foo&quot;, &quot;bar&quot;, &quot;ar&quot;]\nresult = [c for c in candidates if not any(c in o and len(o) &gt; len(c) for o in candidates)]\nprint(result)\n</code></pre>\n<p>Counter to what was suggested in the comments:</p>\n<pre><code>from timeit import timeit\n\n\ndef filter_not_substring(candidates):\n    survive = []\n    for a in candidates:\n        for b in candidates:\n            if a == b:\n                continue\n            if a in b:\n                break\n        else:\n            survive.append(a)\n    return survive\n\n\ndef filter_not_substring2a(candidates):\n    return [c for c in candidates if not any(len(o) &gt; len(c) and c in o for o in candidates)]\n\n\ndef filter_not_substring2b(candidates):\n    return [c for c in candidates if not any(c in o and len(o) &gt; len(c) for o in candidates)]\n\n\nxs = [&quot;Hello&quot;, &quot;World&quot;, &quot;HelloWorld&quot;, &quot;Foo&quot;, &quot;bar&quot;, &quot;ar&quot;, &quot;bar&quot;]\nprint(filter_not_substring(xs), filter_not_substring2a(xs), filter_not_substring2b(xs))\nprint(timeit(lambda: filter_not_substring(xs)))\nprint(timeit(lambda: filter_not_substring2a(xs)))\nprint(timeit(lambda: filter_not_substring2b(xs)))\n</code></pre>\n<p>Result:</p>\n<pre class=\"lang-none prettyprint-override\"><code>['HelloWorld', 'Foo', 'bar', 'bar'] ['HelloWorld', 'Foo', 'bar', 'bar'] ['HelloWorld', 'Foo', 'bar', 'bar']\n1.5163685\n4.6516653\n3.8334089999999996\n</code></pre>\n<p>So, OP's solution is substantially faster, but <code>filter_not_substring2b</code> is still about 20% faster than <code>2a</code>. So, putting the <code>len</code> comparison first doesn't save time.</p>\n<p>For any production scenario, OP's function is probably optimal - a way to speed it up might be to bring the whole problem into C, but I doubt that would show great gains, since the logic is pretty straightforward already and I'd expect Python to do a fairly good job of it as well.</p>\n<p>User @ming noted that OP's solution can be improved a bit:</p>\n<pre><code>def filter_not_substring_b(candidates):\n    survive = []\n    for a in candidates:\n        for b in candidates:\n            if a in b and a != b:\n                break\n        else:\n            survive.append(a)\n    return survive\n</code></pre>\n<p>This version of the function is somewhat faster, for me about 10-15%</p>\n<p>Finally, note that this is only <em>just</em> faster than <code>2b</code>, even though it is very similar to the optimised solution by @ming, but almost 3x slower than their solution. It's unclear to me why that would be - if anyone has fairly certain thoughts on that, please share in the comments:</p>\n<pre><code>def filter_not_substring_c(candidates):\n    return [a for a in candidates if all(a not in b or a == b for b in candidates)]\n</code></pre>\n"}
{"Id": 70923969, "PostTypeId": 1, "Title": "how to remove the \"User-Agent\" header when send request in python", "Body": "<p>I'm using <a href=\"https://docs.python-requests.org/en/latest/\" rel=\"noreferrer\">python requests</a> library, I need send a request without a user-agent header.\nI found <a href=\"https://stackoverflow.com/questions/32954366/python3-urllib2-need-to-remove-the-user-agent-header-completely\">this question</a>, but it's for Urllib2.</p>\n<p>I'm trying to simulate an Android app which does this when calling a private API.</p>\n<p>I try to set <code>User-Agent</code> to <code>None</code> as in the following code, but it doesn't work. It still sends <code>User-Agent: python-requests/2.27.1</code>.</p>\n<p>Is there any way?</p>\n<pre><code>headers = requests.utils.default_headers()\nheaders['User-Agent'] = None\nrequests.post(url, *args, headers=headers, **kwargs)\n</code></pre>\n", "AcceptedAnswerId": 70924222, "AcceptedAnswer": "<p>The <a href=\"https://docs.python-requests.org/en/latest/\" rel=\"noreferrer\">requests</a> library is <a href=\"https://stackoverflow.com/a/54698280/8153147\">built on top</a> of the <a href=\"https://urllib3.readthedocs.io/en/stable/\" rel=\"noreferrer\">urllib3</a> library.  So, when you pass <code>None</code> <code>User-Agent</code> header to the requests's <code>post</code> method, the <code>urllib3</code> set their own default <code>User-Agent</code></p>\n<pre><code>import requests\n\nr = requests.post(&quot;https://httpbin.org/post&quot;, headers={\n    &quot;User-Agent&quot;: None,\n})\n\nprint(r.json()[&quot;headers&quot;][&quot;User-Agent&quot;])\n</code></pre>\n<p>Output</p>\n<pre><code>python-urllib3/1.26.7\n</code></pre>\n<p>Here the urllib3 source of <code>connection.py</code></p>\n<pre><code>class HTTPConnection(_HTTPConnection, object):\n    ...\n\n    def request(self, method, url, body=None, headers=None):\n        if headers is None:\n            headers = {}\n        else:\n            # Avoid modifying the headers passed into .request()\n            headers = headers.copy()\n        if &quot;user-agent&quot; not in (six.ensure_str(k.lower()) for k in headers):\n            headers[&quot;User-Agent&quot;] = _get_default_user_agent()\n        super(HTTPConnection, self).request(method, url, body=body, headers=headers) \n</code></pre>\n<p>So, you can monkey patch it to disable default <code>User-Agent</code> header</p>\n<pre><code>import requests\nfrom urllib3 import connection\n\n\ndef request(self, method, url, body=None, headers=None):\n    if headers is None:\n        headers = {}\n    else:\n        # Avoid modifying the headers passed into .request()\n        headers = headers.copy()\n    super(connection.HTTPConnection, self).request(method, url, body=body, headers=headers)\n\nconnection.HTTPConnection.request = request\n\n\nr = requests.post(&quot;https://httpbin.org/post&quot;, headers={\n    &quot;User-Agent&quot;: None,\n})\n\nprint(r.json()[&quot;headers&quot;])\n</code></pre>\n<p>Output</p>\n<pre><code>{\n'Accept': '*/*', \n'Accept-Encoding': 'gzip, deflate', \n'Content-Length': '0', \n'Host': 'httpbin.org', \n'X-Amzn-Trace-Id': 'Root=1-61f7b53b-26c4c8f6498c86a24ff05940'\n}\n</code></pre>\n<p>Also, consider to provide browser-like <code>User-Agent</code> like this <code>Mozilla/5.0 (Macintosh; Intel Mac OS X 12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36</code>. Maybe it solves your task with less effort</p>\n"}
{"Id": 70587544, "PostTypeId": 1, "Title": "\"brew install python\" installs 3.9. Why not 3.10?", "Body": "<p>My understanding is that &quot;brew install python&quot; installs the latest version of python. Why isn't it pulling 3.10? 3.10 is marked as a stable release.</p>\n<p>I can install 3.10 with &quot;brew install python@3.10 just fine and can update my PATH so that python and pip point to the right versions. But I am curious why &quot;brew install python&quot; its not installing 3.10.</p>\n<p>My other understanding is that 3.10 is directly compatible with the M1 chips so that is why I want 3.10.</p>\n<p>Please let me know if I am mistaken.</p>\n", "AcceptedAnswerId": 70589077, "AcceptedAnswer": "<p>As Henry Schreiner have specified now Python 3.10 is the new default in Brew. Thx for pointing it</p>\n<p>--- Obsolete ---\nThe &quot;python3&quot; formula is still 3.9 in the brew system\ncheck the doc here:\n<a href=\"https://formulae.brew.sh/formula/python@3.9#default\" rel=\"nofollow noreferrer\">https://formulae.brew.sh/formula/python@3.9#default</a></p>\n<p>The latest version of the formula for 3.9 also support apple silicon.</p>\n<p>If you want to use python3.10 you need to run as you described brew install python@3.10</p>\n<p>The reason why 3.9 is still the official python3 formula is that generally user using the vanilla python3 are not looking for the latest revision but the more stable. in some months the transition will done.</p>\n"}
{"Id": 70610919, "PostTypeId": 1, "Title": "Installing python in Dockerfile without using python image as base", "Body": "<p>I have a python script that uses DigitalOcean tools (doctl and kubectl) I want to containerize. This means my container will need python, doctl, and kubectl installed. The trouble is, I figure out how to install both python and DigitalOcean tools in the dockerfile.</p>\n<p>I can install python using the base image &quot;python:3&quot; and I can also install the DigitalOcean tools using the base image &quot;alpine/doctl&quot;. However, the rule is you can only use one base image in a dockerfile.</p>\n<p>So I can include the python base image and install the DigitalOcean tools another way:</p>\n<pre><code>FROM python:3\nRUN &lt;somehow install doctl and kubectl&gt;\nRUN pip install firebase-admin\nCOPY script.py\nCMD [&quot;python&quot;, &quot;script.py&quot;]\n</code></pre>\n<p>Or I can include the alpine/doctl base image and install python3 another way.</p>\n<pre><code>FROM alpine/doctl\nRUN &lt;somehow install python&gt;\nRUN pip install firebase-admin\nCOPY script.py\nCMD [&quot;python&quot;, &quot;script.py&quot;]\n</code></pre>\n<p>Unfortunately, I'm not sure how I would do this. Any help in how I can get all these tools installed would be great!</p>\n", "AcceptedAnswerId": 70611018, "AcceptedAnswer": "<p>just add this with any other thing you want to <code>apt-get install</code>:</p>\n<pre><code>RUN apt-get update &amp;&amp; apt-get install -y \\\n    python3.6 &amp;&amp;\\\n    python3-pip &amp;&amp;\\\n</code></pre>\n<p>in alpine it should be something like:</p>\n<pre><code>RUN apk add --update --no-cache python3 &amp;&amp; ln -sf python3 /usr/bin/python &amp;&amp;\\\n    python3 -m ensurepip &amp;&amp;\\\n    pip3 install --no-cache --upgrade pip setuptools &amp;&amp;\\\n</code></pre>\n"}
{"Id": 71053839, "PostTypeId": 1, "Title": "VSCode Jupyter not connecting to python kernel", "Body": "<p>Launching a cell will make this message appear: <code>Connecting to kernel: Python 3.9.6 64-bit: Activating Python Environment 'Python 3.9.6 64-bit'</code>. This message will then stay up loading indefinitely, without anything happening. No actual error message.</p>\n<p>I've already tried searching for this problem, but every other post seem to obtain at least an error message, which isn't the case here. I still looked at some of these, which seemed to indicate the problem might have come from the <code>traitlets</code> package. I tried to downgrade it to what was recommended, but it didn't solve anything, so I reverted the downgrade.</p>\n<p>The main problem here is that I have no idea what could cause such a problem, without even an error message. If you think additional info could help, please do ask, I have no idea what could be of use right now.</p>\n", "AcceptedAnswerId": 71092223, "AcceptedAnswer": "<p>Not sure what did the trick but downgrading VSCode to <a href=\"https://code.visualstudio.com/updates/v1_63\" rel=\"noreferrer\">November version</a> and after that reinstalling Jupyter extension worked for me.</p>\n"}
{"Id": 70721360, "PostTypeId": 1, "Title": "Python/Selenium web scrap how to find hidden src value from a links?", "Body": "<p>Scrapping links should be a simple feat, usually just grabbing the <code>src</code> value of the a tag.</p>\n<p>I recently came across this website (<a href=\"https://sunteccity.com.sg/promotions\" rel=\"nofollow noreferrer\">https://sunteccity.com.sg/promotions</a>) where the href value of a tags of each item cannot be found, but the redirection still works. I'm trying to figure out a way to grab the items and their corresponding links. My typical python selenium code looks something as such</p>\n<pre><code>all_items = bot.find_elements_by_class_name('thumb-img')\nfor promo in all_items:\n    a = promo.find_elements_by_tag_name(&quot;a&quot;)\n    print(&quot;a[0]: &quot;, a[0].get_attribute(&quot;href&quot;))\n</code></pre>\n<p>However, I can't seem to retrieve any <code>href</code>, <code>onclick</code> attributes, and I'm wondering if this is even possible. I noticed that I couldn't do a right-click, open link in new tab as well.</p>\n<p>Are there any ways around getting the links of all these items?</p>\n<p>Edit: Are there any ways to retrieve all the links of the items on the pages?</p>\n<p>i.e.</p>\n<pre><code>https://sunteccity.com.sg/promotions/724\nhttps://sunteccity.com.sg/promotions/731\nhttps://sunteccity.com.sg/promotions/751\nhttps://sunteccity.com.sg/promotions/752\nhttps://sunteccity.com.sg/promotions/754\nhttps://sunteccity.com.sg/promotions/280\n...\n</code></pre>\n<hr />\n<p>Edit:\nAdding an image of one such anchor tag for better clarity:\n<a href=\"https://i.stack.imgur.com/xbUke.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/xbUke.png\" alt=\"enter image description here\" /></a></p>\n", "AcceptedAnswerId": 70725182, "AcceptedAnswer": "<p>By reverse-engineering the Javascript that takes you to the promotions pages (seen in <a href=\"https://sunteccity.com.sg/_nuxt/d4b648f.js\" rel=\"nofollow noreferrer\">https://sunteccity.com.sg/_nuxt/d4b648f.js</a>) that gives you a way to get all the links, which are based on the <code>HappeningID</code>. You can verify by running this in the JS console, which gives you the first promotion:</p>\n<pre class=\"lang-js prettyprint-override\"><code>window.__NUXT__.state.Promotion.promotions[0].HappeningID\n</code></pre>\n<p>Based on that, you can create a Python loop to get all the promotions:</p>\n<pre class=\"lang-py prettyprint-override\"><code>items = driver.execute_script(&quot;return window.__NUXT__.state.Promotion;&quot;)\nfor item in items[&quot;promotions&quot;]:\n    base = &quot;https://sunteccity.com.sg/promotions/&quot;\n    happening_id = str(item[&quot;HappeningID&quot;])\n    print(base + happening_id)\n</code></pre>\n<p>That generated the following output:</p>\n<pre><code>https://sunteccity.com.sg/promotions/724\nhttps://sunteccity.com.sg/promotions/731\nhttps://sunteccity.com.sg/promotions/751\nhttps://sunteccity.com.sg/promotions/752\nhttps://sunteccity.com.sg/promotions/754\nhttps://sunteccity.com.sg/promotions/280\nhttps://sunteccity.com.sg/promotions/764\nhttps://sunteccity.com.sg/promotions/766\nhttps://sunteccity.com.sg/promotions/762\nhttps://sunteccity.com.sg/promotions/767\nhttps://sunteccity.com.sg/promotions/732\nhttps://sunteccity.com.sg/promotions/733\nhttps://sunteccity.com.sg/promotions/735\nhttps://sunteccity.com.sg/promotions/736\nhttps://sunteccity.com.sg/promotions/737\nhttps://sunteccity.com.sg/promotions/738\nhttps://sunteccity.com.sg/promotions/739\nhttps://sunteccity.com.sg/promotions/740\nhttps://sunteccity.com.sg/promotions/741\nhttps://sunteccity.com.sg/promotions/742\nhttps://sunteccity.com.sg/promotions/743\nhttps://sunteccity.com.sg/promotions/744\nhttps://sunteccity.com.sg/promotions/745\nhttps://sunteccity.com.sg/promotions/746\nhttps://sunteccity.com.sg/promotions/747\nhttps://sunteccity.com.sg/promotions/748\nhttps://sunteccity.com.sg/promotions/749\nhttps://sunteccity.com.sg/promotions/750\nhttps://sunteccity.com.sg/promotions/753\nhttps://sunteccity.com.sg/promotions/755\nhttps://sunteccity.com.sg/promotions/756\nhttps://sunteccity.com.sg/promotions/757\nhttps://sunteccity.com.sg/promotions/758\nhttps://sunteccity.com.sg/promotions/759\nhttps://sunteccity.com.sg/promotions/760\nhttps://sunteccity.com.sg/promotions/761\nhttps://sunteccity.com.sg/promotions/763\nhttps://sunteccity.com.sg/promotions/765\nhttps://sunteccity.com.sg/promotions/730\nhttps://sunteccity.com.sg/promotions/734\nhttps://sunteccity.com.sg/promotions/623\n</code></pre>\n"}
{"Id": 70729502, "PostTypeId": 1, "Title": "F2 rename variable doesn't work in vscode + jupyter notebook + python", "Body": "<p>I can use the normal F2 rename variable functionality in regular python files in vscode. But not when editing python in a jupyter notebook.</p>\n<p>When I press F2 on a variable in a jupyter notebook in vscode I get the familiar change variable window but when I press enter the variable is not changed and I get this error message:</p>\n<blockquote>\n<p>No result. No result.</p>\n</blockquote>\n<p>Is there a way to get the F2 change variable functionality to work in jupyter notebooks?</p>\n<p>Here's my system info:</p>\n<p>jupyter module version</p>\n<pre><code>(adventofcode) C:\\git\\leetcode&gt;pip show jupyter\nName: jupyter\nVersion: 1.0.0\nSummary: Jupyter metapackage. Install all the Jupyter components in one go.\nHome-page: http://jupyter.org\nAuthor: Jupyter Development Team\nAuthor-email: jupyter@googlegroups.org\nLicense: BSD\nLocation: c:\\users\\johan\\anaconda3\\envs\\adventofcode\\lib\\site-packages\nRequires: ipykernel, qtconsole, nbconvert, jupyter-console, notebook, ipywidgets\nRequired-by:\n</code></pre>\n<p>Python version:</p>\n<pre><code>(adventofcode) C:\\git\\leetcode&gt;python --version\nPython 3.10.0\n</code></pre>\n<p>vscode version:</p>\n<pre><code>1.63.2 (user setup)\n</code></pre>\n<p>vscode Jupyter extension version (from the changelog in the extensions window):</p>\n<pre><code>2021.11.100 (November Release on 8 December 2021)\n</code></pre>\n", "AcceptedAnswerId": 70736000, "AcceptedAnswer": "<p>Notice that you put up a bug report in GitHub and see this issue: <a href=\"https://github.com/microsoft/vscode-jupyter/issues/7433\" rel=\"noreferrer\">Renaming variables didn't work</a>, the programmer replied:</p>\n<blockquote>\n<p>Some language features are currently not supported in notebooks, but\nwe are making plans now to hopefully bring more of those online soon.</p>\n</blockquote>\n<p>So please wait for this feature.</p>\n"}
{"Id": 70704285, "PostTypeId": 1, "Title": "Can no longer fold python dictionaries in VS Code", "Body": "<p>I used to be able to collapse (fold) python dictionaries just fine in my VS Code.  Randomly I am not able to do that anymore.  I can still fold classes and functions just fine, but dictionaries cannot fold, the arrow on the left hand side just isn't there.  I've checked my settings but I can't figure out what would've changed.  I'm not sure the best forum to go to for help, so I'm hoping this is ok.  Any ideas?</p>\n", "AcceptedAnswerId": 70714478, "AcceptedAnswer": "<p>It's caused by Pylance v2022.1.1. Use v2022.1.0 instead.</p>\n<p>Issue <a href=\"https://github.com/microsoft/pylance-release/issues/2248\" rel=\"nofollow noreferrer\">#2248</a></p>\n"}
{"Id": 70751249, "PostTypeId": 1, "Title": "Which are safe methods and practices for string formatting with user input in Python 3?", "Body": "<h1>My Understanding</h1>\n<p>From various sources, I have come to the understanding that there are four main techniques of string formatting/interpolation in Python 3 (3.6+ for f-strings):</p>\n<ol>\n<li>Formatting with <code>%</code>, which is similar to C's <code>printf</code></li>\n<li>The <code>str.format()</code> method</li>\n<li>Formatted string literals/f-strings</li>\n<li>Template strings from the standard library <code>string</code> module</li>\n</ol>\n<p>My knowledge of usage mainly comes from <a href=\"https://realpython.com/python-string-formatting/\" rel=\"noreferrer\">Python String Formatting Best Practices (<em>source A</em>)</a>:</p>\n<ul>\n<li><code>str.format()</code> was created as a better alternative to the <code>%</code>-style, so the latter is now obsolete\n<ul>\n<li>However, <code>str.format()</code> is <a href=\"https://lucumr.pocoo.org/2016/12/29/careful-with-str-format/\" rel=\"noreferrer\" title=\"Be Careful with Python's New-Style String Format\">vulnerable to attacks</a> if user-given format strings are not properly handled</li>\n</ul>\n</li>\n<li>f-strings allow <code>str.format()</code>-like behavior only for string literals but are shorter to write and are actually somewhat-optimized syntactic sugar for concatenation</li>\n<li>Template strings are safer than <code>str.format()</code> (demonstrated in the first source) and the other two methods (implied in the first source) when dealing with user input</li>\n</ul>\n<p>I understand that the aforementioned vulnerability in <code>str.format()</code> comes from the method being usable on any normal strings where the delimiting braces are part of the string data itself. Malicious user input containing brace-delimited replacement fields can be supplied to the method to access environment attributes. I believe this is unlike the other ways of formatting where the programmer is the only one that can supply variables to the pre-formatted string. For example, <a href=\"https://docs.python.org/3/reference/lexical_analysis.html#f-strings\" rel=\"noreferrer\" title=\"Python Docs: f-strings\">f-strings</a> have similar syntax to <a href=\"https://docs.python.org/3/library/string.html#format-string-syntax\" rel=\"noreferrer\" title=\"Python Docs: Format String Syntax\"><code>str.format()</code></a> but, because f-strings are literals and the inserted values are evaluated separately through concatenation-like behavior, they are not vulnerable to the same attack (<a href=\"https://security.stackexchange.com/questions/238338/are-there-any-security-concerns-to-using-python-f-strings-with-user-input\" title=\"Are there any Security Concerns to using Python F Strings with User Input\"><em>source B</em></a>). Both <code>%</code>-formatting and Template strings also seem to only be supplied variables for substitution by the programmer; the main difference pointed out is Template's more limited functionality.</p>\n<h1>My Confusion</h1>\n<p>I have seen a lot of emphasis on the vulnerability of <code>str.format()</code> which leaves me with questions of what I should be wary of when using the other techniques. <em>Source A</em> describes Template strings as the safest of the above methods &quot;due to their reduced complexity&quot;:</p>\n<blockquote>\n<p>The more complex formatting mini-languages of the other string formatting techniques might introduce security vulnerabilities to your programs.</p>\n</blockquote>\n<ol>\n<li>Yes, it seems like f-strings are not vulnerable in the same way <code>str.format()</code> is, but are there known concerns about <strong>f-string</strong> security as is implied by <em>source A</em>? Is the concern more like risk mitigation for unknown exploits and unintended interactions?</li>\n</ol>\n<p>I am not familiar with C and I don't plan on using the clunkier <code>%</code>/<code>printf</code>-style formatting, but I have heard that C's <code>printf</code> had its own potential vulnerabilities. In addition, both <em>sources A and B</em> seem to imply a lack of security with this method. The top answer in Source B says,</p>\n<blockquote>\n<p>String formatting may be dangerous when a format string depends on untrusted data. So, when using str.format() or %-formatting, it's important to use static format strings, or to sanitize untrusted parts before applying the formatter function.</p>\n</blockquote>\n<ol start=\"2\">\n<li>Do <code>%</code>-style strings have known security concerns?</li>\n<li>Lastly, which methods should be used and how can user input-based attacks be prevented (e.g. filtering input with regex)?\n<ul>\n<li>More specifically, are Template strings really the safer option? and Can f-strings be used just as easily and safely while granting more functionality?</li>\n</ul>\n</li>\n</ol>\n", "AcceptedAnswerId": 70755916, "AcceptedAnswer": "<p>It doesn't matter which format you choose, any format and library can have its own downsides and vulnerabilities. The bigger questions you need to ask yourself is what is the risk factor and the scenario you are facing with, and what are you going to do about it.\nFirst ask yourself: will there be a scenario where a user or an external entity of some kind (for example - an external system) sends you a format string? If the answer is no, there is no risk. If the answer is yes, you need to see whether this is needed or not. If not - remove it to eliminate the risk.\nIf you need it - you can perform whitelist-based input validation and exclude all format-specific special characters from the list of permitted characters, in order to eliminate the risk. For example, no format string can pass the ^[a-zA-Z0-9\\s]*$ generic regular expression.</p>\n<p>So the bottom line is: it doesn't matter which format string type you use, what's really important is what do you do with it and how can you reduce and eliminate the risk of it being tampered.</p>\n"}
{"Id": 70773526, "PostTypeId": 1, "Title": "Why do we need a dict.update() method in python instead of just assigning the values to the corresponding keys?", "Body": "<p>I have been working with dictionaries that I have to modify within different parts of my code. I am trying to make sure if I do not miss anything about there is no need for dict_update() in any scenario.</p>\n<p>So the reasons to use update() method is either to add a new key-value pair to current dictionary, or update the value of your existing ones.</p>\n<p>But wait!?</p>\n<p>Aren't they already possible by just doing:</p>\n<pre><code>&gt;&gt;&gt;test_dict = {'1':11,'2':1445}\n&gt;&gt;&gt;test_dict['1'] = 645\n&gt;&gt;&gt;test_dict\n{'1': 645, '2': 1445}\n&gt;&gt;&gt;test_dict[5]=123\n&gt;&gt;&gt;test_dict\n{'1': 645, '2': 1445, 5: 123}\n</code></pre>\n<p>In what case it would be crucial to use it ? I am curious.</p>\n<p>Many thanks</p>\n", "AcceptedAnswerId": 70773868, "AcceptedAnswer": "<h3>1. You can update many keys on the same statement.</h3>\n<pre><code>my_dict.update(other_dict)\n</code></pre>\n<p>In this case you don't have to know how many keys are in the <code>other_dict</code>. You'll just be sure that all of them will be updated on <code>my_dict</code>.</p>\n<h3>2. You can use any iterable of key/value pairs with dict.update</h3>\n<p>As per the <a href=\"https://docs.python.org/3/library/stdtypes.html\" rel=\"noreferrer\">documentation</a> you can use another dictionary, kwargs, list of tuples, or even generators that yield tuples of len 2.</p>\n<h3>3. You can use the <code>update</code> method as an argument for functions that expect a function argument.</h3>\n<p>Example:</p>\n<pre><code>def update_value(key, value, update_function):\n    update_function([(key, value)])\n\nupdate_value(&quot;k&quot;, 3, update_on_the_db)  # suppose you have a update_on_the_db function\nupdate_value(&quot;k&quot;, 3, my_dict.update)  # this will update on the dict\n</code></pre>\n"}
{"Id": 71238822, "PostTypeId": 1, "Title": "Why is setuptools not available in environment Ubuntu docker image with Python & dev tools installed?", "Body": "<p>I'm trying to build a Ubuntu 18.04 Docker image running Python 3.7 for a machine learning project. When installing specific Python packages with <code>pip</code> from <code>requirements.txt</code>, I get the following error:</p>\n<pre><code>Collecting sklearn==0.0\n  Downloading sklearn-0.0.tar.gz (1.1 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'error'\n  error: subprocess-exited-with-error\n  \n  \u00d7 python setup.py egg_info did not run successfully.\n  \u2502 exit code: 1\n  \u2570\u2500&gt; [1 lines of output]\n      ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n      [end of output]\n</code></pre>\n<p>Although here the error arises in the context of <code>sklearn</code>, the issue is not specific to one library; when I remove that libraries and try to rebuild the image, the error arises with other libraries.</p>\n<p>Here is my <code>Dockerfile</code>:</p>\n<pre><code>FROM ubuntu:18.04\n\n# install python\nRUN apt-get update &amp;&amp; \\\n    apt-get install --no-install-recommends -y \\\n    python3.7 python3-pip python3.7-dev\n\n# copy requirements\nWORKDIR /opt/program\nCOPY requirements.txt requirements.txt\n\n# install requirements\nRUN python3.7 -m pip install --upgrade pip &amp;&amp; \\\n    python3.7 -m pip install -r requirements.txt\n\n# set up program in image\nCOPY . /opt/program\n</code></pre>\n<p>What I've tried:</p>\n<ul>\n<li>installing <code>python-devtools</code>, both instead of and alongside, <code>python3.7-dev</code> before installing requirements with <code>pip</code>;</li>\n<li>installing <code>setuptools</code> in <code>requirements.txt</code> before affected libraries are installed.</li>\n</ul>\n<p>In both cases the same error arose.</p>\n<p>Do you know how I can ensure <code>setuptools</code> is available in my environment when installing libraries like <code>sklearn</code>?</p>\n", "AcceptedAnswerId": 71239956, "AcceptedAnswer": "<p>As mentioned in comment, install <code>setuptools</code> with <code>pip</code> before running <code>pip install -r requirements.txt</code>.</p>\n<p>It is different than putting <code>setuptools</code> higher in the <code>requirements.txt</code> because it forces the order while the requirements file collect all the packages and installs them after so you don't control the order.</p>\n"}
{"Id": 70879159, "PostTypeId": 1, "Title": "Get datetime format from string python", "Body": "<p>In Python there are multiple DateTime parsers which can parse a date string automatically without providing the datetime format. My problem is that I don't need to cast the datetime, I only need the datetime format.</p>\n<p>Example:\nFrom &quot;2021-01-01&quot;, I want something like &quot;%Y-%m-%d&quot; or &quot;yyyy-MM-dd&quot;.</p>\n<p>My only idea was to try casting with different formats and get the successful one, but I don't want to list every possible format.</p>\n<p>I'm working with pandas, so I can use methods that work either with series or the string DateTime parser.</p>\n<p>Any ideas?</p>\n", "AcceptedAnswerId": 70879221, "AcceptedAnswer": "<p>In <code>pandas</code>, this is achieved by <code>pandas._libs.tslibs.parsing.guess_datetime_format</code></p>\n<pre class=\"lang-py prettyprint-override\"><code>from pandas._libs.tslibs.parsing import guess_datetime_format\n\nguess_datetime_format('2021-01-01')\n\n# '%Y-%m-%d'\n</code></pre>\n<p>As there will always be an ambiguity on the day/month, you can specify the dayfirst case:</p>\n<pre class=\"lang-py prettyprint-override\"><code>guess_datetime_format('2021-01-01', dayfirst=True)\n# '%Y-%d-%m'\n</code></pre>\n"}
{"Id": 70967266, "PostTypeId": 1, "Title": "what exactly is python typing.Callable?", "Body": "<p>I have seen <code>typing.Callable</code>, but I didn't find any useful docs about it. What exactly is <code>typing.Callable</code>?</p>\n", "AcceptedAnswerId": 70967371, "AcceptedAnswer": "<p><a href=\"https://docs.python.org/3/library/typing.html#typing.Callable\" rel=\"noreferrer\"><code>typing.Callable</code></a> is the type you use to indicate a <a href=\"https://docs.python.org/3/library/functions.html#callable\" rel=\"noreferrer\">callable</a>. Most python types that support the <code>()</code> operator are of the type <a href=\"https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable\" rel=\"noreferrer\"><code>collections.abc.Callable</code></a>. Examples include functions, <a href=\"https://docs.python.org/3/library/functions.html#classmethod\" rel=\"noreferrer\"><code>classmethod</code></a>s, <a href=\"https://docs.python.org/3/library/functions.html#staticmethod\" rel=\"noreferrer\"><code>staticmethod</code></a>s, bound methods and lambdas.</p>\n<p>In summary, anything with a <code>__call__</code> method (which is how <code>()</code> is implemented), is a callable.</p>\n<p><a href=\"https://www.python.org/dev/peps/pep-0677/\" rel=\"noreferrer\">PEP 677</a> attempted to introduce implicit tuple-with-arrow syntax, so that something like <code>Callable[[int, str], list[float]]</code> could be expressed much more intuitively as <code>(int, str) -&gt; list[float]</code>. The PEP was rejected because the benefits of the new syntax were not deemed sufficient given the added maintenance burden and possible room for confusion.</p>\n"}
{"Id": 71500756, "PostTypeId": 1, "Title": "What is Python's \"Namespace\" object?", "Body": "<p>I know what namespaces are. But when running</p>\n<pre><code>import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument('bar')\nparser.parse_args(['XXX']) # outputs:  Namespace(bar='XXX')\n</code></pre>\n<p>What kind of object is <code>Namespace(bar='XXX')</code>? I find this totally confusing.</p>\n<p>Reading the argparse docs, it says &quot;Most ArgumentParser actions add some value as an attribute of the object returned by parse_args()&quot;.  Shouldn't this object then appear when running <code>globals()</code>? Or how can I introspect it?</p>\n", "AcceptedAnswerId": 71500890, "AcceptedAnswer": "<p>Samwise's answer is very good, but let me answer the other part of the question.</p>\n<blockquote>\n<p>Or how can I introspect it?</p>\n</blockquote>\n<p>Being able to introspect objects is a valuable skill in any language, so let's approach this as though <code>Namespace</code> is a completely unknown type.</p>\n<pre><code>&gt;&gt;&gt; obj = parser.parse_args(['XXX']) # outputs:  Namespace(bar='XXX')\n</code></pre>\n<p>Your first instinct is good. See if there's a <code>Namespace</code> in the global scope, which there isn't.</p>\n<pre><code>&gt;&gt;&gt; Namespace\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nNameError: name 'Namespace' is not defined\n</code></pre>\n<p>So let's see the actual type of the thing. The <code>Namespace(bar='XXX')</code> printer syntax is coming from a <code>__str__</code> or <code>__repr__</code> method somewhere, so let's see what the type <em>actually</em> is.</p>\n<pre><code>&gt;&gt;&gt; type(obj)\n&lt;class 'argparse.Namespace'&gt;\n</code></pre>\n<p>and its module</p>\n<pre><code>&gt;&gt;&gt; type(obj).__module__\n'argparse'\n</code></pre>\n<p>Now it's a pretty safe bet that we can do <code>from argparse import Namespace</code> and get the type. Beyond that, we can do</p>\n<pre><code>&gt;&gt;&gt; help(argparse.Namespace)\n</code></pre>\n<p>in the interactive interpreter to get detailed documentation on the <code>Namespace</code> class, all with no Internet connection necessary.</p>\n"}
{"Id": 70863543, "PostTypeId": 1, "Title": "Can a Python docstring be calculated (f-string or %-expression)?", "Body": "<p>Is it possible to have a Python docstring calculated? I have a lot of repetitive things in my docstrings, so I'd like to either use f-strings or a %-style format expression.</p>\n<p>When I use an f-string at the place of a docstring</p>\n<ul>\n<li>importing the module invokes the processing</li>\n<li>but when I check the <code>__doc__ </code>of such a function it is empty</li>\n<li>sphinx barfs when the docstring is an f-string</li>\n</ul>\n<p>I do know how to process the docstrings after the import, but that doesn't work for object 'doc' strings which is recognized by sphinx but is not a real <code>__doc__</code>'s of the object.</p>\n", "AcceptedAnswerId": 70865657, "AcceptedAnswer": "<p>Docstrings in Python must be regular string literals.</p>\n<p>This is pretty easy to test - the following program does not show the docstring:</p>\n<pre><code>BAR = &quot;Hello world!&quot;\n\ndef foo():\n        f&quot;&quot;&quot;This is {BAR}&quot;&quot;&quot;\n        pass\n\nassert foo.__doc__ is None\nhelp(foo)\n\n</code></pre>\n<p>The Python syntax docs say that <a href=\"https://docs.python.org/3/reference/compound_stmts.html#id19\" rel=\"noreferrer\">the docstring must be a &quot;string literal&quot;</a>, and the tail end of <a href=\"https://docs.python.org/3/reference/lexical_analysis.html#formatted-string-literals\" rel=\"noreferrer\">the f-string reference</a> says they &quot;cannot be used as docstrings&quot;.</p>\n<p>So unfortunately you must use the <code>__doc__</code> attribute.</p>\n<p>However, you should be able to use a decorator to read the <code>__doc__</code> attribute and replace it with whatever you want.</p>\n"}
{"Id": 70987896, "PostTypeId": 1, "Title": "Why is this task faster in Python than Julia?", "Body": "<p>I ran the following code in RStudio:</p>\n<pre><code>exo &lt;- read.csv('exoplanets.csv',TRUE,&quot;,&quot;)\ndf &lt;- data.frame(exo)\n\nranks &lt;- 570\nfiles &lt;- 3198\ndatas &lt;- vector()\n\nfor ( w in 2:files ) {\n    listas &lt;-vector()\n    for ( i in 1:ranks) {\n            name &lt;- as.character(df[i,w])\n            listas &lt;- append (listas, name)\n    }\n    datas &lt;- append (datas, listas)\n}\n</code></pre>\n<p>It reads a huge NASA CSV file, converts it to a dataframe,\nconverts each element to string, and adds them to a vector.</p>\n<p>RStudio took 4 min and 15 seconds.</p>\n<p>So I decided to implement the same code in Julia.\nI ran the following in VS Code:</p>\n<pre><code>using CSV, DataFrames\n\ndf = CSV.read(&quot;exoplanets.csv&quot;, DataFrame)\n\nfil, col = 570, 3198\narr = []\n\nfor i in 2:fil\n        for j in 1:col\n            push!(arr, string(df[i, j]))\n        end\nend\n</code></pre>\n<p>The result was good.\nThe Julia code took only 1 minute and 25 seconds!</p>\n<p>Then for pure curiosity I implemented the same code\nthis time in Python to compare.\nI ran the following in VS Code:</p>\n<pre><code>import numpy as np\nimport pandas as pd\n\nexo = pd.read_csv(&quot;exoplanets.csv&quot;)\narr = np.array(exo)\n\nfil, col = 570, 3198\nlis = []\n\nfor i in range(1, fil):\n        for j in range(col):\n            lis.append(arr[i][j].astype('str'))\n</code></pre>\n<p>The result shocked me! Only 35 seconds!!!\nAnd in Spyder from Anaconda only 26 seconds!!!\nAlmost 2 million floats!!!\nIs Julia slower than Python in data analysis?\nCan I improve the Julia code?</p>\n", "AcceptedAnswerId": 70988453, "AcceptedAnswer": "<p><strong>NOTE:</strong> I wrote the below assuming you want the other column order (as in the Python and R examples).  It is more efficient in Julia this way; to make it work equivalently to your original behaviour, permute the logic or your data at the right places (left as an exercise). Bogumi\u0142's anwer does the right thing already.</p>\n<hr />\n<p>Put stuff into functions, preallocate where possible, iterate in stride order, use views, and use builtin functions and broadcasting:</p>\n<pre><code>function tostringvector(d)\n    r, c = size(d)\n    result = Vector{String}(undef, r*c)\n    v = reshape(result, r, c)\n    for (rcol, dcol) in zip(eachcol(v), eachcol(d))\n        @inbounds rcol .= string.(dcol)\n    end\n    return result\nend\n</code></pre>\n<p>Which certainly can be optimized harder.</p>\n<p>Or shorter, making use of what <code>DataFrames</code> already provides:</p>\n<pre><code>tostringvector(d) = vec(Matrix(string.(d)))\n</code></pre>\n"}
{"Id": 71518406, "PostTypeId": 1, "Title": "How to bypass cloudflare browser checking selenium Python", "Body": "<p>I am trying to access a site using selenium Python.\nBut the site is checking and checking continuously by cloudflare.\nNo other page is coming.</p>\n<p>Check the screenshot here.</p>\n<p><a href=\"https://i.stack.imgur.com/PuCfK.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/PuCfK.jpg\" alt=\"enter image description here\" /></a></p>\n<p>I have tried undetected chrome but it is not working at all.</p>\n", "AcceptedAnswerId": 71518481, "AcceptedAnswer": "<p>By undetected chrome do you mean undetected chromedriver?:</p>\n<p>Anyways, undetected-chromedriver works for me:</p>\n<h2>Undetected chromedriver</h2>\n<p>Github: <a href=\"https://github.com/ultrafunkamsterdam/undetected-chromedriver\" rel=\"noreferrer\">https://github.com/ultrafunkamsterdam/undetected-chromedriver</a></p>\n<pre><code>pip install undetected-chromedriver\n</code></pre>\n<h3>Code that gets a cloudflare protected site:</h3>\n<pre><code>import undetected_chromedriver as uc\ndriver = uc.Chrome(use_subprocess=True)\ndriver.get('https://nowsecure.nl')\n</code></pre>\n<h3>My POV</h3>\n<p><a href=\"https://i.stack.imgur.com/5ZryO.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/5ZryO.png\" alt=\"enter image description here\" /></a>\n<a href=\"https://i.stack.imgur.com/wjl1i.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/wjl1i.png\" alt=\"enter image description here\" /></a></p>\n<hr />\n<h3>Quick setup code that logs into your google account:</h3>\n<p>Github: <a href=\"https://github.com/xtekky/google-login-bypass\" rel=\"noreferrer\">https://github.com/xtekky/google-login-bypass</a></p>\n<pre><code>import undetected_chromedriver as uc\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n#  ---------- EDIT ----------\nemail = 'email\\n' # replace email\npassword = 'password\\n' # replace password\n#  ---------- EDIT ----------\n\ndriver = uc.Chrome(use_subprocess=True)\nwait = WebDriverWait(driver, 20)\nurl = 'https://accounts.google.com/ServiceLogin?service=accountsettings&amp;continue=https://myaccount.google.com%3Futm_source%3Daccount-marketing-page%26utm_medium%3Dgo-to-account-button'\ndriver.get(url)\n\n\nwait.until(EC.visibility_of_element_located((By.NAME, 'identifier'))).send_keys(email)\nwait.until(EC.visibility_of_element_located((By.NAME, 'password'))).send_keys(password)\nprint(&quot;You're in!! enjoy&quot;)\n\n# [ ---------- paste your code here ---------- ]\n</code></pre>\n"}
{"Id": 70872276, "PostTypeId": 1, "Title": "FastAPI python: How to run a thread in the background?", "Body": "<p>I'm making a server in python using FastAPI, and I want a function that is not related to my API, to run in background every 5 minutes (like checking stuff from an API and printing stuff depending on the response)</p>\n<p>I've tried to make a thread that runs the function <code>start_worker</code>, but it doesn't print anything.</p>\n<p>Does anyone know how to do so ?</p>\n<pre class=\"lang-py prettyprint-override\"><code>def start_worker():\n    print('[main]: starting worker...')\n    my_worker = worker.Worker()\n    my_worker.working_loop() # this function prints &quot;hello&quot; every 5 seconds\n\nif __name__ == '__main__':\n    print('[main]: starting...')\n    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000, reload=True)\n    _worker_thread = Thread(target=start_worker, daemon=False)\n    _worker_thread.start()\n</code></pre>\n", "AcceptedAnswerId": 70873984, "AcceptedAnswer": "<p>You should start your Thread before calling <code>uvicorn.run</code>, as <code>uvicorn.run</code> is blocking the thread.</p>\n<p>PS: In your question you state that you would like the background task to run every 5 minutes, but in your code you say every 5 <strong>seconds</strong>. The below examples assume that is the latter you want. If you want it to be executed every 5 minutes instead, then adjust the time to <strong>60 * 5</strong>.</p>\n<p><strong>Option 1</strong></p>\n<pre><code>import time\nimport threading\nfrom fastapi import FastAPI\nimport uvicorn\n\napp = FastAPI()\nclass BackgroundTasks(threading.Thread):\n    def run(self,*args,**kwargs):\n        while True:\n            print('Hello')\n            time.sleep(5)\n  \nif __name__ == '__main__':\n    t = BackgroundTasks()\n    t.start()\n    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)\n</code></pre>\n<p>You could also start your thread using FastAPI's <a href=\"https://fastapi.tiangolo.com/advanced/events/#startup-event\" rel=\"noreferrer\">startup event</a>, as long as it is ok to run before the application starts.</p>\n<pre><code>@app.on_event(&quot;startup&quot;)\nasync def startup_event():\n    t = BackgroundTasks()\n    t.start()\n</code></pre>\n<p><strong>Option 2</strong></p>\n<p>You could instead use a repeating <a href=\"https://docs.python.org/3/library/sched.html\" rel=\"noreferrer\">Event scheduler</a> for the background task, as below:</p>\n<pre><code>import sched, time\nfrom threading import Thread\nfrom fastapi import FastAPI\nimport uvicorn\n\napp = FastAPI()\ns = sched.scheduler(time.time, time.sleep)\n\ndef print_event(sc): \n    print(&quot;Hello&quot;)\n    sc.enter(5, 1, print_event, (sc,))\n\ndef start_scheduler():\n    s.enter(5, 1, print_event, (s,))\n    s.run()\n\n@app.on_event(&quot;startup&quot;)\nasync def startup_event():\n    thread = Thread(target = start_scheduler)\n    thread.start()\n\nif __name__ == '__main__':\n    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)\n</code></pre>\n"}
{"Id": 70966298, "PostTypeId": 1, "Title": "Python Black code formatter doesn't format docstring line length", "Body": "<p>I am running the Black code formatter against a Python script however it doesn't reformat the line length for docstrings. For example, given the following code:</p>\n<pre><code>def my_func():\n    &quot;&quot;&quot;\n    This is a really long docstring. This is a really long docstring. This is a really long docstring. This is a really long docstring. This is a really long docstring. This is a really long docstring.\n    &quot;&quot;&quot;\n    return\n</code></pre>\n<p>When running Black against this script, the line length does not change. How can I ensure docstrings get formatted when running Black?</p>\n", "AcceptedAnswerId": 71041192, "AcceptedAnswer": "<p>maintainer here! :wave:</p>\n<p>The short answer is <strong>no you cannot configure Black to fix line length issues in docstrings currently.</strong></p>\n<p>It's not likely Black will split or merge lines in docstrings as it would be far too risky, structured data can and does exist in docstrings. While I would hope the added newlines wouldn't break the consumers it's still a valid concern.</p>\n<p>There's currently an open issue asking for this (although it also wants the line length limit for docstrings and strings to be 79) <a href=\"https://github.com/psf/black/issues/2289\" rel=\"nofollow noreferrer\">GH-2289</a>, and specifically for docstrings <a href=\"https://github.com/psf/black/issues/2865\" rel=\"nofollow noreferrer\">GH-2865</a>. You can also read <a href=\"https://github.com/psf/black/issues/1713\" rel=\"nofollow noreferrer\">GH-1713</a> which is about splitting comments (and likewise has mixed feelings from maintainers).</p>\n<p>For the time being, perhaps you can look into <a href=\"https://github.com/PyCQA/docformatter\" rel=\"nofollow noreferrer\">https://github.com/PyCQA/docformatter</a> which does seem to wrap docstrings (see the <code>--wrap-descriptions</code> and <code>--wrap-summaries</code> options)</p>\n<hr />\n<p><sup>P.S. if you're curious whether we'll add a flag to split docstrings or comments, it's once again unlikely since we seek to minimize formatting configurability. Especially as the pre-existing flags only disable certain elements of Black's style (barring --line-length which exists as there's no real consensus what it should be). Feel free to state your arguments in the linked issues tho!</sup></p>\n"}
{"Id": 70669213, "PostTypeId": 1, "Title": "gyp ERR! stack Error: Command failed: python -c import sys; print \"%s.%s.%s\" % sys.version_info[:3]", "Body": "<p>I'm trying to npm install in a Vue project, and even if I just ran vue create (name)\nit gives me this err:</p>\n<pre><code>npm ERR! gyp verb check python checking for Python executable &quot;c:\\Python310\\python.exe&quot; in the PATH\nnpm ERR! gyp verb `which` succeeded c:\\Python310\\python.exe c:\\Python310\\python.exe\nnpm ERR! gyp ERR! configure error\nnpm ERR! gyp ERR! stack Error: Command failed: c:\\Python310\\python.exe -c import sys; print &quot;%s.%s.%s&quot; % sys.version_info[:3];\nnpm ERR! gyp ERR! stack   File &quot;&lt;string&gt;&quot;, line 1\nnpm ERR! gyp ERR! stack     import sys; print &quot;%s.%s.%s&quot; % sys.version_info[:3];\nnpm ERR! gyp ERR! stack                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnpm ERR! gyp ERR! stack SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\nnpm ERR! gyp ERR! stack\nnpm ERR! gyp ERR! stack     at ChildProcess.exithandler (node:child_process:397:12)\nnpm ERR! gyp ERR! stack     at ChildProcess.emit (node:events:390:28)\nnpm ERR! gyp ERR! stack     at maybeClose (node:internal/child_process:1064:16)\nnpm ERR! gyp ERR! stack     at Process.ChildProcess._handle.onexit (node:internal/child_process:301:5)\nnpm ERR! gyp ERR! System Windows_NT 10.0.19044\nnpm ERR! gyp ERR! command &quot;C:\\\\Program Files\\\\nodejs\\\\node.exe&quot; &quot;C:\\\\Upwork\\\\contact_book\\\\node_modules\\\\node-gyp\\\\bin\\\\node-gyp.js&quot; &quot;rebuild&quot; &quot;--verbose&quot; &quot;--libsass_ext=&quot; &quot;--libsass_cflags=&quot; &quot;--libsass_ldflags=&quot; &quot;--libsass_library=&quot;\nnpm ERR! gyp ERR! cwd C:\\Upwork\\contact_book\\node_modules\\node-sass\nnpm ERR! gyp ERR! node -v v16.13.1\nnpm ERR! gyp ERR! node-gyp -v v3.8.0\nnpm ERR! gyp ERR! not ok\nnpm ERR! Build failed with error code: 1\n</code></pre>\n<p>I tried it in another PC but it is working fine, I think it is because I need to install something (since the PC is new)</p>\n", "AcceptedAnswerId": 70968862, "AcceptedAnswer": "<p>As @MehdiMamas pointed out in the comments, downgrading Node to v14 should solve the problem</p>\n<pre><code>nvm install 14\nnvm use 14\n</code></pre>\n"}
{"Id": 71048280, "PostTypeId": 1, "Title": "Upgrade python to 3.10 in windows; Do I have to reinstall all site-packages manually?", "Body": "<p>I have in windows 10 64 bit installed python 3.9 with site-packages. I would like to install python 3.10.2 on windows 10 64 bit and find a way to install packages automatically in python 3.10.2, the same ones I currently have installed in python 3.9. I am also interested in the answer to this question for windows 11 64 bit.</p>\n", "AcceptedAnswerId": 71048281, "AcceptedAnswer": "<p>I upgraded to python 3.10.2 in windows 10 64 bit. To properly install the packages, install the appropriate version of the Microsoft Visual C++ compiler if necessary. Details can be read <a href=\"https://wiki.python.org/moin/WindowsCompilers\" rel=\"noreferrer\">https://wiki.python.org/moin/WindowsCompilers</a> . With the upgrade to python 3.10.2 from 3.9, it turned out that I had to do it, due to errors that are appearing during the installation of the packages. Before the installing python 3.10.2, type and execute the following command in the windows command prompt:</p>\n<pre><code>pip freeze &gt; reqs.txt\n</code></pre>\n<p>This command writes to the reqs.txt file the names of all installed packages in the version suitable for pip. If you run the command prompt with administrator privileges, the reqs.txt file will be saved in the directory <code>C:\\WINDOWS\\system32</code>.</p>\n<p>Then, after the installing of python 3.10.2 and the adding it to the paths in PATH, with the help of the command prompt you need to issue the command:</p>\n<pre><code>pip install -r reqs.txt\n</code></pre>\n<p>This will start the installing of the packages in the same versions as for python 3.9. If problems occur, e.g. an installation error appears during the installation of lxml, then you can remove from the regs.txt file the entry with the name of the package whose installation is causing the problem and then install it manually. To edit the reqs.txt file you need the administrator privileges. The easiest way is to run the command prompt in the administrator mode, type reqs.txt and click Enter to edit it.</p>\n<p>I decided later to update the missing packages to the latest version, because I suspected that with python 3.10.2 older versions were not compatible.\nThis means that when upgrading to python 3.10.2 it is worth asking yourself whether it is better to upgrade for all packages. To do this, you can generate the list of the outdated packages using the command:</p>\n<pre><code>pip list \u2013-outdated\n</code></pre>\n<p>After the printing of the list in the command prompt, you can upgrade the outdated packages using the command:</p>\n<pre><code>pip install --upgrade &lt;package-name&gt;\n</code></pre>\n<p>This can be automated by the editing of the reqs.txt file and the changing of the mark == to &gt; which will speed up the upgrade. The mark &gt;  should only be changed for the outdated packages or you will get an error: &quot;Could not find a version that satisfies the requirement ... &quot;.</p>\n<p>Supplement to virtual environments:</p>\n<p>When you enter a virtual environment directory (in the windows command prompt):, such as <code>D:\\python_projects\\data_visualization\\env\\Scripts</code>, type activate to activate it. Then create the reqs.txt file analogous to the description above. Then, copy the file to a temporary directory. After this delete the virtual environment, e.g. using the windows explorator by the deleting of the contents of the <code>env</code> directory. Then, using the version of python in windows of our choice, create a virtual environment using the <code>env</code> directory (see: <a href=\"https://docs.python.org/3/library/venv.html\" rel=\"noreferrer\">https://docs.python.org/3/library/venv.html</a>). Copy the regs.txt file to the newly created <code>D:\\python_projects\\data_visualization\\env\\Scripts</code> directory. Install site-packages with the support of the regs.txt file as described above.</p>\n"}
{"Id": 71019671, "PostTypeId": 1, "Title": "VSCode Python Debugger stops suddenly", "Body": "<p>after installing Windows updates today, debugging is not working anymore.</p>\n<p>This is my active debug configuration:</p>\n<pre><code>&quot;launch&quot;: {\n  &quot;version&quot;: &quot;0.2.0&quot;,\n  &quot;configurations&quot;: [\n    {\n      &quot;name&quot;: &quot;DEBUG CURR&quot;,\n      &quot;type&quot;: &quot;python&quot;,\n      &quot;request&quot;: &quot;launch&quot;,\n      &quot;program&quot;: &quot;${file}&quot;,\n      &quot;console&quot;: &quot;internalConsole&quot;,\n      &quot;justMyCode&quot;: false,\n      &quot;stopOnEntry&quot;: false,\n    }...\n</code></pre>\n<p>When I start the debugger, the menu pops up briefly for 1-2 seconds. But then it closes. There is no output in the console.</p>\n<p>It does not stop at set breakpoints.</p>\n<p>Does anybody have the same problem? Is there a solution?</p>\n<h3>System settings</h3>\n<ul>\n<li>OS: Microsoft Windows 10 Enterprise (10.0.17763 Build 17763)</li>\n<li>VSCode version 1.64.0</li>\n<li>Python version: 3.8.11 (in the active Anaconda Environment)</li>\n</ul>\n<p>Installed VSCode extensions:</p>\n<ul>\n<li>Python (Microsoft) version: v2022.0.1786462952</li>\n<li>Pylance (Microsoft) version: v2022.2.0</li>\n</ul>\n", "AcceptedAnswerId": 71020430, "AcceptedAnswer": "<p>It's an issue with the latest Python Extension for VSCode.</p>\n<p>Downgrading the python extension to v2021.12.1559732655 fixes the problem.</p>\n<p><a href=\"https://i.stack.imgur.com/mpU6G.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/mpU6G.png\" alt=\"enter image description here\" /></a></p>\n"}
{"Id": 71034111, "PostTypeId": 1, "Title": "How to set default python3 to python 3.9 instead of python 3.8 in Ubuntu 20.04 LTS", "Body": "<p>I have installed Python 3.9 in the Ubuntu 20.04 LTS. Now the system has both Python 3.8 and Python 3.9.</p>\n<pre><code># which python\n# which python3\n/usr/bin/python3\n# which python3.8\n/usr/bin/python3.8\n# which python3.9\n/usr/bin/python3.9\n# ls -alith /usr/bin/python3\n12583916 lrwxrwxrwx 1 root root 9 Jul 19  2021 /usr/bin/python3 -&gt; python3.8\n</code></pre>\n<p>But the <code>pip3</code> command will still install everything into the Python 3.8 directory.</p>\n<pre><code># pip3 install --upgrade --find-links file:///path/to/directory &lt;...&gt;\n</code></pre>\n<p>I want to change that default pip3 behavior by updating the symbolic link /usr/bin/python3 to /usr/bin/python3.9.</p>\n<p>How to do that?</p>\n<pre><code># update-alternatives --set python3 /usr/bin/python3.9\nThis command will not work as expected.\n</code></pre>\n<p><strong>Here is the pip3 info:</strong></p>\n<pre><code># which pip3\n/usr/bin/pip3\n# ls -alith /usr/bin/pip3\n12589712 -rwxr-xr-x 1 root root 367 Jul 13  2021 /usr/bin/pip3\n# pip3 -V\npip 20.0.2 from /usr/lib/python3/dist-packages/pip (python 3.8)\n# \n</code></pre>\n<p>The <code>alias</code> command will not work:</p>\n<pre><code># alias python3=python3.9\n# ls -alith /usr/bin/python3\n12583916 lrwxrwxrwx 1 root root 9 Jul 19  2021 /usr/bin/python3 -&gt; python3.8\n</code></pre>\n", "AcceptedAnswerId": 71034427, "AcceptedAnswer": "<p>You should be able to use <code>python3.9 -m pip install &lt;package&gt;</code> to run pip with a specific python version, in this case 3.9.</p>\n<p>The full docs on this are here: <a href=\"https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/\" rel=\"noreferrer\">https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/</a></p>\n<p>If you want python3 to point to python3.9 you could use the quick and dirty.</p>\n<pre><code>alias python3=python3.9\n</code></pre>\n<p>EDIT:</p>\n<p>Tried to recreate your problem,</p>\n<pre><code># which python3\n/usr/bin/python3\n# python3 --version\nPython 3.8.10\n# which python3.8\n/usr/bin/python3.8\n# which python3.9\n/usr/bin/python3.9\n</code></pre>\n<p>Then update the alternatives, and set new priority:</p>\n<pre><code># sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n# sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n# sudo update-alternatives --config python3\nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                Priority   Status\n------------------------------------------------------------\n  0            /usr/bin/python3.9   2         auto mode\n  1            /usr/bin/python3.8   2         manual mode\n* 2            /usr/bin/python3.9   2         manual mode\n\nPress &lt;enter&gt; to keep the current choice[*], or type selection number: 0\n</code></pre>\n<p>Check new version:</p>\n<pre><code># ls -alith /usr/bin/python3\n3338 lrwxrwxrwx 1 root root 25 Feb  8 14:33 /usr/bin/python3 -&gt; /etc/alternatives/python3\n# python3 -V\nPython 3.9.5\n# ls -alith /usr/bin/pip3\n48482 -rwxr-xr-x 1 root root 367 Jul 13  2021 /usr/bin/pip3\n# pip3 -V\npip 20.0.2 from /usr/lib/python3/dist-packages/pip (python 3.9)\n</code></pre>\n<p>Hope this helps (tried it in wsl2 Ubuntu 20.04 LTS)</p>\n"}
{"Id": 71078751, "PostTypeId": 1, "Title": "VS Code Python Formatting: Change max line-length with autopep8 / yapf / black", "Body": "<p>I am experimenting with different python formatters and would like to increase the max line length. Ideally without editing the <code>settings.json</code> file. Is there a way to achieve that?\n<a href=\"https://i.stack.imgur.com/a1Nax.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/a1Nax.png\" alt=\"select formatter\" /></a></p>\n", "AcceptedAnswerId": 71078792, "AcceptedAnswer": "<p>For all three formatters, the max line length can be increased with additional arguments passed in from settings, i.e.:</p>\n<ul>\n<li>autopep8 args: <code>--max-line-length=120</code></li>\n<li>black args: <code>--line-length=120</code></li>\n<li>yapf args: <code>--style={based_on_style: google, column_limit: 120, indent_width: 4}</code></li>\n</ul>\n<p>Hope that helps someone in the future!</p>\n<p><a href=\"https://i.stack.imgur.com/kUR66.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/kUR66.png\" alt=\"enter image description here\" /></a></p>\n"}
{"Id": 71121056, "PostTypeId": 1, "Title": "Plotly Python update figure with dropMenu", "Body": "<p>i am currently working with plotly i have a function called plotChart that takes a dataframe as input and plots a candlestick chart. I am trying to figure out a way to pass a list of dataframes  to the function plotChart and use a plotly dropdown menu to show the options on the input list by the stock name. The drop down menu will have the list of dataframe and when an option is clicked on it will update the figure in plotly is there away to do this. below is the code i have to plot a single dataframe</p>\n<pre><code>def make_multi_plot(df):\n    \n    fig = make_subplots(rows=2, cols=2,\n                        shared_xaxes=True,\n                        vertical_spacing=0.03,\n                        subplot_titles=('OHLC', 'Volume Profile'),\n                        row_width=[0.2, 0.7])\n\n    for s in df.name.unique():\n        \n        trace1 = go.Candlestick(\n            x=df.loc[df.name.isin([s])].time,\n            open=df.loc[df.name.isin([s])].open,\n            high=df.loc[df.name.isin([s])].high,\n            low=df.loc[df.name.isin([s])].low,\n            close=df.loc[df.name.isin([s])].close,\n            name = s)\n        fig.append_trace(trace1,1,1)\n        \n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].BbandsMid, mode='lines',name='MidBollinger'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].BbandsUpp, mode='lines',name='UpperBollinger'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].BbandsLow, mode='lines',name='LowerBollinger'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].vwap, mode='lines',name='VWAP'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].STDEV_1, mode='lines',name='UPPERVWAP'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].STDEV_N1, mode='lines',name='LOWERVWAP'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].KcMid, mode='lines',name='KcMid'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].KcUpper, mode='lines',name='KcUpper'),1,1)\n        fig.append_trace(go.Scatter(x=df.loc[df.name.isin([s])].time, y=df.loc[df.name.isin([s])].KcLow, mode='lines',name='KcLow'),1,1)\n        \n\n        trace2 = go.Bar(\n                x=df.loc[df.name.isin([s])].time,\n                y=df.loc[df.name.isin([s])].volume,\n                name = s)\n        fig.append_trace(trace2,2,1)\n        # fig.update_layout(title_text=s)\n        \n        \n        \n    graph_cnt=len(fig.data)\n\n        \n    tr = 11\n    symbol_cnt =len(df.name.unique())\n    for g in range(tr, graph_cnt):\n        fig.update_traces(visible=False, selector=g)\n        #print(g)\n    def create_layout_button(k, symbol):\n        \n        start, end = tr*k, tr*k+2\n        visibility = [False]*tr*symbol_cnt\n        visibility[start:end] = [True,True,True,True,True,True,True,True,True,True,True]\n        return dict(label = symbol,\n                    method = 'restyle',\n                    args = [{'visible': visibility[:-1],\n                             'title': symbol,\n                             'showlegend': False}])    \n    \n    fig.update(layout_xaxis_rangeslider_visible=False)\n    fig.update_layout(\n        updatemenus=[go.layout.Updatemenu(\n            active = 0,\n            buttons = [create_layout_button(k, s) for k, s in enumerate(df.name.unique())]\n            )\n        ])\n    \n    fig.show()\n</code></pre>\n<p>i am trying to add annotations to the figure it will be different for each chart below is how i had it setup for the single chart df['superTrend'] is a Boolean column</p>\n<pre><code>for i in range(df.first_valid_index()+1,len(df.index)):\n        prev = i - 1\n        if df['superTrend'][i] != df['superTrend'][prev] and not np.isnan(df['superTrend'][i]) :\n            #print(i,df['inUptrend'][i])\n            fig.add_annotation(x=df['time'][i], y=df['open'][i],\n            text= 'Buy' if df['superTrend'][i] else 'Sell',\n            showarrow=True,\n            arrowhead=6,\n            font=dict(\n                #family=&quot;Courier New, monospace&quot;,\n                size=20,\n                #color=&quot;#ffffff&quot;\n            ),)\n</code></pre>\n", "AcceptedAnswerId": 71155096, "AcceptedAnswer": "<p>I adapted an example from the <a href=\"https://community.plotly.com/t/combining-multiple-subplots-with-drop-down-menu-buttons/49513/2\" rel=\"nofollow noreferrer\">plotly community</a> to your example and created the code. The point of creation is to create the data for each subplot and then switch between them by means of buttons. The sample data is created using representative companies of US stocks. one issue is that the title is set but not displayed. We are currently investigating this issue.</p>\n<pre><code>import yfinance as yf\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport pandas as pd\n\nsymbols = ['AAPL','GOOG','TSLA']\nstocks = pd.DataFrame()\nfor s in symbols:\n    data = yf.download(s, start=&quot;2021-01-01&quot;, end=&quot;2021-12-31&quot;)\n    data['mean'] = data['Close'].rolling(20).mean()\n    data['std'] = data['Close'].rolling(20).std()\n    data['upperBand'] = data['mean'] + (data['std'] * 2)\n    data.reset_index(inplace=True)\n    data['symbol'] = s\n    stocks = stocks.append(data, ignore_index=True)\n\ndef make_multi_plot(df):\n    \n    fig = make_subplots(rows=2, cols=1,\n                        shared_xaxes=True,\n                        vertical_spacing=0.03,\n                        subplot_titles=('OHLC', 'Volume Profile'),\n                        row_width=[0.2, 0.7])\n\n    for s in df.symbol.unique():\n        trace1 = go.Candlestick(\n            x=df.loc[df.symbol.isin([s])].Date,\n            open=df.loc[df.symbol.isin([s])].Open,\n            high=df.loc[df.symbol.isin([s])].High,\n            low=df.loc[df.symbol.isin([s])].Low,\n            close=df.loc[df.symbol.isin([s])].Close,\n            name=s)\n        fig.append_trace(trace1,1,1)\n        \n        trace2 = go.Scatter(\n            x=df.loc[df.symbol.isin([s])].Date,\n            y=df.loc[df.symbol.isin([s])].upperBand,\n            name=s)\n        fig.append_trace(trace2,1,1)\n        \n        trace3 = go.Bar(\n            x=df.loc[df.symbol.isin([s])].Date,\n            y=df.loc[df.symbol.isin([s])].Volume,\n            name=s)\n        fig.append_trace(trace3,2,1)\n        # fig.update_layout(title_text=s)\n    \n    # Calculate the total number of graphs\n    graph_cnt=len(fig.data)\n    # Number of Symbols\n    symbol_cnt =len(df.symbol.unique())\n    # Number of graphs per symbol\n    tr = 3\n    # Hide setting for initial display\n    for g in range(tr, graph_cnt): \n        fig.update_traces(visible=False, selector=g)\n\n    def create_layout_button(k, symbol):\n        start, end = tr*k, tr*k+2\n        visibility = [False]*tr*symbol_cnt\n        # Number of graphs per symbol, so if you add a graph, add True.\n        visibility[start:end] = [True,True,True]\n        return dict(label = symbol,\n                    method = 'restyle',\n                    args = [{'visible': visibility[:-1],\n                             'title': symbol,\n                             'showlegend': True}])    \n    \n    fig.update(layout_xaxis_rangeslider_visible=False)\n    fig.update_layout(\n        updatemenus=[go.layout.Updatemenu(\n            active = 0,\n            buttons = [create_layout_button(k, s) for k, s in enumerate(df.symbol.unique())]\n            )\n        ])\n    \n    fig.show()\n    return fig.layout\n    \nmake_multi_plot(stocks)\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/OZLSi.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OZLSi.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/3RMCE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3RMCE.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/Enh3E.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Enh3E.png\" alt=\"enter image description here\" /></a></p>\n"}
{"Id": 71193085, "PostTypeId": 1, "Title": "Creating nested columns in python dataframe", "Body": "<p>I have 3 columns namely Models(should be taken as index), Accuracy without normalization, Accuracy with normalization (zscore, minmax, maxabs, robust) and these are required to be created as:</p>\n<pre><code> ------------------------------------------------------------------------------------\n|   Models  |  Accuracy without normalization    |      Accuracy with normalization  |\n|           |                                    |-----------------------------------|\n|           |                                    | zscore | minmax | maxabs | robust |\n ------------------------------------------------------------------------------------\n\n</code></pre>\n<pre><code>dfmod-&gt; Models column\ndfacc-&gt; Accuracy without normalization\ndfacc1-&gt; Accuracy with normalization - zscore\ndfacc2-&gt; Accuracy with normalization - minmax\ndfacc3-&gt; Accuracy with normalization - maxabs\ndfacc4-&gt; Accuracy with normalization - robust\n</code></pre>\n<pre><code>dfout=pd.DataFrame({('Accuracy without Normalization'):{dfacc},\n     ('Accuracy using Normalization','zscore'):{dfacc1},\n     ('Accuracy using Normalization','minmax'):{dfacc2},\n     ('Accuracy using Normalization','maxabs'):{dfacc3},\n     ('Accuracy using Normalization','robust'):{dfacc4},\n   },index=dfmod\n)\n</code></pre>\n<p>I was trying to do something like this but i can't figure out any further</p>\n<p>Test data:</p>\n<pre><code>qda    0.6333       0.6917      0.5917      0.6417     0.5833\nsvm    0.5333       0.6917      0.5333      0.575      0.575\nlda    0.5333       0.6583      0.5333      0.5667     0.5667\nlr     0.5333       0.65        0.4917      0.5667     0.5667\ndt     0.5333       0.65        0.4917      0.5667     0.5667\nrc     0.5083       0.6333      0.4917      0.525      0.525\nnb     0.5          0.625       0.475       0.5        0.4833\nrfc    0.5          0.625       0.4417      0.4917     0.4583\nknn    0.3917       0.6         0.4417      0.4833     0.45\net     0.375        0.5333      0.4333      0.4667     0.45\ndc     0.375        0.5333      0.4333      0.4667     0.425\nqds    0.3417       0.5333      0.4         0.4583     0.3667\nlgt    0.3417       0.525       0.3917      0.45       0.3583\nlt     0.2333       0.45        0.3917      0.4167     0.3417\n</code></pre>\n<p>These are values for respective subcolumns in order specified in the table above</p>\n", "AcceptedAnswerId": 71194341, "AcceptedAnswer": "<p>There's a dirty way to do this, I'll write about it till someone answers with a better idea. Here we go:</p>\n<pre><code>import pandas as pd\n\n# I assume that you can read raw data named test.csv by pandas and\n# set header = None cause you mentioned the Test data without any headers, so:\ndf = pd.read_csv(&quot;test.csv&quot;, header = None)\n\n# Then define preferred Columns! \nMyColumns = pd.MultiIndex.from_tuples([(&quot;Models&quot; , &quot;&quot;),\n                                       (&quot;Accuracy without normalization&quot; , &quot;&quot;),\n                                       (&quot;Accuracy with normalization&quot; , &quot;zscore&quot;),\n                                       (&quot;Accuracy with normalization&quot; , &quot;minmax&quot;),\n                                       (&quot;Accuracy with normalization&quot; , &quot;maxabs&quot;),\n                                       (&quot;Accuracy with normalization&quot; , &quot;robust&quot;)])\n\n# Create new DataFrame with specified Columns, after this you should pass values \nNew_DataFrame = pd.DataFrame(df , columns = MyColumns)\n\n# a loop for passing values\nfor item in range(len(MyColumns)):\n    New_DataFrame.loc[: , MyColumns[item]] = df.iloc[: , item]\n</code></pre>\n<p>This gives me:</p>\n<p><a href=\"https://i.stack.imgur.com/8LmcK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/8LmcK.png\" alt=\"enter image description here\" /></a></p>\n<p>after all, if you want to set <code>Models</code> as the index of <code>New_DataFrame</code>, You can continue with:</p>\n<pre><code>New_DataFrame.set_index(New_DataFrame.columns[0][0] , inplace=True)\nNew_DataFrame\n</code></pre>\n<p>This gives me:</p>\n<p><a href=\"https://i.stack.imgur.com/PuF9d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/PuF9d.png\" alt=\"enter image description here\" /></a></p>\n"}
{"Id": 71758114, "PostTypeId": 1, "Title": "Python list comprehension with complex data structures", "Body": "<p>I'm trying to flatten some mixed arrays in Python using LC. I'm having some trouble figuring out how to structure it.</p>\n<p>Here's the array's i'm trying to flatten</p>\n<pre><code>arr_1 = [1, [2, 3], 4, 5]\narr_2 = [1,[2,3],[[4,5]]]\n</code></pre>\n<p>I tried this methods for arr_1 but get &quot;TypeError: 'int' object is not iterable&quot;</p>\n<pre><code>print([item if type(items) is list else items for items in arr_1 for item in items])\n</code></pre>\n<p>So I decided to break it into parts to see where it's failing by using this</p>\n<pre><code>def check(item):\nreturn item;\n\nprint([check(item) if type(items) is list else check(items) for items in [1, [2, 3], 4, 5] for items in arr_2]) \n</code></pre>\n<p>Through the debugger I found that it's failing at the 2d array in</p>\n<pre><code>for items in [1, [2, 3], 4, 5]\n</code></pre>\n<p>I don't need the LC to be in one line but I just wanted to know how to do it in a single nested LC if its even possible.</p>\n", "AcceptedAnswerId": 71758467, "AcceptedAnswer": "<p>Using an internal stack and <a href=\"https://docs.python.org/3/library/functions.html#iter\" rel=\"nofollow noreferrer\"><code>iter</code></a>'s second form to simulate a <code>while</code> loop:</p>\n<pre><code>def flatten(obj):\n    return [x\n            for stack in [[obj]]\n            for x, in iter(lambda: stack and [stack.pop()], [])\n            if isinstance(x, int)\n            or stack.extend(reversed(x))]\n\nprint(flatten([1, [2, 3], 4, 5]))\nprint(flatten([1, [2, 3], [[4, 5]]]))\nprint(flatten([1, [2, [], 3], [[4, 5]]]))\n</code></pre>\n<p>Output (<a href=\"https://tio.run/##fY/BCsIwDIbve4ocWyiCTkH2KqGHbk2xOrvSValPX2txhzH0PyXk@/Mn/hUvk2vPPuSsyYAZVYzk2NRfeddAUaD4CA4w1W6RmQLMUQ03sGWGBZdyAyTxmdpIgY3q3mvVfT3KacBa7vzkGZcCUPKV3xqws3UFcgOxuimuieWCHaVysWaBnhRm0ixxLpvGh@Jgyz@4LxEHAW2JOgo4Sc7/EIiVkb8plBsy5zc\" rel=\"nofollow noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a>):</p>\n<pre><code>[1, 2, 3, 4, 5]\n[1, 2, 3, 4, 5]\n[1, 2, 3, 4, 5]\n</code></pre>\n<p>Slight variation, splitting the &quot;long&quot; line into two (<a href=\"https://tio.run/##fY/NCsIwEITvfYo9JhAKWgXpq4Qg/dlitCZhGyU@fVwrPZSic1vmm2EnvOLFu@oUKOceBxjGJkZ0wrdXWRfAIowPcqDTfC0aPMEUm@4Glj3NuDEb4PwxbUQSY3Nv@6b@RhRoIzdwmptmoAw@CLnuswPYyTr2XYciKabjumT5qMTEC3pB@ESasBdJclcRiBNi2ad3/MVeQWUUHBQcjZR/CK1nxvymtNmQOb8B\" rel=\"nofollow noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a>):</p>\n<pre><code>def flatten(obj):\n    return [x\n            for stack in [[obj]]\n            for _ in iter(lambda: stack, [])\n            for x in [stack.pop()]\n            if isinstance(x, int)\n            or stack.extend(reversed(x))]\n</code></pre>\n<p>To explain it a bit, here's roughly the same with ordinary code:</p>\n<pre><code>def flatten(obj):\n    result = []\n    stack = [obj]\n    while stack:\n        x = stack.pop()\n        if isinstance(x, int):\n            result.append(x)\n        else:\n            stack.extend(reversed(x))\n    return result\n</code></pre>\n<p>If the order doesn't matter, we can use a queue instead (inspired by 0x263A's comment), although it's less memory-efficient (<a href=\"https://tio.run/##fc7BCgIhEAbg@z7FHBUkqC2IXmWYw9aOZISaq@A@vZngIZb6b8P/Mfx@jXdnx7MPpcysQT@nGNkKd33IywA1gWMKFjC3q0e7AK/EicHUDisn2oD8KZv6qowGsxi7xMneWGRVVZTQH@441wGzyJKGwYfaiT4K9wrwoGAkBUcFJ5Lyj0Bshn4rpI0s5Q0\" rel=\"nofollow noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a>):</p>\n<pre><code>def flatten(obj):\n    return [x\n            for queue in [[obj]]\n            for x in queue\n            if isinstance(x, int) or queue.extend(x)]\n</code></pre>\n<p>We can fix the order if instead of putting each list's contents at the <em>end</em> of the queue, we <em>insert</em> them right <em>after</em> the list (which is less time-efficient) in the &quot;priority&quot; queue (<a href=\"https://tio.run/##fc7BCsIwDAbg@54ixxaKMKcgvkopZWqKla2bbQrz6WucTJChuYV8f5LxQdchNIcxlnJBB65riTCI4XSTxwq4IlKOAfQ0d0u5IcJ4z5gRPA81e2NWwiuYXnMMucfYEop3RkEtv7B34JMPidpwRjEpDpGEz42NtQnJE/bWitR5NrzaS14vTVWNkblYXte1Ar1V0BgFOwV7I@UfofVszG@lzUqW8gQ\" rel=\"nofollow noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a>):</p>\n<pre><code>def flatten(obj):\n    return [x\n            for pqueue in [[obj]]\n            for i, x in enumerate(pqueue, 1)\n            if isinstance(x, int) or pqueue.__setitem__(slice(i, i), x)]\n</code></pre>\n"}
{"Id": 71079342, "PostTypeId": 1, "Title": "How can I take comma separated inputs for python AnyTree module?", "Body": "<p><strong>Community</strong>. I need to accept multiple comma-separated inputs to produce a summary of information ( specifically, how many different employees participated in each group/project)? The program takes employees, managers and groups in the form of strings.</p>\n<p>I'm using anytree python library to be able to search/count the occurrence of each employee per group. However, this program is only accepting one value/cell at a time instead of multiple values. <br></p>\n<p><strong>Here is the tree structure and how I accept input values?</strong></p>\n<pre><code>Press q to exit, Enter your data: Joe\nPress q to exit, Enter your data: Manager1\nPress q to exit, Enter your data: Group1\nPress q to exit, Enter your data: Charles \nPress q to exit, Enter your data: Manager1\nPress q to exit, Enter your data: Group2\nPress q to exit, Enter your data: Joe\nPress q to exit, Enter your data: Manager3\nPress q to exit, Enter your data: Group1\nPress q to exit, Enter your data: Charles\nPress q to exit, Enter your data: Manager3\nPress q to exit, Enter your data: Group1\nPress q to exit, Enter your data: Joe\nPress q to exit, Enter your data: Manager5\nPress q to exit, Enter your data: Group2\nPress q to exit, Enter your data: q\nEmployee   No of groups\n   JOE       2\n   CHARLES       2\nGroup\n\u251c\u2500\u2500 GROUP1\n\u2502   \u251c\u2500\u2500 JOE\n\u2502   \u2502   \u2514\u2500\u2500 MANAGER1\n\u2502   \u251c\u2500\u2500 JOE\n\u2502   \u2502   \u2514\u2500\u2500 MANAGER3\n\u2502   \u2514\u2500\u2500 CHARLES\n\u2502       \u2514\u2500\u2500 MANAGER3\n\u2514\u2500\u2500 GROUP2\n    \u251c\u2500\u2500 CHARLES\n    \u2502   \u2514\u2500\u2500 MANAGER1\n    \u2514\u2500\u2500 JOE\n        \u2514\u2500\u2500 MANAGER5\n</code></pre>\n<p>I need help with this code so that It can accept comma-separated values; for example, to enter <strong>Joe, Manager1, Group1</strong> at a time.</p>\n<pre><code>import anytree\n\nfrom anytree import Node, RenderTree, LevelOrderIter, LevelOrderGroupIter, PreOrderIter\n\nimport sys\n\n# user input\nio=''\nlst_input = []\nwhile (io!='q'):\n    io=input('Press q to exit, Enter your data: ')\n    if io!='q':\n        lst_input.append(io.upper())\n\n# change list in to matrix\nlst=[]\nfor i in range(0, len(lst_input), 3):\n    lst.append(lst_input[i:i + 3])\n\nlst\n\n# create tree structure from lst\ngroup = Node('Group')\nstoreGroup = {}\nfor i in range(len(lst)):\n    if lst[i][2] in [x.name for x in group.children]: # parent already exist, append childrens\n        storeGroup[lst[i][0]] = Node(lst[i][0], parent=storeGroup[lst[i][2]])\n        storeGroup[lst[i][1]] = Node(lst[i][1], parent=storeGroup[lst[i][0]])\n    else: # create parent and append childreds\n        storeGroup[lst[i][2]] = Node(lst[i][2], parent=group)\n        storeGroup[lst[i][0]] = Node(lst[i][0], parent=storeGroup[lst[i][2]])\n        storeGroup[lst[i][1]] = Node(lst[i][1], parent=storeGroup[lst[i][0]])\n\n\nstore = {}\nfor children in LevelOrderIter(group, maxlevel=3):\n    if children.parent!=None and children.parent.name!='Group':\n        if children.name not in store:\n            store[children.name] = {children.parent.name}\n        else:\n            store[children.name] = store[children.name] | {children.parent.name}\n\nprint('Employee', '  No of groups')\nfor i in store:\n    print('   '+i+'      ', len(store[i]))\n\n\nfor pre,fill, node in RenderTree(group):\n    print('{}{}'.format(pre,node.name))\n</code></pre>\n<p><br> Thank you! Any thoughts are welcomed.</p>\n", "AcceptedAnswerId": 71110010, "AcceptedAnswer": "<p>Leverage unpacking to extract elements. Then the if statement can be re-written this way.</p>\n<pre><code>if io!='q':\n    name, role, grp = io.upper(). split(',')\n    lst_input.append([name,role, grp]) \n</code></pre>\n<p>you also need to change <code>lst.append(lst_input[i:i + 3])</code> in the for loop to this.</p>\n<pre><code>lst.append(lst_input[0][i:i + 3])\n</code></pre>\n"}
{"Id": 71295840, "PostTypeId": 1, "Title": "python pip: \"error: legacy-install-failure\"", "Body": "<p>I want to install <code>gensim</code> python package via <code>pip install gensim</code></p>\n<p>But this error occurs and I have no idea what should I do to solve it.</p>\n<pre><code>      running build_ext\n      building 'gensim.models.word2vec_inner' extension\n      error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: legacy-install-failure\n\n\u00d7 Encountered error while trying to install package.\n\u2570\u2500&gt; gensim\n\nnote: This is an issue with the package mentioned above, not pip.\nhint: See above for output from the failure.\n</code></pre>\n", "AcceptedAnswerId": 71296224, "AcceptedAnswer": "<p>If you fail to install plugins,<br />\nyou can download it from other repositories like this one:\n<a href=\"https://www.lfd.uci.edu/%7Egohlke/pythonlibs/#gensim\" rel=\"noreferrer\">repository</a> depends on the version of python and the system.</p>\n<p>for example: for  windows 11(x64) and python 3.10 you should take this file: <em><strong>gensim\u20114.1.2\u2011cp310\u2011cp310\u2011win_amd64.whl</strong></em></p>\n"}
{"Id": 71297077, "PostTypeId": 1, "Title": "Python regex replace every 2nd occurrence in a string", "Body": "<p>I have a string with data that looks like this:</p>\n<pre><code>str1 = &quot;[2.4],[5],[2.54],[4],[3.36],[4.46],[3.36],[4],[3.63],[4.86],[4],[4.63]&quot;\n</code></pre>\n<p>I would want to replace every second iteration of <code>&quot;],[&quot;</code> with <code>&quot;,&quot;</code> so it will look like this:</p>\n<pre><code>str2 = &quot;[2.4,5],[2.54,4],[3.36,4.46],[3.36,4],[3.63,4.86],[4,4.63]&quot;\n</code></pre>\n<p>Here is was I have so far:</p>\n<pre><code>str1 = &quot;[2.4],[5],[2.54],[4],[3.36],[4.46],[3.36],[4],[3.63],[4.86],[4],[4.63]&quot;\ns2 = re.sub(r&quot;],\\[&quot;, ',', str1)\nprint(s2)\n</code></pre>\n<p>I was trying to mess around with this:</p>\n<pre><code>(.*?],\\[){2}\n</code></pre>\n<p>But it does not seem to yield me the desired results.</p>\n<p>I tried using loops but I only managed to replace only the second occurrence and nothing after using this sample code I found <a href=\"https://stackoverflow.com/a/35091558/14951530\">here</a>. And the code is:</p>\n<pre><code>import re\n\ndef replacenth(string, sub, wanted, n):\n    where = [m.start() for m in re.finditer(sub, string)][n-1]\n    before = string[:where]\n    after = string[where:]\n    after = after.replace(sub, wanted, 1)\n    newString = before + after\n    print(newString)\nFor these variables:\n\nstring = 'ababababababababab'\nsub = 'ab'\nwanted = 'CD'\nn = 5\n</code></pre>\n<p>Thank you.</p>\n", "AcceptedAnswerId": 71297176, "AcceptedAnswer": "<p>You can use</p>\n<pre class=\"lang-py prettyprint-override\"><code>import re\nfrom itertools import count\n\nstr1 = &quot;[2.4],[5],[2.54],[4],[3.36],[4.46],[3.36],[4],[3.63],[4.86],[4],[4.63]&quot;\nc = count(0)\nprint( re.sub(r&quot;],\\[&quot;, lambda x: &quot;,&quot; if next(c) % 2 == 0 else x.group(), str1) )\n# =&gt; [2.4,5],[2.54,4],[3.36,4.46],[3.36,4],[3.63,4.86],[4,4.63]\n</code></pre>\n<p>See <a href=\"https://ideone.com/hkUxDV\" rel=\"noreferrer\">the Python demo</a>.</p>\n<p>The regex is the same, <code>],\\[</code>, it matches a literal <code>],[</code> text.</p>\n<p>The <code>c = count(0)</code>  initializes the counter whose value is incremented upon each match inside a lambda expression used as the replacement argument. When the  counter is even, the match is replaced with a comma, else, it is kept as is.</p>\n"}
{"Id": 71805426, "PostTypeId": 1, "Title": "how to tell a python type checker that an optional definitely exists?", "Body": "<p>I'm used to typescript, in which one can use a <code>!</code> to tell the type-checker to assume a value won't be null. Is there something analogous when using type annotations in python?</p>\n<p>A (contrived) example:</p>\n<p>When executing the expression <code>m.maybe_num + 3</code> in the code below, the enclosing <code>if</code> guarantees that <code>maybe_num</code> won't be <code>None</code>.  But the type-checker doesn't know that, and returns an error.  (Verified in <a href=\"https://mypy-play.net/?mypy=latest&amp;python=3.10.\" rel=\"noreferrer\">https://mypy-play.net/?mypy=latest&amp;python=3.10.</a>) How can I tell the type-checker that I know better?</p>\n<pre class=\"lang-py prettyprint-override\"><code>from typing import Optional\n\nclass MyClass:\n\n    def __init__(self, maybe_num: Optional[int]):\n        self.maybe_num = maybe_num\n        \n    def has_a_num(self) -&gt; bool:\n        return self.maybe_num is not None\n\n    def three_more(self) -&gt; Optional[int]:\n        if self.has_a_num:\n            # mypy error: Unsupported operand types for + (&quot;None&quot; and &quot;int&quot;)\n            return self.maybe_num + 3\n        else:\n            return None\n</code></pre>\n", "AcceptedAnswerId": 71806921, "AcceptedAnswer": "<p>Sadly there's no clean way to infer the type of something from a function call like this, but you can work some magic with <a href=\"https://docs.python.org/3/library/typing.html#typing.TypeGuard\" rel=\"nofollow noreferrer\"><code>TypeGuard</code></a> annotations for the <code>has_a_num()</code> method, although the benefit from those annotations won't really be felt unless the difference is significantly more major than the type of a single int. If it's just a single value, you should just use a standard  is not None check.</p>\n<pre class=\"lang-py prettyprint-override\"><code>if self.maybe_num is not None:\n    ...\n</code></pre>\n<p>You can define a subclass of your primary subclass, where the types of any parameters whose types are affected are explicitly redeclared.</p>\n<pre class=\"lang-py prettyprint-override\"><code>class MyIntClass(MyClass):\n    maybe_num: int\n</code></pre>\n<p>From there, your checker function should still return a boolean, but the annotated return type tells MyPy that it should use it for type narrowing to the listed type.</p>\n<p>Sadly it will only do this for proper function parameters, rather than the implicit <code>self</code> argument, but this can be fixed easily enough by providing self explicitly as follows:</p>\n<pre class=\"lang-py prettyprint-override\"><code>if MyClass.has_a_num(self):\n    ...\n</code></pre>\n<p>That syntax is yucky, but it works with MyPy.</p>\n<p>This makes the full solution be as follows</p>\n<pre class=\"lang-py prettyprint-override\"><code># Parse type annotations as strings to avoid \n# circular class references\nfrom __future__ import annotations\nfrom typing import Optional, TypeGuard\n\nclass MyClass:\n    def __init__(self, maybe_num: Optional[int]):\n        self.maybe_num = maybe_num\n\n    def has_a_num(self) -&gt; TypeGuard[_MyClass_Int]:\n        # This annotation defines a type-narrowing operation,\n        # such that if the return value is True, then self\n        # is (from MyPy's perspective) _MyClass_Int, and \n        # otherwise it isn't\n        return self.maybe_num is not None\n\n    def three_more(self) -&gt; Optional[int]:\n        if MyClass.has_a_num(self):\n            # No more mypy error\n            return self.maybe_num + 3\n        else:\n            return None\n\nclass _MyClass_Int(MyClass):\n    maybe_num: int\n</code></pre>\n<p><code>TypeGuard</code> was added in Python 3.10, but can be used in earlier versions using the <a href=\"https://pypi.org/project/typing-extensions/\" rel=\"nofollow noreferrer\"><code>typing_extensions</code></a> module from <code>pip</code>.</p>\n"}
{"Id": 71232879, "PostTypeId": 1, "Title": "How to speed up async requests in Python", "Body": "<p>I want to download/scrape 50 million log records from a site. Instead of downloading 50 million in one go, I was trying to download it in parts like 10 million at a time using the following code but it's only handling 20,000 at a time (more than that throws an error) so it becomes time-consuming to download that much data. Currently, it takes 3-4 mins to download 20,000 records with the speed of <code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20000/20000 [03:48&lt;00:00, 87.41it/s]</code> so how to speed it up?</p>\n<pre><code>import asyncio\nimport aiohttp\nimport time\nimport tqdm\nimport nest_asyncio\n\nnest_asyncio.apply()\n\n\nasync def make_numbers(numbers, _numbers):\n    for i in range(numbers, _numbers):\n        yield i\n\n\nn = 0\nq = 10000000\n\n\nasync def fetch():\n    # example\n    url = &quot;https://httpbin.org/anything/log?id=&quot;\n\n    async with aiohttp.ClientSession() as session:\n        post_tasks = []\n        # prepare the coroutines that poat\n        async for x in make_numbers(n, q):\n            post_tasks.append(do_get(session, url, x))\n        # now execute them all at once\n\n        responses = [await f for f in tqdm.tqdm(asyncio.as_completed(post_tasks), total=len(post_tasks))]\n\n\nasync def do_get(session, url, x):\n    headers = {\n        'Content-Type': &quot;application/x-www-form-urlencoded&quot;,\n        'Access-Control-Allow-Origin': &quot;*&quot;,\n        'Accept-Encoding': &quot;gzip, deflate&quot;,\n        'Accept-Language': &quot;en-US&quot;\n    }\n\n    async with session.get(url + str(x), headers=headers) as response:\n        data = await response.text()\n        print(data)\n\n\ns = time.perf_counter()\ntry:\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(fetch())\nexcept:\n    print(&quot;error&quot;)\n\nelapsed = time.perf_counter() - s\n# print(f&quot;{__file__} executed in {elapsed:0.2f} seconds.&quot;)\n</code></pre>\n<p>Traceback (most recent call last):</p>\n<pre><code>File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 986, in _wrap_create_connection\n    return await self._loop.create_connection(*args, **kwargs)  # type: ignore[return-value]  # noqa\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py&quot;, line 1056, in create_connection\n    raise exceptions[0]\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py&quot;, line 1041, in create_connection\n    sock = await self._connect_sock(\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py&quot;, line 955, in _connect_sock\n    await self.sock_connect(sock, address)\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\proactor_events.py&quot;, line 702, in sock_connect\n    return await self._proactor.connect(sock, address)\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\tasks.py&quot;, line 328, in __wakeup\n    future.result()\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\windows_events.py&quot;, line 812, in _poll\n    value = callback(transferred, key, ov)\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\windows_events.py&quot;, line 599, in finish_connect\n    ov.getresult()\nOSError: [WinError 121] The semaphore timeout period has expired\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\SGM\\Desktop\\xnet\\x3stackoverflow.py&quot;, line 136, in &lt;module&gt;\n    loop.run_until_complete(fetch())\n  File &quot;C:\\Users\\SGM\\AppData\\Roaming\\Python\\Python39\\site-packages\\nest_asyncio.py&quot;, line 81, in run_until_complete\n    return f.result()\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\futures.py&quot;, line 201, in result\n    raise self._exception\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\tasks.py&quot;, line 256, in __step\n    result = coro.send(None)\n  File &quot;C:\\Users\\SGM\\Desktop\\xnet\\x3stackoverflow.py&quot;, line 88, in fetch\n    response = await f\n  File &quot;C:\\Users\\SGM\\Desktop\\xnet\\x3stackoverflow.py&quot;, line 37, in _wait_for_one\n    return f.result()\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\futures.py&quot;, line 201, in result\n    raise self._exception\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\tasks.py&quot;, line 258, in __step\n    result = coro.throw(exc)\n  File &quot;C:\\Users\\SGM\\Desktop\\xnet\\x3stackoverflow.py&quot;, line 125, in do_get\n    async with session.get(url + str(x), headers=headers) as response:\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\client.py&quot;, line 1138, in __aenter__\n    self._resp = await self._coro\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\client.py&quot;, line 535, in _request\n    conn = await self._connector.connect(\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 542, in connect\n    proto = await self._create_connection(req, traces, timeout)\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 907, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 1206, in _create_direct_connection\n    raise last_exc\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 1175, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n  File &quot;C:\\Users\\SGM\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\aiohttp\\connector.py&quot;, line 992, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host example.com:80 ssl:default [The semaphore timeout period has expired]\n</code></pre>\n", "AcceptedAnswerId": 71285322, "AcceptedAnswer": "<h1>Bottleneck: number of simultaneous connections</h1>\n<p>First, the bottleneck is the total number of simultaneous connections in the TCP connector.</p>\n<p>That default for <code>aiohttp.TCPConnector</code> is <code>limit=100</code>. On most systems (tested on macOS), you should be able to double that by passing a <code>connector</code> with <code>limit=200</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code># async with aiohttp.ClientSession() as session:\nasync with aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit=200)) as session:\n</code></pre>\n<p>The time taken should decrease significantly. (On macOS: <code>q = 20_000</code> decreased 43% from 58 seconds to 33 seconds, and <code>q = 10_000</code> decreased 42% from 31 to 18 seconds.)</p>\n<p>The <code>limit</code> you can configure depends on the number of file descriptors that your machine can open. (On macOS: You can run <code>ulimit -n</code> to check, and <code>ulimit -n 1024</code> to increase to 1024 for the current terminal session, and then change to <code>limit=1000</code>. Compared to <code>limit=100</code>, <code>q = 20_000</code> decreased 76% to 14 seconds, and <code>q = 10_000</code> decreased 71% to 9 seconds.)</p>\n<h1>Supporting 50 million requests: async generators</h1>\n<p>Next, the reason why 50 million requests appears to hang is simply because of its sheer number.</p>\n<p>Just creating 10 million coroutines in <code>post_tasks</code> takes 68-98 seconds (varies greatly on my machine), and then the event loop is further burdened with that many tasks, 99.99% of which are blocked by the TCP connection pool.</p>\n<p>We can defer the creation of coroutines using an async generator:</p>\n<pre class=\"lang-py prettyprint-override\"><code>async def make_async_gen(f, n, q):\n    async for x in make_numbers(n, q):\n        yield f(x)\n</code></pre>\n<p>We need a counterpart to <code>asyncio.as_completed()</code> to handle <code>async_gen</code> and <code>concurrency</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from asyncio import ensure_future, events\nfrom asyncio.queues import Queue\n\ndef as_completed_for_async_gen(fs_async_gen, concurrency):\n    done = Queue()\n    loop = events.get_event_loop()\n    # todo = {ensure_future(f, loop=loop) for f in set(fs)}  # -\n    todo = set()                                             # +\n\n    def _on_completion(f):\n        todo.remove(f)\n        done.put_nowait(f)\n        loop.create_task(_add_next())  # +\n\n    async def _wait_for_one():\n        f = await done.get()\n        return f.result()\n\n    async def _add_next():  # +\n        try:\n            f = await fs_async_gen.__anext__()\n        except StopAsyncIteration:\n            return\n        f = ensure_future(f, loop=loop)\n        f.add_done_callback(_on_completion)\n        todo.add(f)\n\n    # for f in todo:                           # -\n    #     f.add_done_callback(_on_completion)  # -\n    # for _ in range(len(todo)):               # -\n    #     yield _wait_for_one()                # -\n    for _ in range(concurrency):               # +\n        loop.run_until_complete(_add_next())   # +\n    while todo:                                # +\n        yield _wait_for_one()                  # +\n</code></pre>\n<p>Then, we update <code>fetch()</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from functools import partial\n\nCONCURRENCY = 200  # +\n\nn = 0\nq = 50_000_000\n\nasync def fetch():\n    # example\n    url = &quot;https://httpbin.org/anything/log?id=&quot;\n\n    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit=CONCURRENCY)) as session:\n        # post_tasks = []                                                # -\n        # # prepare the coroutines that post                             # -\n        # async for x in make_numbers(n, q):                             # -\n        #     post_tasks.append(do_get(session, url, x))                 # -\n        # Prepare the coroutines generator                               # +\n        async_gen = make_async_gen(partial(do_get, session, url), n, q)  # +\n\n        # now execute them all at once                                                                         # -\n        # responses = [await f for f in tqdm.asyncio.tqdm.as_completed(post_tasks, total=len(post_tasks))]     # -\n        # Now execute them with a specified concurrency                                                        # +\n        responses = [await f for f in tqdm.tqdm(as_completed_for_async_gen(async_gen, CONCURRENCY), total=q)]  # +\n</code></pre>\n<h1>Other limitations</h1>\n<p>With the above, the program can <em>start</em> processing 50 million requests but:</p>\n<ol>\n<li>it will still take 8 hours or so with <code>CONCURRENCY = 1000</code>, based on the estimate from <code>tqdm</code>.</li>\n<li>your program may run out of memory for <code>responses</code> and crash.</li>\n</ol>\n<p>For point 2, you should probably do:</p>\n<pre class=\"lang-py prettyprint-override\"><code># responses = [await f for f in tqdm.tqdm(as_completed_for_async_gen(async_gen, CONCURRENCY), total=q)]\nfor f in tqdm.tqdm(as_completed_for_async_gen(async_gen, CONCURRENCY), total=q):\n    response = await f\n    \n    # Do something with response, such as writing to a local file\n    # ...\n</code></pre>\n<hr />\n<h1>An error in the code</h1>\n<p><code>do_get()</code> should <code>return data</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>async def do_get(session, url, x):\n    headers = {\n        'Content-Type': &quot;application/x-www-form-urlencoded&quot;,\n        'Access-Control-Allow-Origin': &quot;*&quot;,\n        'Accept-Encoding': &quot;gzip, deflate&quot;,\n        'Accept-Language': &quot;en-US&quot;\n    }\n\n    async with session.get(url + str(x), headers=headers) as response:\n        data = await response.text()\n        # print(data)  # -\n        return data    # +\n</code></pre>\n"}
{"Id": 71343002, "PostTypeId": 1, "Title": "Downloading files from public Google Drive in python: scoping issues?", "Body": "<p>Using my answer to <a href=\"https://stackoverflow.com/questions/68270332/automatically-download-large-files-in-public-gdrive-folder\">my question</a> on how to download files from a public Google drive I managed in the past to download images using their IDs from a python script and Google API v3 from a public drive using the following bock of code:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from google_auth_oauthlib.flow import Flow, InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\nfrom google.auth.transport.requests import Request\nimport io\nimport re\nSCOPES = ['https://www.googleapis.com/auth/drive']\nCLIENT_SECRET_FILE = &quot;myjson.json&quot;\nauthorized_port = 6006 # authorize URI redirect on the console\nflow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\ncred = flow.run_local_server(port=authorized_port)\ndrive_service = build(&quot;drive&quot;, &quot;v3&quot;, credentials=cred)\nregex = &quot;(?&lt;=https://drive.google.com/file/d/)[a-zA-Z0-9]+&quot;\nfor i, l in enumerate(links_to_download):\n    url = l\n    file_id = re.search(regex, url)[0]\n    request = drive_service.files().get_media(fileId=file_id)\n    fh = io.FileIO(f&quot;file_{i}&quot;, mode='wb')\n    downloader = MediaIoBaseDownload(fh, request)\n    done = False\n    while done is False:\n        status, done = downloader.next_chunk()\n        print(&quot;Download %d%%.&quot; % int(status.progress() * 100))\n</code></pre>\n<p>In the mean time I discovered <a href=\"https://github.com/googlearchive/PyDrive\" rel=\"nofollow noreferrer\">pydrive</a> and <a href=\"https://github.com/iterative/PyDrive2\" rel=\"nofollow noreferrer\">pydrive2</a>, two wrappers around Google API v2 that allows to do very useful things such as listing files from folders and basically allows to do the same thing with a lighter syntax:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nimport io\nimport re\nCLIENT_SECRET_FILE = &quot;client_secrets.json&quot;\n\ngauth = GoogleAuth()\ngauth.LocalWebserverAuth()\ndrive = GoogleDrive(gauth)\nregex = &quot;(?&lt;=https://drive.google.com/file/d/)[a-zA-Z0-9]+&quot;\nfor i, l in enumerate(links_to_download):\n    url = l\n    file_id = re.search(regex, url)[0]\n    file_handle = drive.CreateFile({'id': file_id})\n    file_handle.GetContentFile(f&quot;file_{i}&quot;)\n</code></pre>\n<p>However now whether I use pydrive or the raw API <strong>I cannot seem to be able to download the same files</strong> and instead I am met with:</p>\n<pre><code>googleapiclient.errors.HttpError: &lt;HttpError 404 when requesting https://www.googleapis.com/drive/v3/files/fileID?alt=media returned &quot;File not found: fileID.&quot;. Details: &quot;[{'domain': 'global', 'reason': 'notFound', 'message': 'File not found: fileID.', 'locationType': 'parameter', 'location': 'fileId'}]&quot;&gt;\n</code></pre>\n<p>I tried everything and registered 3 different apps using Google console it seems it might be (or not) a question of scoping (see for instance <a href=\"https://stackoverflow.com/a/54492150/4844184\">this answer</a>, with apps having access to only files in my Google drive or created by this app). However I did not have this issue before (last year).</p>\n<p>When going to the <a href=\"https://console.cloud.google.com/apis/credentials/consent?authuser=1\" rel=\"nofollow noreferrer\">Google console</a> explicitly giving <code>https://www.googleapis.com/auth/drive</code> as a scope to the API mandates filling a ton of fields with application's website/conditions of use/confidentiality rules/authorized domains and youtube videos explaining the app. However I will be the sole user of this script.\nSo I could only give explicitly the following scopes:</p>\n<pre><code>/auth/drive.appdata\n/auth/drive.file\n/auth/drive.install\n</code></pre>\n<p>Is it because of scoping ? Is there a solution that doesn't require creating a homepage and a youtube video ?</p>\n<p><strong>EDIT 1:</strong>\nHere is an example of <code>links_to_download</code>:</p>\n<pre><code>links_to_download = [&quot;https://drive.google.com/file/d/fileID/view?usp=drivesdk&amp;resourcekey=0-resourceKeyValue&quot;]\n</code></pre>\n<p><strong>EDIT 2:</strong>\nIt is super instable sometimes it works without a sweat sometimes it doesn't. When I relaunch the script multiple times I get different results. Retry policies are working to a certain extent but sometimes it fails multiple times for hours.</p>\n", "AcceptedAnswerId": 71351780, "AcceptedAnswer": "<p>Well thanks to the <a href=\"https://support.google.com/drive/answer/10729743?hl=en\" rel=\"nofollow noreferrer\">security update</a> released by Google few months before. This makes the link sharing stricter and you need resource key as well to access the file in-addition to the <code>fileId</code>.</p>\n<p>As per the <a href=\"https://developers.google.com/drive/api/v3/resource-keys#syntax\" rel=\"nofollow noreferrer\">documentation</a> , You need to provide the resource key as well for newer links, if you want to access it in the header <code>X-Goog-Drive-Resource-Keys</code> as <code>fileId1/resourceKey1</code>.</p>\n<p>If you apply this change in your code, it will work as normal. Example edit below:</p>\n<pre><code>regex = &quot;(?&lt;=https://drive.google.com/file/d/)[a-zA-Z0-9]+&quot;\nregex_rkey = &quot;(?&lt;=resourcekey=)[a-zA-Z0-9-]+&quot;\nfor i, l in enumerate(links_to_download):\n    url = l\n    file_id = re.search(regex, url)[0]\n    resource_key = re.search(regex_rkey, url)[0]\n    request = drive_service.files().get_media(fileId=file_id)\n    request.headers[&quot;X-Goog-Drive-Resource-Keys&quot;] = f&quot;{file_id}/{resource_key}&quot;\n    fh = io.FileIO(f&quot;file_{i}&quot;, mode='wb')\n    downloader = MediaIoBaseDownload(fh, request)\n    done = False\n    while done is False:\n        status, done = downloader.next_chunk()\n        print(&quot;Download %d%%.&quot; % int(status.progress() * 100))\n</code></pre>\n<p>Well, the regex for resource key was something I quickly made, so cannot be sure on if it supports every case. But this provides you the solution.\nNow, you may have to listen to old and new links based on this and set the changes.</p>\n"}
{"Id": 71029876, "PostTypeId": 1, "Title": "How can I perform a type guard on a property of an object in Python", "Body": "<p><a href=\"https://www.python.org/dev/peps/pep-0647\" rel=\"noreferrer\">PEP 647</a> introduced type guards to perform complex type narrowing operations using functions. If I have a class where properties can have various types, is there a way that I can perform a similar type narrowing operation on the property of an object given as the function argument?</p>\n<pre class=\"lang-py prettyprint-override\"><code>class MyClass:\n    a: Optional[int]\n    b: Optional[str]\n    # Some other things\n\ndef someTypeGuard(my_obj: MyClass) -&gt; ???:\n    return my_obj.a is not None\n</code></pre>\n<p>I'm thinking it might be necessary for me to implement something to do with square brackets in type hints, but I really don't know where to start on this.</p>\n", "AcceptedAnswerId": 71252167, "AcceptedAnswer": "<p><code>TypeGuard</code> annotations can be used to annotate subclasses of a class. If parameter types are specified for those classes, then MyPy will recognise the type narrowing operation successfully.</p>\n<pre class=\"lang-py prettyprint-override\"><code>class MyClass:\n    a: Optional[int]\n    b: Optional[str]\n    # Some other things\n\n# Two hidden classes for the different types\nclass _MyClassInt(MyClass):\n    a: int\n    b: None\nclass _MyClassStr(MyClass):\n    a: None\n    b: str\n\n\ndef someTypeGuard(my_obj: MyClass) -&gt; TypeGuard[_MyClassInt]:\n    &quot;&quot;&quot;Check if my_obj's `a` property is NOT `None`&quot;&quot;&quot;\n    return my_obj.a is not None\n\ndef someOtherTypeGuard(my_obj: MyClass) -&gt; TypeGuard[_MyClassStr]:\n    &quot;&quot;&quot;Check if my_obj's `b` property is NOT `None`&quot;&quot;&quot;\n    return my_obj.b is not None\n</code></pre>\n<p>Sadly failure to narrow to one type doesn't automatically narrow to the other type, and I can't find an easy way to do this other than an <code>assert someOtherTypeGuard(obj)</code> in your else block.</p>\n<p>Even still this seems to be the best solution.</p>\n"}
{"Id": 71372066, "PostTypeId": 1, "Title": "Docker fails to install cffi with python:3.9-alpine in Dockerfile", "Body": "<p>Im trying to run the below Dockerfile using docker-compose.\nI searched around but I couldnt find a solution on how to install cffi with python:3.9-alpine.</p>\n<p>I also read this post which states that pip 21.2.4 or greater can be a possible solution but it didn't work out form me</p>\n<p><a href=\"https://www.pythonfixing.com/2021/09/fixed-why-i-getting-this-error-while.html\" rel=\"noreferrer\">https://www.pythonfixing.com/2021/09/fixed-why-i-getting-this-error-while.html</a></p>\n<p>Docker file</p>\n<pre><code>FROM python:3.9-alpine\n\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONUNBUFFERED 1\n\nCOPY ./requirements.txt .\n\nRUN apk add --update --no-cache postgresql-client\n\nRUN apk add --update --no-cache --virtual .tmp-build-deps \\\n    gcc libc-dev linux-headers postgresql-dev\nRUN pip3 install --upgrade pip &amp;&amp; pip3 install -r /requirements.txt\n\nRUN apk del .tmp-build-deps\n\nRUN mkdir /app\nWORKDIR /app\nCOPY . /app\n\nRUN adduser -D user\n\nUSER user\n</code></pre>\n<p>This is the requirements.txt file.</p>\n<pre><code>asgiref==3.5.0\nbackports.zoneinfo==0.2.1\ncertifi==2021.10.8\ncffi==1.15.0\ncfgv==3.3.1\n...\n</code></pre>\n<p>Error message:</p>\n<pre><code>process-exited-with-error\n#9 47.99   \n#9 47.99   \u00d7 Running setup.py install for cffi did not run successfully.\n#9 47.99   \u2502 exit code: 1\n#9 47.99   \u2570\u2500&gt; [58 lines of output]\n#9 47.99       Package libffi was not found in the pkg-config search path.\n#9 47.99       Perhaps you should add the directory containing `libffi.pc'\n#9 47.99       to the PKG_CONFIG_PATH environment variable\n#9 47.99       Package 'libffi', required by 'virtual:world', not found\n#9 47.99       Package libffi was not found in the pkg-config search path.\n#9 47.99       Perhaps you should add the directory containing `libffi.pc'\n#9 47.99       to the PKG_CONFIG_PATH environment variable\n#9 47.99       Package 'libffi', required by 'virtual:world', not found\n#9 47.99       Package libffi was not found in the pkg-config search path.\n#9 47.99       Perhaps you should add the directory containing `libffi.pc'\n#9 47.99       to the PKG_CONFIG_PATH environment variable\n#9 47.99       Package 'libffi', required by 'virtual:world', not found\n#9 47.99       Package libffi was not found in the pkg-config search path.\n#9 47.99       Perhaps you should add the directory containing `libffi.pc'\n#9 47.99       to the PKG_CONFIG_PATH environment variable\n#9 47.99       Package 'libffi', required by 'virtual:world', not found\n#9 47.99       Package libffi was not found in the pkg-config search path.\n#9 47.99       Perhaps you should add the directory containing `libffi.pc'\n#9 47.99       to the PKG_CONFIG_PATH environment variable\n#9 47.99       Package 'libffi', required by 'virtual:world', not found\n#9 47.99       running install\n#9 47.99       running build\n#9 47.99       running build_py\n#9 47.99       creating build\n#9 47.99       creating build/lib.linux-aarch64-3.9\n#9 47.99       creating build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/__init__.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/cffi_opcode.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/commontypes.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/vengine_gen.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/vengine_cpy.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/backend_ctypes.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/api.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/ffiplatform.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/verifier.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/error.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/setuptools_ext.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/lock.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/recompiler.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/pkgconfig.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/cparser.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/model.py -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/_cffi_include.h -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/parse_c_type.h -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/_embedding.h -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       copying cffi/_cffi_errors.h -&gt; build/lib.linux-aarch64-3.9/cffi\n#9 47.99       warning: build_py: byte-compiling is disabled, skipping.\n#9 47.99       \n#9 47.99       running build_ext\n#9 47.99       building '_cffi_backend' extension\n#9 47.99       creating build/temp.linux-aarch64-3.9\n#9 47.99       creating build/temp.linux-aarch64-3.9/c\n#9 47.99       gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -DTHREAD_STACK_SIZE=0x100000 -fPIC -DUSE__THREAD -DHAVE_SYNC_SYNCHRONIZE -I/usr/include/ffi -I/usr/include/libffi -I/usr/local/include/python3.9 -c c/_cffi_backend.c -o build/temp.linux-aarch64-3.9/c/_cffi_backend.o\n#9 47.99       c/_cffi_backend.c:15:10: fatal error: ffi.h: No such file or directory\n#9 47.99          15 | #include &lt;ffi.h&gt;\n#9 47.99             |          ^~~~~~~\n#9 47.99       compilation terminated.\n#9 47.99       error: command '/usr/bin/gcc' failed with exit code 1\n#9 47.99       [end of output]\n#9 47.99   \n#9 47.99   note: This error originates from a subprocess, and is likely not a problem with pip.\n#9 47.99 error: legacy-install-failure\n#9 47.99 \n#9 47.99 \u00d7 Encountered error while trying to install package.\n#9 47.99 \u2570\u2500&gt; cffi\n#9 47.99 \n#9 47.99 note: This is an issue with the package mentioned above, not pip.\n#9 47.99 hint: See above for output from the failure.\n</code></pre>\n", "AcceptedAnswerId": 71372163, "AcceptedAnswer": "<p>@Klaus D.'s comment helped a lot.\nI updated Dockerfile:</p>\n<pre><code>RUN apk add --update --no-cache --virtual .tmp-build-deps \\\n    gcc libc-dev linux-headers postgresql-dev \\\n    &amp;&amp; apk add libffi-dev\n</code></pre>\n"}
{"Id": 71938799, "PostTypeId": 1, "Title": "Python asyncio.create_task() - really need to keep a reference?", "Body": "<p>The documentation of <code>asyncio.create_task()</code> states the following warning:</p>\n<blockquote>\n<p><strong>Important</strong>: Save a reference to the result of this function, to avoid a task disappearing mid execution. <a href=\"https://docs.python.org/3.10/library/asyncio-task.html#asyncio.create_task\" rel=\"noreferrer\">(source)</a></p>\n</blockquote>\n<p>My question is: Is this really true?</p>\n<p>I have several IO bound &quot;fire and forget&quot; tasks which I want to run concurrently using <code>asyncio</code> by submitting them to the event loop using <code>asyncio.create_task()</code>. However, I do not really care for the return value of the coroutine or even if they run successfully, only that they <em>do</em> run eventually. One use case is writing data from an &quot;expensive&quot; calculation back to a Redis data base. If Redis is available, great. If not, oh well, no harm. This is why I do not want/need to <code>await</code> those tasks.</p>\n<p>Here a generic example:</p>\n<pre><code>import asyncio\n\nasync def fire_and_forget_coro():\n    &quot;&quot;&quot;Some random coroutine waiting for IO to complete.&quot;&quot;&quot;\n    print('in fire_and_forget_coro()')\n    await asyncio.sleep(1.0)\n    print('fire_and_forget_coro() done')\n\n\nasync def async_main():\n    &quot;&quot;&quot;Main entry point of asyncio application.&quot;&quot;&quot;\n    print('in async_main()')\n    n = 3\n    for _ in range(n):\n        # create_task() does not block, returns immediately.\n        # Note: We do NOT save a reference to the submitted task here!\n        asyncio.create_task(fire_and_forget_coro(), name='fire_and_forget_coro')\n\n    print('awaiting sleep in async_main()')\n    await asycnio.sleep(2.0) # &lt;-- note this line\n    print('sleeping done in async_main()')\n\n    print('async_main() done.')\n\n    # all references of tasks we *might* have go out of scope when returning from this coroutine!\n    return\n\nif __name__ == '__main__':\n    asyncio.run(async_main())\n</code></pre>\n<p>Output:</p>\n<pre><code>in async_main()\nawaiting sleep in async_main()\nin fire_and_forget_coro()\nin fire_and_forget_coro()\nin fire_and_forget_coro()\nfire_and_forget_coro() done\nfire_and_forget_coro() done\nfire_and_forget_coro() done\nsleeping done in async_main()\nasync_main() done.\n</code></pre>\n<p>When commenting out the <code>await asyncio.sleep()</code> line, we never see <code>fire_and_forget_coro()</code> finish. This is to be expected: When the event loop started with <code>asyncio.run()</code> closes, tasks will not be excecuted anymore. But it appears that as long as the event loop is still running, all tasks will be taken care of, even when I never explicitly created references to them. This seem logical to me, as the event loop itself <em>must</em> have a reference to all scheduled tasks in order to run them. And we can even get them all using <code>asyncio.all_tasks()</code>!</p>\n<p>So, I <em>think</em> I can trust Python to have at least one strong reference to every scheduled tasks as long as the event loop it was submitted to is still running, and thus I do not have to manage references myself. But I would like a second opinion here. Am I right or are there pitfalls I have not yet recognized?</p>\n<p>If I am right, why the explicit warning in the documentation? It is a usual Python thing that stuff is garbage-collected if you do not keep a reference to it. Are there situations where one does not have a running event loop but still some task objects to reference? Maybe when creating an event loop manually (never did this)?</p>\n", "AcceptedAnswerId": 71956673, "AcceptedAnswer": "<p>There is an open issue at the cpython bug tracker at github about this topic I just found:\n<a href=\"https://github.com/python/cpython/issues/88831\" rel=\"noreferrer\">https://github.com/python/cpython/issues/88831</a></p>\n<p>Quote:</p>\n<blockquote>\n<p>asyncio will only keep weak references to alive tasks (in <code>_all_tasks</code>). If a user does not keep a reference to a task and the task is not currently executing or sleeping, the user may get &quot;Task was destroyed but it is pending!&quot;.</p>\n</blockquote>\n<p>So the answer to my question is, unfortunately, yes. One has to keep around a reference to the scheduled task.</p>\n<p>However, the github issue also describes a relatively simple workaround: Keep all running tasks in a <code>set()</code> and add a callback to the task which removes itself from the <code>set()</code> again.</p>\n<pre><code>running_tasks = set()\n# [...]\ntask = asyncio.create_task(some_background_function())\nrunning_tasks.add(task)\ntask.add_done_callback(lambda t: running_tasks.remove(t))\n</code></pre>\n"}
{"Id": 71862398, "PostTypeId": 1, "Title": "Install python 3.6.* on Mac M1", "Body": "<p>I'm trying to run an old app that requires python &lt; 3.7. I'm currently using python 3.9 and need to use multiple versions of python.</p>\n<p>I've installed <code>pyenv-virtualenv</code> and <code>pyenv</code> and successfully installed python 3.7.13. However, when I try to install 3.6.*, I get this:</p>\n<pre><code>$ pyenv install 3.6.13\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.6.13.tar.xz...\n-&gt; https://www.python.org/ftp/python/3.6.13/Python-3.6.13.tar.xz\nInstalling Python-3.6.13...\npython-build: use tcl-tk from homebrew\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\n\nBUILD FAILED (OS X 12.3.1 using python-build 2.2.5-11-gf0f2cdd1)\n\nInspect or clean up the working tree at /var/folders/r5/xz73mp557w30h289rr6trb800000gp/T/python-build.20220413143259.33773\nResults logged to /var/folders/r5/xz73mp557w30h289rr6trb800000gp/T/python-build.20220413143259.33773.log\n\nLast 10 log lines:\nchecking for --with-cxx-main=&lt;compiler&gt;... no\nchecking for clang++... no\nconfigure:\n\n  By default, distutils will build C++ extension modules with &quot;clang++&quot;.\n  If this is not intended, then set CXX on the configure command line.\n  \nchecking for the platform triplet based on compiler characteristics... darwin\nconfigure: error: internal configure error for the platform triplet, please file a bug report\nmake: *** No targets specified and no makefile found.  Stop.\n</code></pre>\n<p>Is there a way to solve this? I've looked and it seems like Mac M1 doesn't allow installing 3.6.*</p>\n", "AcceptedAnswerId": 71957981, "AcceptedAnswer": "<p>Copying from a <a href=\"https://github.com/pyenv/pyenv/issues/1768#issuecomment-1105450096\" rel=\"noreferrer\">GitHub issue</a>.</p>\n<hr />\n<p>I successfully installed Python <code>3.6</code> on an Apple M1 MacBook Pro running Monterey using the following setup. There is probably some things in here that can be removed/refined... but it worked for me!</p>\n<pre class=\"lang-sh prettyprint-override\"><code>#Install Rosetta\n/usr/sbin/softwareupdate --install-rosetta --agree-to-license\n\n# Install x86_64 brew\narch -x86_64 /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;\n\n# Set up x86_64 homebrew and pyenv and temporarily set aliases\nalias brew86=&quot;arch -x86_64 /usr/local/bin/brew&quot;\nalias pyenv86=&quot;arch -x86_64 pyenv&quot;\n\n# Install required packages and flags for building this particular python version through emulation\nbrew86 install pyenv gcc libffi gettext\nexport CPPFLAGS=&quot;-I$(brew86 --prefix libffi)/include -I$(brew86 --prefix openssl)/include -I$(brew86 --prefix readline)/lib&quot;\nexport CFLAGS=&quot;-I$(brew86 --prefix openssl)/include -I$(brew86 --prefix bzip2)/include -I$(brew86 --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include -Wno-implicit-function-declaration&quot; \nexport LDFLAGS=&quot;-L$(brew86 --prefix openssl)/lib -L$(brew86 --prefix readline)/lib -L$(brew86 --prefix zlib)/lib -L$(brew86 --prefix bzip2)/lib -L$(brew86 --prefix gettext)/lib -L$(brew86 --prefix libffi)/lib&quot;\n\n# Providing an incorrect openssl version forces a proper openssl version to be downloaded and linked during the build\nexport PYTHON_BUILD_HOMEBREW_OPENSSL_FORMULA=openssl@1.0\n\n# Install Python 3.6\npyenv86 install --patch 3.6.15 &lt;&lt;(curl -sSL https://raw.githubusercontent.com/pyenv/pyenv/master/plugins/python-build/share/python-build/patches/3.6.15/Python-3.6.15/0008-bpo-45405-Prevent-internal-configure-error-when-runn.patch\\?full_index\\=1)\n</code></pre>\n<p>Note, the build succeeds but gives the following warning</p>\n<pre><code>WARNING: The Python readline extension was not compiled. Missing the GNU readline lib?\n</code></pre>\n<p>running <code>pyenv versions</code> shows that <code>3.6.15</code> can be used normally by the system</p>\n"}
{"Id": 71391946, "PostTypeId": 1, "Title": "Does Raku has Python's Union type?", "Body": "<p>In Python, Python has <a href=\"https://docs.python.org/3/library/typing.html#typing.Union\" rel=\"noreferrer\">Union</a> type, which is convenient when a method can accept multi types:</p>\n<pre><code>from typing import Union\n\ndef test(x: Union[str,int,float,]):\n    print(x)\n\nif __name__ == '__main__':\n    test(1)\n    test('str')\n    test(3.1415926)\n</code></pre>\n<p>Raku probably doesn't have Union type as Python, but a <code>where</code> clause can achieve a similar effect:</p>\n<pre><code>sub test(\\x where * ~~ Int | Str | Rat) {\n    say(x)\n}\n\nsub MAIN() {\n    test(1);\n    test('str');\n    test(3.1415926);\n}\n</code></pre>\n<p>I wander if Raku have a possibility to provide the Union type as Python?</p>\n<pre><code>#        vvvvvvvvvvvvvvvvvvvv - the Union type doesn't exist in Raku now.\nsub test(Union[Int, Str, Rat] \\x) {\n    say(x)\n}\n</code></pre>\n", "AcceptedAnswerId": 71402432, "AcceptedAnswer": "<p>My answer (which is very similar to your first solution ;) would be:</p>\n<pre><code>subset Union where Int | Rat | Str;\n\nsub test(Union \\x) {\n   say(x) \n}\n\nsub MAIN() {\n    test(1);\n    test('str');\n    test(pi);\n}\n\nConstraint type check failed in binding to parameter 'x'; \nexpected Union but got Num (3.141592653589793e0)\n</code></pre>\n<p>(or you can put a <code>where</code> clause in the call signature, as you have it)</p>\n<p>In contrast to Python:</p>\n<ul>\n<li>this is native in raku and does not rely on a package like &quot;typing&quot; to be imported</li>\n<li>Python Union / SumTypes are used for static hinting, which is good for eg. IDEs</li>\n<li><strong>but</strong> these types are unenforced in Python (per @freshpaste comment and this <a href=\"https://stackoverflow.com/questions/38854282/do-union-types-actually-exist-in-python\">SO</a>), in raku they are checked and will fail at runtime</li>\n</ul>\n<p>So - the raku syntax is there to do what you ask ... sure, it's a different language so it does it in a different way.</p>\n<p>Personally I think that a typed language should fail if type checks are breached. It seems to me that type hinting that is not always enforced is a false comfort blanket.</p>\n<p>On a wider point, raku also offers built in <a href=\"https://docs.raku.org/type/Allomorph\" rel=\"noreferrer\">Allomorph</a> types for IntStr, RatStr, NumStr and ComplexStr - so you can work in a mixed mode using both string and math functions</p>\n"}
{"Id": 71150313, "PostTypeId": 1, "Title": "python-docx adding bold and non-bold strings to same cell in table", "Body": "<p>I'm using python-docx to create a document with a table I want to populate from textual data. My text looks like this:</p>\n<pre><code>01:02:10.3 \na: Lorem ipsum dolor sit amet,  \nb: consectetur adipiscing elit.\na: Mauris a turpis erat. \n01:02:20.4 \na: Vivamus dignissim aliquam\nb: Nam ultricies\n(etc.)\n</code></pre>\n<p>I need to organize it in a table like this (using ASCII for visualization):</p>\n<pre><code>+---+--------------------+---------------------------------+\n|   |         A          |                B                |\n+---+--------------------+---------------------------------+\n| 1 | 01:02:10.3         | a: Lorem ipsum dolor sit amet,  |\n| 2 |                    | b: consectetur adipiscing elit. |\n| 3 |                    | a: Mauris a turpis erat.        |\n| 4 | ------------------ | ------------------------------- |\n| 5 | 01:02:20.4         | a: Vivamus dignissim aliqua     |\n| 6 |                    | b: Nam ultricies                |\n+---+--------------------+---------------------------------+\n</code></pre>\n<p>however, I need to make it so everything after &quot;a: &quot; is bold, and everything after &quot;b: &quot; isn't, while they <strong>both occupy the same cell</strong>. It's pretty easy to iterate and organize this the way I want, but I'm really unsure about how to make only some of the lines bold:</p>\n<pre><code>IS_BOLD = { \n    'a': True\n    'b': False\n}\n\nrow_cells = table.add_row().cells\n\nfor line in lines: \n    if is_timestamp(line): # function that uses regex to discern between columns\n        if row_cells[1]:\n            row_cells = table.add_row().cells\n\n        row_cells[0].text = line\n\n    else \n        row_cells[1].text += line\n\n        if IS_BOLD[ line.split(&quot;:&quot;)[0] ]:\n            # make only this line within the cell bold, somehow.\n</code></pre>\n<p>(this is sort of pseudo-code, I'm doing some more textual processing but that's kinda irrelevant here). I found one <a href=\"https://stackoverflow.com/questions/53638832/bold-underlining-and-iterations-with-python-docx\">probably relevant question</a> where someone uses something called <code>run</code> but I'm finding it hard to understand how to apply it to my case.</p>\n<p>Any help?\nThanks.</p>\n", "AcceptedAnswerId": 71280321, "AcceptedAnswer": "<p>You need to add <code>run</code> in the cell's paragraph. This way you can control the specific text you wish to bold</p>\n<p>Full example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from docx import Document\nfrom docx.shared import Inches\nimport os\nimport re\n\n\ndef is_timestamp(line):\n    # it's flaky, I saw you have your own method and probably you did a better job parsing this.\n    return re.match(r'^\\d{2}:\\d{2}:\\d{2}', line) is not None\n\n\ndef parse_raw_script(raw_script):\n    current_timestamp = ''\n    current_content = ''\n    for line in raw_script.splitlines():\n        line = line.strip()\n        if is_timestamp(line):\n            if current_timestamp:\n                yield {\n                    'timestamp': current_timestamp,\n                    'content': current_content\n                }\n\n            current_timestamp = line\n            current_content = ''\n            continue\n\n        if current_content:\n            current_content += '\\n'\n\n        current_content += line\n\n    if current_timestamp:\n        yield {\n            'timestamp': current_timestamp,\n            'content': current_content\n        }\n\n\ndef should_bold(line):\n    # i leave it to you to replace with your logic\n    return line.startswith('a:')\n\n\ndef load_raw_script():\n    # I placed here the example from your question. read from file instead I presume\n\n    return '''01:02:10.3 \na: Lorem ipsum dolor sit amet,  \nb: consectetur adipiscing elit.\na: Mauris a turpis erat. \n01:02:20.4 \na: Vivamus dignissim aliquam\nb: Nam ultricies'''\n\n\ndef convert_raw_script_to_docx(raw_script, output_file_path):\n    document = Document()\n    table = document.add_table(rows=1, cols=3, style=&quot;Table Grid&quot;)\n\n    # add header row\n    header_row = table.rows[0]\n    header_row.cells[0].text = ''\n    header_row.cells[1].text = 'A'\n    header_row.cells[2].text = 'B'\n\n    # parse the raw script into something iterable\n    script_rows = parse_raw_script(raw_script)\n\n    # create a row for each timestamp row\n    for script_row in script_rows:\n        timestamp = script_row['timestamp']\n        content = script_row['content']\n\n        row = table.add_row()\n        timestamp_cell = row.cells[1]\n        timestamp_cell.text = timestamp\n\n        content_cell = row.cells[2]\n        content_paragraph = content_cell.paragraphs[0]  # using the cell's default paragraph here instead of creating one\n\n        for line in content.splitlines():\n            run = content_paragraph.add_run(line)\n            if should_bold(line):\n                run.bold = True\n\n            run.add_break()\n\n    # resize table columns (optional)\n    for row in table.rows:\n        row.cells[0].width = Inches(0.2)\n        row.cells[1].width = Inches(1.9)\n        row.cells[2].width = Inches(3.9)\n\n    document.save(output_file_path)\n\n\ndef main():\n    script_dir = os.path.dirname(__file__)\n    dist_dir = os.path.join(script_dir, 'dist')\n\n    if not os.path.isdir(dist_dir):\n        os.makedirs(dist_dir)\n\n    output_file_path = os.path.join(dist_dir, 'so-template.docx')\n    raw_script = load_raw_script()\n    convert_raw_script_to_docx(raw_script, output_file_path)\n\n\nif __name__ == '__main__':\n    main()\n\n</code></pre>\n<p>Result (file should be in <code>./dist/so-template.docx</code>):</p>\n<p><a href=\"https://i.stack.imgur.com/JOoHK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/JOoHK.png\" alt=\"enter image description here\" /></a></p>\n<hr />\n<p>BTW - if you prefer sticking with your own example, this is what needs to be changed:</p>\n<pre class=\"lang-py prettyprint-override\"><code>IS_BOLD = {\n    'a': True,\n    'b': False\n}\n\nrow_cells = table.add_row().cells\n\nfor line in lines:\n    if is_timestamp(line):\n        if row_cells[1]:\n            row_cells = table.add_row().cells\n        row_cells[0].text = line\n\n    else:\n        run = row_cells[1].paragraphs[0].add_run(line)\n        if IS_BOLD[line.split(&quot;:&quot;)[0]]:\n            run.bold = True\n\n        run.add_break()\n</code></pre>\n"}
{"Id": 71969299, "PostTypeId": 1, "Title": "How to disable code formatting in ipython?", "Body": "<p>IPython has this new feature that reformats my prompt. Unfortunately, it is really buggy, so I want to disable it. I managed to do it when starting IPython from the command line by adding the following line in my <code>ipython_config.py</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>c.TerminalInteractiveShell.autoformatter = None\n</code></pre>\n<p>However, it does not work when I run it from a python script. I start IPython from my script the following way:</p>\n<pre class=\"lang-py prettyprint-override\"><code>c = traitlets.config.get_config()\nc.InteractiveShellEmbed.colors = &quot;Linux&quot;\nc.TerminalInteractiveShell.autoformatter = None\nc.InteractiveShellEmbed.loop_runner = lambda coro: loop.run_until_complete(coro)\nIPython.embed(display_banner='', using='asyncio', config=c)\n</code></pre>\n<p>If I change the <code>colors</code> value, the colors change accordingly, so the configuration itself works. However, no matter what I do with <code>autoformatter</code>, IPython autoformats my code regardless. What am I doing wrong?</p>\n", "AcceptedAnswerId": 71995927, "AcceptedAnswer": "<p>Apparently, the answer is:</p>\n<pre class=\"lang-py prettyprint-override\"><code>c.InteractiveShellEmbed.autoformatter = None\n</code></pre>\n"}
{"Id": 71424233, "PostTypeId": 1, "Title": "How do I list my scheduled queries via the Python google client API?", "Body": "<p>I have set up my service account and I can run queries on bigQuery using <code>client.query()</code>.</p>\n<p>I could just write all my scheduled queries into this new <code>client.query()</code> format but I already have many scheduled queries so I was wondering if there is a way I can get/list the scheduled queries and then use that information to run those queries from a script.</p>\n<p><a href=\"https://i.stack.imgur.com/sq7qz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sq7qz.png\" alt=\"I can query with big Query but I want to list queries\" /></a></p>\n", "AcceptedAnswerId": 71428499, "AcceptedAnswer": "<p>Yes, you can use the APIs. When you don't know which one to use, I have a tip. Use the command proposed by @Yev</p>\n<p><code>bq ls --transfer_config --transfer_location=US --format=prettyjson</code></p>\n<p>But log the API calls. for that use the <code>--apilog &lt;logfile name&gt;</code> parameter like that</p>\n<p><code>bq --apilog ./log ls --transfer_config --transfer_location=US --format=prettyjson</code></p>\n<p>And, magically, you can find the API called by the command:\n<code>https://bigquerydatatransfer.googleapis.com/v1/projects/&lt;PROJECT-ID&gt;/locations/US/transferConfigs?alt=json</code></p>\n<p>Then, a simple google search leads you to the <a href=\"https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.transferConfigs/list\" rel=\"noreferrer\">correct documentation</a></p>\n<hr />\n<p>In python, add that dependencies in your <code>requirements.txt</code>: <code>google-cloud-bigquery-datatransfer</code> and use that code</p>\n<pre><code>from google.cloud import bigquery_datatransfer\n\nclient = bigquery_datatransfer.DataTransferServiceClient()\nparent = client.common_project_path(&quot;&lt;PROJECT-ID&gt;&quot;)\nresp = client.list_transfer_configs(parent=parent)\nprint(resp)\n</code></pre>\n"}
{"Id": 71583528, "PostTypeId": 1, "Title": "Python extracting string", "Body": "<p>I have a dataframe where one of the columns which is in string format looks like this</p>\n<pre><code>    filename\n 0  Machine02-2022-01-28_00-21-45.blf.424\n 1  Machine02-2022-01-28_00-21-45.blf.425\n 2  Machine02-2022-01-28_00-21-45.blf.426\n 3  Machine02-2022-01-28_00-21-45.blf.427\n 4  Machine02-2022-01-28_00-21-45.blf.428\n</code></pre>\n<p>I want my column to look like this</p>\n<pre><code>      filename\n 0    2022-01-28 00-21-45 424\n 1    2022-01-28 00-21-45 425\n 2    2022-01-28 00-21-45 426\n 3    2022-01-28 00-21-45 427\n 4    2022-01-28 00-21-45 428\n</code></pre>\n<p>I tried this code</p>\n<pre><code>df['filename'] = df['filename'].str.extract(r&quot;(\\d{4}-\\d{1,2}-\\d{1,2})_(\\d{2}-\\d{2}-\\d{2}).*\\.(\\d+)&quot;, r&quot;\\1 \\2 \\3&quot;)\n</code></pre>\n<p>I am getting this error, unsupported operand type(s) for &amp;: 'str' and 'int'.<br />\nCan anyone please tell me where I am doing wrong ?</p>\n", "AcceptedAnswerId": 71583643, "AcceptedAnswer": "<p>please try this:</p>\n<pre><code>df['filename'] = df['filename'].str.split('-',1).apply(lambda x:' '.join(x[1].split('_')).replace('.blf.',' '))\n</code></pre>\n"}
{"Id": 71452013, "PostTypeId": 1, "Title": "Does Python not reuse memory here? What does tracemalloc's output mean?", "Body": "<p>I create a list of a million <code>int</code> objects, then replace each with its negated value. <code>tracemalloc</code> reports 28 MB extra memory (28 bytes per new <code>int</code> object). Why? Does Python not reuse the memory of the garbage-collected <code>int</code> objects for the new ones? Or am I misinterpreting the <code>tracemalloc</code> results? Why does it say those numbers, what do they really mean here?</p>\n<pre><code>import tracemalloc\n\nxs = list(range(10**6))\ntracemalloc.start()\nfor i, x in enumerate(xs):\n    xs[i] = -x\nprint(tracemalloc.get_traced_memory())\n</code></pre>\n<p>Output (<a href=\"https://tio.run/##TYzLCsJADADv@Yocs0VFEUQEv0SkLDXWwL7IRth@/Vo8dW4Dw5TFPjmdr0V7l1iyGpr6iaMPIU8AreIdg1Qj9WlmOh2H4eIcbKJDNa9GDt5ZUXbYUBJy@kZWb0ytuhvgSqsPea63fYOikoy2j5lt/PtrjByzLuRc7z8\" rel=\"noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a>):</p>\n<pre><code>(27999860, 27999972)\n</code></pre>\n<p>If I replace <code>xs[i] = -x</code> with <code>x = -x</code> (so the new object rather than the original object gets garbage-collected), the output is a mere <code>(56, 196)</code> (<a href=\"https://tio.run/##TYzLCsJADEX3@Yosk6KiCCKC31KGGuvAvMhEmH79tHTVuztwzi2L/XK6P4v27mPJamjqJokuhDwBtIpvDL4aqUuz0O06DA9mOEiXak6NGL5Z0Z@woU8o6R9FnQm1yi/AbW17Ojco6pPRsZ/Fxp0/Y5SYdSHm3lc\" rel=\"noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">try it</a>). How does it make any difference which of the two objects I keep/lose?</p>\n<p>And if I do the loop twice, it still only reports <code>(27992860, 27999972)</code> (<a href=\"https://tio.run/##lY3LCsJADEX38xVZJkVFEUQEv6RIGWqsgc6DTITp14/FVbee3YXDPXmxd4rna9bWJOSkBqZ@5ODnOY3O1QJ3mKUYqo8T4@nYdRcit5EOxbwaknslBdlBBYnA8RNYvTHWQjcHK7X08ljf9vUPM6tEw21tYht@@zkEDkkXJGrtCw\" rel=\"noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">try it</a>). Why not 56 MB? How is the second run any different for this than the first?</p>\n", "AcceptedAnswerId": 71481334, "AcceptedAnswer": "<h2>Short Answer</h2>\n<p>tracemalloc was started too late to track the inital block of memory, so it\ndidn't realize it was a reuse. In the example you gave, you free 27999860 bytes\nand allocate 27999860 bytes, but tracemalloc can't 'see' the free. Consider the\nfollowing, slightly modified example:</p>\n<pre><code>import tracemalloc\n\ntracemalloc.start()\n\nxs = list(range(10**6))\nprint(tracemalloc.get_traced_memory())\nfor i, x in enumerate(xs):\n    xs[i] = -x\nprint(tracemalloc.get_traced_memory())\n</code></pre>\n<p>On my machine (python 3.10, but same allocator), this displays:</p>\n<pre><code>(35993436, 35993436)\n(36000576, 36000716)\n</code></pre>\n<p>After we allocate xs, the system has allocated 35993436 bytes, and after we run\nthe loop we have a net total of 36000576. This shows that the memory usage isn't\nactually increasing by 28 Mb.</p>\n<h2>Why does it behave this way?</h2>\n<p>Tracemalloc works by overriding the standard internal methods for allocating\nwith <code>tracemalloc_alloc</code>, and the similar free and realloc methods. Taking a\npeek at the <a href=\"https://github.com/python/cpython/blob/2cf7f865f099db11cc6903b334d9c376610313e8/Modules/_tracemalloc.c#L583-L607\" rel=\"noreferrer\">source</a>:</p>\n<pre><code>static void*\ntracemalloc_alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)\n{\n    PyMemAllocatorEx *alloc = (PyMemAllocatorEx *)ctx;\n    void *ptr;\n\n    assert(elsize == 0 || nelem &lt;= SIZE_MAX / elsize);\n\n    if (use_calloc)\n        ptr = alloc-&gt;calloc(alloc-&gt;ctx, nelem, elsize);\n    else\n        ptr = alloc-&gt;malloc(alloc-&gt;ctx, nelem * elsize);\n    if (ptr == NULL)\n        return NULL;\n\n    TABLES_LOCK();\n    if (ADD_TRACE(ptr, nelem * elsize) &lt; 0) {\n        /* Failed to allocate a trace for the new memory block */\n        TABLES_UNLOCK();\n        alloc-&gt;free(alloc-&gt;ctx, ptr);\n        return NULL;\n    }\n    TABLES_UNLOCK();\n    return ptr;\n}\n</code></pre>\n<p>We see that the new allocator does two things:</p>\n<p>1.) Call out to the &quot;old&quot; allocator to get memory</p>\n<p>2.) Add a trace to a special table, so we can track this memory</p>\n<p>If we look at the associated free functions, it's very similar:</p>\n<p>1.) free the memory</p>\n<p>2.) Remove the trace from the table</p>\n<p>In your example, you allocated xs before you called <code>tracemalloc.start()</code>, so\nthe trace records for this allocation are never put in the memory tracking\ntable. Therefore, when you call free on the initial array data, the traces aren't removed, and thus your weird allocation behavior.</p>\n<h2>Why is the total memory usage 36000000 bytes and not 28000000</h2>\n<p>Lists in python are weird. They're actually a list of pointer to individually\nallocated objects. Internally, they look like this:</p>\n<pre><code>typedef struct {\n    PyObject_HEAD\n    Py_ssize_t ob_size;\n\n    /* Vector of pointers to list elements.  list[0] is ob_item[0], etc. */\n    PyObject **ob_item;\n\n    /* ob_item contains space for 'allocated' elements.  The number\n     * currently in use is ob_size.\n     * Invariants:\n     *     0 &lt;= ob_size &lt;= allocated\n     *     len(list) == ob_size\n     *     ob_item == NULL implies ob_size == allocated == 0\n     */\n    Py_ssize_t allocated;\n} PyListObject;\n</code></pre>\n<p>PyObject_HEAD is a macro that expands to some header information all python\nvariables have. It is just 16 bytes, and contains pointers to type data.</p>\n<p>Importantly, a list of integers is actually a list of pointer to PyObjects\nthat happen to be ints. On the line <code>xs = list(range(10**6))</code>, we expect to\nallocate:</p>\n<ul>\n<li>1 PyListObject with internal size 1000000 -- true size:</li>\n</ul>\n<pre><code>sizeof(PyObject_HEAD) + sizeof(PyObject *) * 1000000 + sizeof(Py_ssize_t)\n(     16 bytes      ) + (    8 bytes     ) * 1000000 + (     8 bytes    )\n8000024 bytes\n</code></pre>\n<ul>\n<li>1000000 PyObject ints (A <code>PyLongObject</code> in the underlying implmentation)</li>\n</ul>\n<pre><code>1000000 * sizeof(PyLongObject)\n1000000 * (     28 bytes     )\n28000000 bytes\n</code></pre>\n<p>For a grand total of 36000024 bytes. That number looks pretty farmiliar!</p>\n<p>When you overwrite a value in the array, your just freeing the old value, and updating the pointer in PyListObject-&gt;ob_item. This means the array structure is allocated once, takes up 8000024 bytes, and lives to the end of the program. Additionally, 1000000 Integer objects are each allocated, and references are put in the array. They take up the 28000000 bytes. One by one, they are deallocated, and then the memory is used to reallocate a new object in the loop. This is why multiple loops don't increase the amount of memory.</p>\n"}
{"Id": 71486255, "PostTypeId": 1, "Title": "How can I make Python re work like grep for repeating groups?", "Body": "<p>I have the following string:</p>\n<pre><code>seq = 'MNRYLNRQRLYNMYRNKYRGVMEPMSRMTMDFQGRYMDSQGRMVDPRYYDHYGRMHDYDRYYGRSMFNQGHSMDSQRYGGWMDNPERYMDMSGYQMDMQGRWMDAQGRYNNPFSQMWHSRQGH'\n</code></pre>\n<p>also saved in a file called <code>seq.dat</code>. If I use the following <code>grep</code> command</p>\n<pre><code>grep '\\([MF]D.\\{4,6\\}\\)\\{3,10\\}' seq.dat\n</code></pre>\n<p>I get the following matching string:</p>\n<pre><code>MDNPERYMDMSGYQMDMQGRWMDAQGRYN\n</code></pre>\n<p>which is what I want. In words, what I want to match is as many consecutive repeats as the string has of <code>[MF]D.{4,6}</code>. I don't want to match cases where it has less than 3 consecutive repeats, but I want it to be able to capture up to 6.</p>\n<p>Now, I'm trying to do this with python. I have</p>\n<pre><code>p = re.compile(&quot;(?:[MF]D.{4,6}){3,10}&quot;)\n</code></pre>\n<p>Trying <code>search()</code> returns</p>\n<pre><code>MDNPERYMDMSGYQMDMQGRWM\n</code></pre>\n<p>It is the close to the answer I seek, but is still missing the last <code>MDAQGRYN</code>. I'm guessing this is because <code>.{4,6}</code> matches the <code>M</code>, which in turn prevents <code>{3,10}</code> from capturing this 4th occurence of <code>([MF]D.{4,6})</code>, but since I asked for at least 3, it's happy and it stops.</p>\n<p>How do I make Python regex behave like grep does?</p>\n", "AcceptedAnswerId": 71487029, "AcceptedAnswer": "<p>There is a fundamental difference between POSIX (&quot;text-directed&quot;) and NFA (&quot;regex-directed&quot;) engines. POSIX engines (<code>grep</code> here uses a POSIX BRE regex flavor, it is the flavor used by default) will parse the input text applying the regex to it and return the longest match possible. NFA engine (Python <code>re</code> engine is an NFA engine) here does not re-consume (backtrack) when the subsequent pattern parts match.</p>\n<p>See <a href=\"https://www.regular-expressions.info/engine.html\" rel=\"nofollow noreferrer\"><em>reference on regex-directed and text-directed engines</em></a>:</p>\n<blockquote>\n<p>A regex-directed engine walks through the regex, attempting to match the next token in the regex to the next character. If a match is found, the engine advances through the regex and the subject string. If a token fails to match, the engine backtracks to a previous position in the regex and the subject string where it can try a different path through the regex... Modern regex flavors using regex-directed engines have lots of features such as atomic grouping and possessive quantifiers that allow you to control this backtracking.</p>\n<p>A text-directed engine walks through the subject string, attempting all permutations of the regex before advancing to the next character in the string. A text-directed engine never backtracks. Thus, there isn\u2019t much to discuss about the matching process of a text-directed engine. In most cases, a text-directed engine finds the same matches as a regex-directed engine.</p>\n</blockquote>\n<p>The last sentence says &quot;in most cases&quot;, but not all cases, and yours is a good illustration that discrepances may occur.</p>\n<p>To avoid consuming <code>M</code> or <code>F</code> that are immediately followed with <code>D</code>, I'd suggest using</p>\n<pre class=\"lang-none prettyprint-override\"><code>(?:[MF]D(?:(?![MF]D).){4,6}){3,10}\n</code></pre>\n<p>See the <a href=\"https://regex101.com/r/rewexi/1\" rel=\"nofollow noreferrer\">regex demo</a>. <em>Details</em>:</p>\n<ul>\n<li><code>(?:</code> - start of an outer non-capturing container group:\n<ul>\n<li><code>[MF]D</code> - <code>M</code> or <code>F</code> and then <code>D</code></li>\n<li><code>(?:(?![MF]D).){4,6}</code> - any char (other than a line break) repeated four to six times, that does not start an <code>MD</code> or <code>FD</code> char sequence</li>\n</ul>\n</li>\n<li><code>){3,10}</code> - end of the outer group, repeat 3 to 10 times.</li>\n</ul>\n<p>By the way, if you only want to match uppercase ASCII letters, replace the <code>.</code> with <code>[A-Z]</code>.</p>\n"}
{"Id": 71178416, "PostTypeId": 1, "Title": "Can you safely change a Python object's type in a C extension?", "Body": "<h2>Question</h2>\n<p>Suppose that I have implemented two Python types using the C extension API and that the types are identical (same data layouts/C <code>struct</code>) with the exception of their names and a few methods. Assuming that all methods respect the data layout, can you safely change the type of an object from one of these types into the other in a C function?</p>\n<p>Notably, as of Python 3.9, there appears to be a function <a href=\"https://docs.python.org/3/c-api/structures.html#c.Py_SET_TYPE\" rel=\"nofollow noreferrer\"><code>Py_SET_TYPE</code></a>, but the documentation is not clear as to whether/when this is safe to do. I'm interested in knowing both how to use this function safely and whether types can be safely changed prior to version 3.9.</p>\n<h2>Motivation</h2>\n<p>I'm writing a Python C extension to implement a Persistent <a href=\"https://en.wikipedia.org/wiki/Hash_array_mapped_trie\" rel=\"nofollow noreferrer\">Hash Array Mapped Trie</a> (PHAMT); in case it's useful, the source code is <a href=\"https://github.com/noahbenson/phamt\" rel=\"nofollow noreferrer\">here</a> (as of writing, it is at <a href=\"https://github.com/noahbenson/phamt/tree/186a7bde90a7420f414a6b7f7b5e2cf8bcdac201\" rel=\"nofollow noreferrer\">this commit</a>). A feature I would like to add is the ability to create a Transient Hash Array Mapped Trie (THAMT) from a PHAMT. THAMTs can be created from PHAMTs in <code>O(1)</code> time and can be mutated in-place efficiently. <strong>Critically, THAMTs have the exact same underlying <a href=\"https://github.com/noahbenson/phamt/blob/186a7bde90a7420f414a6b7f7b5e2cf8bcdac201/phamt/phamt.c#L354-L365\" rel=\"nofollow noreferrer\">C data-structure</a> as PHAMTs\u2014the only real difference between a PHAMT and a THAMT is a few methods encapsulated by their Python types.</strong> This common structure allows one to very efficiently turn a THAMT back into a PHAMT once one has finished performing a set of edits. (This pattern typically reduces the number of memory allocations when performing a large number of updates to a PHAMT).</p>\n<p>A very convenient way to implement the conversion from THAMT to PHAMT would be to simply change the type pointers of the THAMT objects from the THAMT type to the PHAMT type. I am confident that I can write code that safely navigates this change, but I can imagine that doing so might, for example, break the Python garbage collector.</p>\n<p>(To be clear: the motivation is just context as to how the question arose. I'm not looking for help implementing the structures described in the <strong>Motivation</strong>, I'm looking for an answer to the <strong>Question</strong>, above.)</p>\n", "AcceptedAnswerId": 71316603, "AcceptedAnswer": "<h3>The supported way</h3>\n<p>It <em>is</em> officially possible to change an object's type in Python, as long as the memory layouts are compatible... but this is mostly limited to types <em>not</em> implemented in C. With some restrictions, it is possible to do</p>\n<pre><code># Python attribute assignment, not C struct member assignment\nobj.__class__ = some_new_class\n</code></pre>\n<p>to change an object's class, with one of the restrictions being that both the old and new classes must be &quot;heap types&quot;, which all classes implemented in Python are and most classes implemented in C are not. (<code>types.ModuleType</code> and subclasses of that type are also specifically permitted, despite <code>types.ModuleType</code> not being a heap type. See the <a href=\"https://github.com/python/cpython/blob/v3.10.2/Objects/typeobject.c#L4697\" rel=\"noreferrer\">source</a> for exact restrictions.)</p>\n<p>If you want to create a heap type from C, <a href=\"https://docs.python.org/3/c-api/typeobj.html#heap-types\" rel=\"noreferrer\">you can</a>, but the interface is pretty different from the normal way of defining Python types from C. Plus, for <code>__class__</code> assignment to work, you have to not set the <code>Py_TPFLAGS_IMMUTABLETYPE</code> flag, and that means that people will be able to monkey-patch your classes in ways you might not like (or maybe you see that as an upside).</p>\n<p>If you want to go that route, I suggest looking at the <a href=\"https://github.com/python/cpython/blob/v3.10.2/Modules/_functoolsmodule.c\" rel=\"noreferrer\">CPython 3.10 <code>_functools</code> module source code</a> for an example. (They set the <code>Py_TPFLAGS_IMMUTABLETYPE</code> flag, which you'll have to make sure not to do.)</p>\n<hr />\n<h3>The unsupported way</h3>\n<p>There was an attempt at one point to allow <code>__class__</code> assignment for non-heap types, as long as the memory layouts worked. It got abandoned because it caused problems with some built-in immutable types, where the interpreter likes to reuse instances. For example, allowing <code>(1).__class__ = SomethingElse</code> would have caused a lot of problems. You can read more in the <a href=\"https://github.com/python/cpython/blob/v3.10.2/Objects/typeobject.c#L4720\" rel=\"noreferrer\">big comment</a> in the source code for the <code>__class__</code> setter. (The comment is slightly out of date, particularly regarding the <code>Py_TPFLAGS_IMMUTABLETYPE</code> flag, which was added after the comment was written.)</p>\n<p>As far as I know, this was the only problem, and I don't think any more problems have been added since then. The interpreter isn't going to aggressively reuse instances of your classes, so as long as <em>you're</em> not doing anything like that, and the memory layouts are compatible, I think changing the type of your objects <em>should</em> work for now, even for non-heap-types. However, it is not officially supported, so even if I'm right about this working for now, there's no guarantee it'll keep working.</p>\n<p><code>Py_SET_TYPE</code> only sets an object's type pointer. It doesn't do any refcount fixing that might be needed. It's a very low-level operation. If neither the old class nor the new class are heap types, no extra refcount fixing is needed, but if the old class is a heap type, you will have to decref the old class, and if the new class is a heap type, you will have to incref the new class.</p>\n<p>If you need to decref the old class, make sure to do it <em>after</em> changing the object's class and possibly incref'ing the new class.</p>\n"}
{"Id": 72071447, "PostTypeId": 1, "Title": "Python Enum and Pydantic : accept enum member's composition", "Body": "<p>I have an enum :</p>\n<pre class=\"lang-py prettyprint-override\"><code>from enum import Enum\n\nclass MyEnum(Enum):\n    val1 = &quot;val1&quot;\n    val2 = &quot;val2&quot;\n    val3 = &quot;val3&quot;\n</code></pre>\n<p>I would like to validate a pydantic field based on that enum.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from pydantic import BaseModel\n\nclass MyModel(BaseModel):\n    my_enum_field: MyEnum\n</code></pre>\n<p>BUT I would like this validation to also accept string that are composed by the Enum members.</p>\n<p>So for example : &quot;val1_val2_val3&quot; or &quot;val1_val3&quot; are valid input.</p>\n<p>I cannot make this field as a string field with a validator since I use a test library (<a href=\"https://hypothesis.readthedocs.io/en/latest/\" rel=\"noreferrer\">hypothesis</a> and <a href=\"https://github.com/Goldziher/pydantic-factories\" rel=\"noreferrer\">pydantic-factories</a>) that needs this type in order to render one of the values from the enum (for mocking random inputs)</p>\n<p>So this :</p>\n<pre class=\"lang-py prettyprint-override\"><code>from pydantic import BaseModel, validator\n\nclass MyModel(BaseModel):\n    my_enum_field: str\n\n    @validator('my_enum_field', pre=True)\n    def validate_my_enum_field(cls, value):\n        split_val = str(value).split('_')\n        if not all(v in MyEnum._value2member_map_ for v in split_val):\n            raise ValueError()\n        return value\n</code></pre>\n<p>Could work, but break my test suites because the field is anymore of enum types.</p>\n<p>How to keep this field as an Enum type (to make my mock structures still valid) and make pydantic accept composite values in the same time ?</p>\n<p>So far, I tried to dynamically extend the enum, with no success.</p>\n", "AcceptedAnswerId": 72072103, "AcceptedAnswer": "<p>I looked at this a bit further, and I believe something like this could be helpful. You can create a new class to define the property that is a list of enum values.</p>\n<p>This class can supply a customized <code>validate</code> method and supply a <code>__modify_schema__</code> to keep the information present about being a string in the json schema.</p>\n<p>We can define a base class for generic lists of concatenated enums like this:</p>\n<pre><code>from typing import Generic, TypeVar, Type\nfrom enum import Enum\n\nT = TypeVar(&quot;T&quot;, bound=Enum)\n\n\nclass ConcatenatedEnum(Generic[T], list[T]):\n    enum_type: Type[T]\n\n    @classmethod\n    def __get_validators__(cls):\n        yield cls.validate\n\n    @classmethod\n    def validate(cls, value: str):\n        return list(map(cls.enum_type, value.split(&quot;_&quot;)))\n\n    @classmethod\n    def __modify_schema__(cls, field_schema: dict):\n        all_values = ', '.join(f&quot;'{ex.value}'&quot; for ex in cls.enum_type)\n        field_schema.update(\n            title=f&quot;Concatenation of {cls.enum_type.__name__} values&quot;,\n            description=f&quot;Underscore delimited list of values {all_values}&quot;,\n            type=&quot;string&quot;,\n        )\n        if &quot;items&quot; in field_schema:\n            del field_schema[&quot;items&quot;]\n</code></pre>\n<p>In the <code>__modify_schema__</code> method I also provide a way to generate a description of which values are valid.</p>\n<p>To use this in your application:</p>\n<pre><code>class MyEnum(Enum):\n    val1 = &quot;val1&quot;\n    val2 = &quot;val2&quot;\n    val3 = &quot;val3&quot;\n\n\nclass MyEnumList(ConcatenatedEnum[MyEnum]):\n    enum_type = MyEnum\n\n\nclass MyModel(BaseModel):\n    my_enum_field: MyEnumList\n</code></pre>\n<p>Examples Models:</p>\n<pre><code>print(MyModel.parse_obj({&quot;my_enum_field&quot;: &quot;val1&quot;}))\nprint(MyModel.parse_obj({&quot;my_enum_field&quot;: &quot;val1_val2&quot;}))\n</code></pre>\n<pre><code>my_enum_field=[&lt;MyEnum.val1: 'val1'&gt;]\nmy_enum_field=[&lt;MyEnum.val1: 'val1'&gt;, &lt;MyEnum.val2: 'val2'&gt;]\n</code></pre>\n<p>Example Schema:</p>\n<pre><code>print(json.dumps(MyModel.schema(), indent=2))\n</code></pre>\n<pre><code>{\n  &quot;title&quot;: &quot;MyModel&quot;,\n  &quot;type&quot;: &quot;object&quot;,\n  &quot;properties&quot;: {\n    &quot;my_enum_field&quot;: {\n      &quot;title&quot;: &quot;Concatenation of MyEnum values&quot;,\n      &quot;description&quot;: &quot;Underscore delimited list of values 'val1', 'val2', 'val3'&quot;,\n      &quot;type&quot;: &quot;string&quot;\n    }\n  },\n  &quot;required&quot;: [\n    &quot;my_enum_field&quot;\n  ]\n}\n</code></pre>\n"}
{"Id": 71292505, "PostTypeId": 1, "Title": "TK python checkbutton RTL", "Body": "<p>I have a checkbutton:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from tkinter import *\nmaster = Tk()\nCheckbutton(master, text=&quot;Here...&quot;).grid(row=0, sticky=W)\nmainloop()\n</code></pre>\n<p>Which looks like this:</p>\n<p><a href=\"https://i.stack.imgur.com/dWDbj.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/dWDbj.png\" alt=\"enter image description here\" /></a></p>\n<p>I tried to move the checkbutton to the other side (to support RTL languages), so it'll be like:</p>\n<p><code>Here...[]</code></p>\n<p>I know that I can draw a label next to the checkbutton, but this way clicking the text won't effect the checkbutton.</p>\n<p>How can I do it?</p>\n", "AcceptedAnswerId": 71348390, "AcceptedAnswer": "<p>You can <a href=\"https://stackoverflow.com/questions/11504571/clickable-tkinter-labels\">bind the left mouse button click event of the label</a>, to a lambda construct that <a href=\"https://dafarry.github.io/tkinterbook/checkbutton.htm#Tkinter.Checkbutton.toggle-method\" rel=\"nofollow noreferrer\">toggles</a> the checkbutton -:</p>\n<pre><code>label.bind(&quot;&lt;Button-1&gt;&quot;, lambda x : check_button.toggle())\n</code></pre>\n<p>The label can then be placed before the checkbutton using grid(as mentioned in the OP at the end) -:</p>\n<pre><code>from tkinter import *\n\nmaster = Tk()\n\nl1 = Label(master, text = &quot;Here...&quot;)\ncb = Checkbutton(master)\nl1.grid(row = 0, column = 0)\ncb.grid(row = 0, column = 1, sticky=W)\n\nl1.bind(&quot;&lt;Button-1&gt;&quot;, lambda x : cb.toggle())\nmainloop()\n</code></pre>\n<p>This will toggle, the checkbutton even if the label is clicked.</p>\n<p><strong>OUTPUT</strong> -:</p>\n<p><a href=\"https://i.stack.imgur.com/NlTM0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NlTM0.png\" alt=\"OUTPUT\" /></a></p>\n<hr />\n<p><strong>NOTE:</strong></p>\n<p>The checkbutton, has to now be fetched as an object(<code>cb</code>), to be used in the lambda construct for the label's bind function callback argument. Thus, it is gridded in the next line. It is generally a good practice to manage the geometry separately, which can prevent error such as <a href=\"https://stackoverflow.com/questions/1101750/tkinter-attributeerror-nonetype-object-has-no-attribute-attribute-name\">this</a> one.</p>\n<hr />\n<p>Also, as mentioned in the <a href=\"https://stackoverflow.com/questions/24745824/change-position-of-checkbox-relative-to-text-in-tkinters-checkbutton\">post</a> linked by <a href=\"https://stackoverflow.com/users/3500157/alexander-b\">@Alexander B.</a> in the comments, if this assembly is to be used multiple times, it can also be made into a class of it's own that inherits from the <code>tkinter.Frame</code> class -:</p>\n<pre><code>class LabeledCheckbutton(Frame):\n    def __init__(self, root, text = &quot;&quot;):\n        Frame.__init__(self, root)\n        self.checkbutton = Checkbutton(self)\n        self.label = Label(self, text = text)\n        self.label.grid(row = 0, column = 0)\n        self.checkbutton.grid(row = 0, column = 1)\n        self.label.bind('&lt;Button-1&gt;', lambda x : self.checkbutton.toggle())\n        return\n    \n    pass\n</code></pre>\n<p>Using this with grid as the geometry manager, would make the full code look like this -:</p>\n<pre><code>from tkinter import *\n\nclass LabeledCheckbutton(Frame):\n    def __init__(self, root, text = &quot;&quot;):\n        Frame.__init__(self, root)\n        self.checkbutton = Checkbutton(self)\n        self.label = Label(self, text = text)\n        self.label.grid(row = 0, column = 0)\n        self.checkbutton.grid(row = 0, column = 1)\n        self.label.bind('&lt;Button-1&gt;', lambda x : self.checkbutton.toggle())\n        return\n    \n    pass\n\nmaster = Tk()\nlcb = LabeledCheckbutton(master, text = &quot;Here...&quot;)\nlcb.grid(row = 0, sticky = W)\n\nmainloop()\n</code></pre>\n<p>The output of the above code remains consistent with that of the first approach. The only difference is that it is now more easily scalable, as an object can be created whenever needed and the same lines of code need not be repeated every time.</p>\n"}
{"Id": 72011315, "PostTypeId": 1, "Title": "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: after installing python-certifi-win32", "Body": "<p>I installed python-certifi-win32 package and after that, I am getting below error, when I import anything or pip install anything, the fail with the final error of PermissionError.</p>\n<p>I tried rebooting the box. It didn't work. I am unable to uninstall the package as pip is erroring out too.</p>\n<p>I am unable to figure out the exact reason why this error is happening. It doesn't seem to be code specific, seems related to the library I installed</p>\n<pre><code>PS C:\\Users\\visha\\PycharmProjects\\master_test_runner&gt; pip install python-certifi-win32                                                                \nTraceback (most recent call last):\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\_common.py&quot;, line 89, in _tempfile\n    os.write(fd, reader())\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\abc.py&quot;, line 371, in read_bytes\n    with self.open('rb') as strm:\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\_adapters.py&quot;, line 54, in open\n    raise ValueError()\nValueError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py&quot;, line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py&quot;, line 86, in _run_code\n    exec(code, run_globals)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\Scripts\\pip.exe\\__main__.py&quot;, line 4, in &lt;module&gt;\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\cli\\main.py&quot;, line 9, in &lt;module&gt;\n    from pip._internal.cli.autocompletion import autocomplete\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\cli\\autocompletion.py&quot;, line 10, in &lt;module&gt;\n    from pip._internal.cli.main_parser import create_main_parser\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\cli\\main_parser.py&quot;, line 8, in &lt;module&gt;\n    from pip._internal.cli import cmdoptions\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\cli\\cmdoptions.py&quot;, line 23, in &lt;module&gt;\n    from pip._internal.cli.parser import ConfigOptionParser\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\cli\\parser.py&quot;, line 12, in &lt;module&gt;\n    from pip._internal.configuration import Configuration, ConfigurationError\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\configuration.py&quot;, line 21, in &lt;module&gt;\n    from pip._internal.exceptions import (\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_internal\\exceptions.py&quot;, line 8, in &lt;module&gt;\n    from pip._vendor.requests.models import Request, Response\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_vendor\\requests\\__init__.py&quot;, line 123, in &lt;module&gt;\n    from . import utils\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\pip\\_vendor\\requests\\utils.py&quot;, line 25, in &lt;module&gt;\n    from . import certs\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1027, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 688, in _load_unlocked\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\importer.py&quot;, line 170, in exec_module\n    notify_module_loaded(module)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\decorators.py&quot;, line 470, in _synchronized\n    return wrapped(*args, **kwargs)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\importer.py&quot;, line 136, in notify_module_loaded\n    hook(module)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\certifi_win32\\wrapt_pip.py&quot;, line 35, in apply_patches\n    import certifi\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1027, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 688, in _load_unlocked\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\importer.py&quot;, line 170, in exec_module\n    notify_module_loaded(module)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\decorators.py&quot;, line 470, in _synchronized\n    return wrapped(*args, **kwargs)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\wrapt\\importer.py&quot;, line 136, in notify_module_loaded\n    hook(module)\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\certifi_win32\\wrapt_certifi.py&quot;, line 20, in apply_patches\n    certifi_win32.wincerts.CERTIFI_PEM = certifi.where()\n  File &quot;C:\\Users\\visha\\PycharmProjects\\GUI_Automation\\venv\\lib\\site-packages\\certifi\\core.py&quot;, line 37, in where\n    _CACERT_PATH = str(_CACERT_CTX.__enter__())\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py&quot;, line 135, in __enter__\n    return next(self.gen)\n  File &quot;C:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\_common.py&quot;, line 95, in _tempfile\n    os.remove(raw_path)\nPermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\visha\\\\AppData\\\\Local\\\\Temp\\\\tmpy_tb8siv'\nPS C:\\Users\\visha\\PycharmProjects\\master_test_runner&gt; \n</code></pre>\n", "AcceptedAnswerId": 72087091, "AcceptedAnswer": "<p>I ran into the same issue today.  I corrected it by removing two *.pth files that were created when I had installed python-certifi-win32.  This prevents python-certifi-win32 from loading when python is run.</p>\n<p>The files are listed below, and were located here:</p>\n<pre><code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\n</code></pre>\n<p>Files:</p>\n<pre><code>python-certifi-win32-init.pth\ndistutils-precedence.pth\n</code></pre>\n<p>Removing these files allowed me to install/uninstall other modules.</p>\n"}
{"Id": 71564200, "PostTypeId": 1, "Title": "Python how to revert the pattern of a list rearrangement", "Body": "<p>So I am rearranging a list based on an index pattern and would like to find a way to calculate the pattern I need to revert the list back to its original order.</p>\n<p>for my example I am using a list of 5 items as I can work out the pattern needed to revert the list back to its original state.</p>\n<p>However this isn't so easy when dealing with 100's of list items.</p>\n<pre><code>def rearrange(pattern: list, L: list):\n    new_list = []\n    for i in pattern:\n        new_list.append(L[i-1])\n    return new_list\n\nprint(rearrange([2,5,1,3,4], ['q','t','g','x','r']))\n\n#['t', 'r', 'q', 'g', 'x']\n</code></pre>\n<p>and in order to set it back to the original pattern\nI would use</p>\n<pre><code>print(rearrange([3,1,4,5,2],['t', 'r', 'q', 'g', 'x']))\n#['q', 't', 'g', 'x', 'r']\n</code></pre>\n<p>What I am looking for is a way to calculate the pattern &quot;[3,1,4,5,2]&quot;\nregarding the above example.\nwhist running the script so that I can set the list back to its original order.</p>\n<p>Using a larger example:</p>\n<pre><code>print(rearrange([18,20,10,11,13,1,9,12,16,6,15,5,3,7,17,2,19,8,14,4],['e','p','b','i','s','r','q','h','m','f','c','g','d','k','l','t','a','n','j','o']))\n#['n', 'o', 'f', 'c', 'd', 'e', 'm', 'g', 't', 'r', 'l', 's', 'b', 'q', 'a', 'p', 'j', 'h', 'k', 'i']\n</code></pre>\n<p>but I need to know the pattern to use with this new list in order to return it to its original state.</p>\n<pre><code>print(rearrange([???],['n', 'o', 'f', 'c', 'd', 'e', 'm', 'g', 't', 'r', 'l', 's', 'b', 'q', 'a', 'p', 'j', 'h', 'k', 'i']))\n#['e','p','b','i','s','r','q','h','m','f','c','g','d','k','l','t','a','n','j','o']\n</code></pre>\n", "AcceptedAnswerId": 71564272, "AcceptedAnswer": "<p>This is commonly called &quot;argsort&quot;. But since you're using 1-based indexing, you're off-by-one. You can get it with numpy:</p>\n<pre><code>&gt;&gt;&gt; pattern\n[2, 5, 1, 3, 4]\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.argsort(pattern) + 1\narray([3, 1, 4, 5, 2])\n</code></pre>\n<p>Without numpy:</p>\n<pre><code>&gt;&gt;&gt; [1 + i for i in sorted(range(len(pattern)), key=pattern.__getitem__)]\n[3, 1, 4, 5, 2]\n</code></pre>\n"}
{"Id": 72161257, "PostTypeId": 1, "Title": "Exclude default fields from python `dataclass` `__repr__`", "Body": "<p><strong>Summary</strong></p>\n<p>I have a <code>dataclass</code> with <strong>10+ fields</strong>. <code>print()</code>ing them buries interesting context in a wall of defaults - let's make them friendlier by not needlessly repeating those.</p>\n<p><strong>Dataclasses in Python</strong></p>\n<p>Python's <a href=\"https://docs.python.org/3/library/dataclasses.html#dataclasses.dataclass\" rel=\"noreferrer\"><code>@dataclasses.dataclass()</code></a> (<a href=\"https://peps.python.org/pep-0557/\" rel=\"noreferrer\">PEP 557</a>) provides automatic printable representations (<a href=\"https://docs.python.org/3/library/functions.html#repr\" rel=\"noreferrer\"><code>__repr__()</code></a>).</p>\n<p>Assume this example, <a href=\"https://docs.python.org/3/library/dataclasses.html#:%7E:text=from%20dataclasses%20import%20dataclass\" rel=\"noreferrer\">based on python.org's</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from dataclasses import dataclass\n\n\n@dataclass\nclass InventoryItem:\n    name: str\n    unit_price: float = 1.00\n    quantity_on_hand: int = 0\n</code></pre>\n<p>The decorator, through <a href=\"https://docs.python.org/3/library/dataclasses.html?highlight=__repr__#:%7E:text=parameter%20is%20ignored.-,repr,-%3A%20If%20true%20(the\" rel=\"noreferrer\"><code>@dataclass(repr=True)</code></a> (default) will <a href=\"https://docs.python.org/3/library/functions.html#print\" rel=\"noreferrer\"><code>print()</code></a> a nice output:</p>\n<pre class=\"lang-py prettyprint-override\"><code>InventoryItem(name='Apple', unit_price='1.00', quantity_on_hand=0)\n</code></pre>\n<p><strong>What I want: Skip printing the defaults</strong></p>\n<p><code>repr</code> It prints <em>all</em> the fields, including implied defaults you wouldn't want to show.</p>\n<pre class=\"lang-py prettyprint-override\"><code>print(InventoryItem(&quot;Apple&quot;))\n\n# Outputs: InventoryItem(name='Apple', unit_price='1.00', quantity_on_hand=0)\n# I want: InventoryItem(name='Apple')\n</code></pre>\n<pre class=\"lang-py prettyprint-override\"><code>print(InventoryItem(&quot;Apple&quot;, unit_price=&quot;1.05&quot;))\n\n# Outputs: InventoryItem(name='Apple', unit_price='1.05', quantity_on_hand=0)\n# I want: InventoryItem(name='Apple', unit_price='1.05')\n</code></pre>\n<pre class=\"lang-py prettyprint-override\"><code>print(InventoryItem(&quot;Apple&quot;, quantity_on_hand=3))\n\n# Outputs: InventoryItem(name='Apple', unit_price=1.00, quantity_on_hand=3)\n# I want: InventoryItem(name='Apple', quantity_on_hand=3)\n</code></pre>\n<pre class=\"lang-py prettyprint-override\"><code>print(InventoryItem(&quot;Apple&quot;, unit_price='2.10', quantity_on_hand=3))\n\n# Output is fine (everything's custom):\n# InventoryItem(name='Apple', unit_price=2.10, quantity_on_hand=3)\n</code></pre>\n<p><strong>Discussion</strong></p>\n<p>Internally, here's the machinery of <code>dataclass</code> <code>repr</code>-generator as of python <code>3.10.4</code>: <a href=\"https://github.com/python/cpython/blob/v3.10.4/Lib/dataclasses.py#L1043-L1045\" rel=\"noreferrer\"><code>cls.__repr__</code></a><code>=</code><a href=\"https://github.com/python/cpython/blob/v3.10.4/Lib/dataclasses.py#L588-L596\" rel=\"noreferrer\"><code>_repr_fn(flds, globals))</code></a> -&gt; <a href=\"https://github.com/python/cpython/blob/v3.10.4/Lib/dataclasses.py#L391-L409\" rel=\"noreferrer\"><code>_recursive_repr(fn)</code></a></p>\n<p>It may be the case that <code>@dataclass(repr=False)</code> be switched off and <code>def __repr__(self):</code> be added.</p>\n<p>If so, what would that look like? We don't want to include the optional defaults.</p>\n<p><strong>Context</strong></p>\n<p>To repeat, in practice, my <code>dataclass</code> has <strong>10+ fields</strong>.</p>\n<p>I'm <code>print()</code>ing instances via running the code and repl, and <a href=\"https://docs.pytest.org/en/7.1.x/how-to/parametrize.html\" rel=\"noreferrer\"><code>@pytest.mark.parametrize</code></a> when running <a href=\"https://docs.pytest.org/en/7.1.x/\" rel=\"noreferrer\">pytest</a> with <code>-vvv</code>.</p>\n<p>Big dataclass' non-defaults (sometimes the inputs) are impossible to see as they're buried in the default fields and worse, each one is disproportionately and distractingly huge: obscuring other valuable stuff bring printed.</p>\n<p><strong>Related questions</strong></p>\n<p>As of today there aren't many <code>dataclass</code> questions yet (this may change):</p>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/67327282/extend-dataclass-repr-programmatically\">Extend dataclass&#39; __repr__ programmatically</a>: This is trying to <em>limit</em> the repr. It should show <em>less</em> fields unless they're explicitly overridden.</li>\n<li><a href=\"https://stackoverflow.com/questions/61740748/python-dataclass-generate-hash-and-exclude-unsafe-fields\">Python dataclass generate hash and exclude unsafe fields</a>: This is for hashing and not related to defaults.</li>\n</ul>\n", "AcceptedAnswerId": 72161437, "AcceptedAnswer": "<p>You could do it like this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import dataclasses\nfrom dataclasses import dataclass\nfrom operator import attrgetter\n\n\n@dataclass(repr=False)\nclass InventoryItem:\n    name: str\n    unit_price: float = 1.00\n    quantity_on_hand: int = 0\n\n    def __repr__(self):\n        nodef_f_vals = (\n            (f.name, attrgetter(f.name)(self))\n            for f in dataclasses.fields(self)\n            if attrgetter(f.name)(self) != f.default\n        )\n\n        nodef_f_repr = &quot;, &quot;.join(f&quot;{name}={value}&quot; for name, value in nodef_f_vals)\n        return f&quot;{self.__class__.__name__}({nodef_f_repr})&quot;\n        \n\n# Prints: InventoryItem(name=Apple)\nprint(InventoryItem(&quot;Apple&quot;))\n\n# Prints: InventoryItem(name=Apple,unit_price=1.05)\nprint(InventoryItem(&quot;Apple&quot;, unit_price=&quot;1.05&quot;))\n\n# Prints: InventoryItem(name=Apple,unit_price=2.10,quantity_on_hand=3)\nprint(InventoryItem(&quot;Apple&quot;, unit_price='2.10', quantity_on_hand=3))\n</code></pre>\n"}
{"Id": 72005302, "PostTypeId": 1, "Title": "Completely uninstall Python 3 on Mac", "Body": "<p>I installed Python 3 on Mac and installed some packages as well. But then I see AWS lamda does not support Python 3 so I decided to downgrade. I removed Python3 folder in Applications and cleared the trash. But still I see a folder named 3 in <em>/Library/Frameworks/Python.framework/Versions</em> which is causing problems, such as this:</p>\n<pre><code>  $ python3 -m pip install virtualenv\n Requirement already satisfied: virtualenv in      /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (20.14.1)\n Requirement already satisfied: platformdirs&lt;3,&gt;=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from virtualenv) (2.5.2) \n</code></pre>\n<p>So my question is how do I completely uninstall python 3 from my Mac?</p>\n", "AcceptedAnswerId": 72005684, "AcceptedAnswer": "<p>Removing the app does not completely uninstall that version of Python. You will need to remove the framework directories and their symbolic links.</p>\n<p><strong>Deleting the frameworks</strong></p>\n<p><code>sudo rm -rf /Library/Frameworks/Python.framework/Versions/[version number]</code>\nreplacing [version number] with 3.10 in your case.</p>\n<p><strong>Removing symbolic links</strong></p>\n<p>To list the broken symbolic links.</p>\n<p><code>ls -l /usr/local/bin | grep '../Library/Frameworks/Python.framework/Versions/[version number]'</code></p>\n<p>And to remove these links:</p>\n<p><code>cd /usr/local/bin</code></p>\n<p><code>ls -l /usr/local/bin | grep '../Library/Frameworks/Python.framework/Versions/[version number]' | awk '{print $9}' | tr -d @ | xargs rm*</code></p>\n<p>As always, please be wary of copying these commands. Please make sure the directories in the inputs are actual working directories before you execute anything.</p>\n<p>The general idea in the end is to remove the folders and symlinks, and you're good to go.</p>\n<p>Here is another response addressing this process: <a href=\"https://stackoverflow.com/questions/3819449/how-to-uninstall-python-2-7-on-a-mac-os-x-10-6-4/3819829#3819829\">How to uninstall Python 2.7 on a Mac OS X 10.6.4?</a></p>\n"}
{"Id": 72238460, "PostTypeId": 1, "Title": "Python ImportError: sys.meta_path is None, Python is likely shutting down", "Body": "<p>When using <code>__del__</code>\ndatetime.date.today() throws ImportError: sys.meta_path is None, Python is likely shutting down</p>\n<pre><code>import datetime\nimport time\nimport sys\n\n\nclass Bug(object):\n\n    def __init__(self):\n        print_meta_path()\n\n    def __del__(self):\n        print_meta_path()\n        try_date('time')\n        try_date('datetime')\n\n\ndef print_meta_path():\n    print(f'meta_path: {sys.meta_path}')\n\n\ndef try_date(date_type):\n    try:\n        print('----------------------------------------------')\n        print(date_type)\n        if date_type == 'time':\n            print(datetime.date.fromtimestamp(time.time()))\n        if date_type == 'datetime':\n            print(datetime.date.today())\n    except Exception as ex:\n        print(ex)\n\n\nif __name__ == '__main__':\n    print(sys.version)\n    bug = Bug()\n</code></pre>\n<p>output with different envs (3.10, 3.9, 3.7):</p>\n<pre><code>3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]\nmeta_path: [&lt;_distutils_hack.DistutilsMetaFinder object at 0x7ff8731f6860&gt;, &lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\nmeta_path: None\n----------------------------------------------\ntime\n2022-05-17\n----------------------------------------------\ndatetime\nsys.meta_path is None, Python is likely shutting down\n</code></pre>\n<pre><code>3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55)\n[GCC 10.3.0]\nmeta_path: [&lt;_distutils_hack.DistutilsMetaFinder object at 0x7fb01126e490&gt;, &lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\nmeta_path: None\n----------------------------------------------\ntime\n2022-05-17\n----------------------------------------------\ndatetime\nsys.meta_path is None, Python is likely shutting down\n</code></pre>\n<pre><code>3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53)\n[GCC 9.4.0]\nmeta_path: [&lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\nmeta_path: None\n----------------------------------------------\ntime\n2022-05-17\n----------------------------------------------\ndatetime\nsys.meta_path is None, Python is likely shutting down\n</code></pre>\n<pre><code>3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]\nmeta_path: [&lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\nmeta_path: None\n----------------------------------------------\ntime\n2022-05-17\n----------------------------------------------\ndatetime\nsys.meta_path is None, Python is likely shutting down\n</code></pre>\n<p>Why is that happening?\nI need to use requests which use urllib3 connection.py</p>\n<p><code>380:  is_time_off = datetime.date.today() &lt; RECENT_DATE</code></p>\n<pre><code>  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/requests/api.py&quot;, line 117, in post\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/requests/api.py&quot;, line 61, in request\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/requests/sessions.py&quot;, line 529, in request\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/requests/sessions.py&quot;, line 645, in send\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/requests/adapters.py&quot;, line 440, in send\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 703, in urlopen\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 386, in _make_request\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/urllib3/connectionpool.py&quot;, line 1040, in _validate_conn\n  File &quot;/home/liron/mambaforge/envs/dm-sdk-dev/lib/python3.10/site-packages/urllib3/connection.py&quot;, line 380, in connect\nImportError: sys.meta_path is None, Python is likely shutting down\n</code></pre>\n<p>switching the line to\n<code>380:  is_time_off = datetime.date.fromtimestamp(time.time()) &lt; RECENT_DATE</code> solve it.</p>\n<pre><code>OS Linux-5.13.0-41-generic-x86_64-with-glibc2.31\nurllib3 1.26.9\n</code></pre>\n<p>I already tried to rebind <code>__del__</code> arguments default</p>\n<p><code>def __del__(self, datetime=datetime):....</code></p>\n<p>Does anyone have an idea? thanks</p>\n", "AcceptedAnswerId": 72275619, "AcceptedAnswer": "<p>Using <code>atexit</code> provide the same behavior as <code>__del__</code> but works</p>\n<pre><code>import datetime\nimport time\nimport sys\nimport atexit\n\n\nclass Bug(object):\n\n    def __init__(self):\n        print_meta_path()\n        atexit.register(self.__close)\n\n    def __close(self):\n        print_meta_path()\n        try_date('time')\n        try_date('datetime')\n\n\ndef print_meta_path():\n    print(f'meta_path: {sys.meta_path}')\n\n\ndef try_date(date_type):\n    try:\n        print('----------------------------------------------')\n        print(date_type)\n        if date_type == 'time':\n            print(datetime.date.fromtimestamp(time.time()))\n        if date_type == 'datetime':\n            print(datetime.date.today())\n    except ImportError:\n        print('')\n\n\nif __name__ == '__main__':\n    print(sys.version)\n    bug = Bug()\n</code></pre>\n<p>output:</p>\n<pre><code>3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]\nmeta_path: [&lt;_distutils_hack.DistutilsMetaFinder object at 0x7fd912112860&gt;, &lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\nmeta_path: [&lt;_distutils_hack.DistutilsMetaFinder object at 0x7fd912112860&gt;, &lt;class '_frozen_importlib.BuiltinImporter'&gt;, &lt;class '_frozen_importlib.FrozenImporter'&gt;, &lt;class '_frozen_importlib_external.PathFinder'&gt;]\n----------------------------------------------\ntime\n2022-05-17\n----------------------------------------------\ndatetime\n2022-05-17\n\nProcess finished with exit code 0\n</code></pre>\n"}
{"Id": 72280762, "PostTypeId": 1, "Title": "pip broke after downlading python-certifi-win32", "Body": "<p>I have downloaded python for the first time in a new computer(ver 3.10.4).\nI have download the package <code>python-certifi-win32</code>, after someone suggested it as a solution to a SSL certificate problem in a similar question to a problem I had.\nSince then, pip has completely stopped working, to the point where i can't not run <code>pip --version</code>\nEvery time the same error is printed, it is mostly seemingly junk(just a deep stack trace), but the file at the end is different.</p>\n<p>start of the printed log:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;C:\\Users\\---\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\_common.py&quot;, line 89, in _tempfile\n    os.write(fd, reader())\n  File &quot;C:\\Users\\---\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\abc.py&quot;, line 371, in read_bytes\n    with self.open('rb') as strm:\n  File &quot;C:\\Users\\---\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\_adapters.py&quot;, line 54, in open\n    raise ValueError()\nValueError\n\nDuring handling of the above exception, another exception occurred:\n</code></pre>\n<p>last row of the printed log:</p>\n<pre><code>PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\-----\\\\AppData\\\\Local\\\\Temp\\\\tmpunox3fhw'\n</code></pre>\n", "AcceptedAnswerId": 72293534, "AcceptedAnswer": "<p>I found the answer in another question -\n<a href=\"https://stackoverflow.com/questions/72011315/permissionerror-winerror-32-the-process-cannot-access-the-file-because-it-is\">PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: after installing python-certifi-win32</a></p>\n<p>basically, you should remove two files that initialize <code>python-certifi-win32</code> when running pip. the files are located in the directory:</p>\n<pre><code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\n</code></pre>\n<p>and their names are:</p>\n<pre><code>python-certifi-win32-init.pth\ndistutils-precedence.pth\n</code></pre>\n<p>Shoutout to Richard from the mentioned post :)</p>\n"}
{"Id": 71737743, "PostTypeId": 1, "Title": "How can I change playback speed of an audio file in python whilst it is playing?", "Body": "<p>I've done alot of searching to try and find a way to achieve this but the solutions I've found either <a href=\"https://stackoverflow.com/questions/51434897/how-to-change-audio-playback-speed-using-pydub\">don't do what I need</a> <a href=\"https://stackoverflow.com/questions/38165103/python-changing-the-speed-of-sound-during-playback\">or</a> <a href=\"https://stackoverflow.com/questions/44895126/play-sounds-of-varying-varying-pitch-asynchronously-and-concurrently\">I don't understand them</a>.</p>\n<p>I'm looking for a way of playing a sound in python (non-blocking) that allows me to change the playback speed in real time, as it's playing, with no gaps or cutouts.</p>\n<p>Changing the pitch is fine. Audio quality isn't even that important.</p>\n<p>Most of the solutions <a href=\"https://stackoverflow.com/questions/22755558/increase-decrease-play-speed-of-a-wav-file-python\">I've found</a> only allow setting the playback speed once, before the file is played.</p>\n", "AcceptedAnswerId": 71748928, "AcceptedAnswer": "<p>I've found a solution, using python-mpv, a wrapper for <a href=\"https://mpv.io\" rel=\"nofollow noreferrer\">mpv.io</a></p>\n<pre><code>from pynput.keyboard import Key, Listener\nimport mpv\nspeed=1\n\n#quick function to change speed via keyboard. \ndef on_press(key):\n\n    global speed\n\n    if key.char == 'f' :\n        speed=speed-0.1\n        player.speed=speed\n    if key.char == 'g' :\n        speed=speed+0.1\n        player.speed=speed\n\nplayer = mpv.MPV(ytdl=True)\nplayer.play('/Users/regvardy/mediapipe_faceswap-main/test.wav')\nwith Listener(\n        on_press=on_press) as listener:\n    listener.join()\nwhile True:\n    \n    player.speed=speed\n</code></pre>\n<p>I haven't tested it for stability yet.</p>\n<p>It feels like a workaround rather than me actually finding out how to do it so I may try and find a different solution.</p>\n"}
{"Id": 72277275, "PostTypeId": 1, "Title": "How to monitor per-process network usage in Python?", "Body": "<p>I'm looking to troubleshoot my internet issue so I need a way to track both my latency and which application is using how much network bandwidth.</p>\n<p>I've already sorted out checking latency, but now I need a way to monitor each process' network usage (KB/s), like how it appears in Windows Task Manager.</p>\n<p>Before you suggest a program, unless it's able to record the values with a timestamp then that's not what I'm looking for. I'm asking for a Pythonic way because I need to record the network bandwidth and latency values at the same time so I can figure out if a specific process is causing latency spikes.</p>\n<p>So here's the info I need:</p>\n<p>Time | Process ID | Process Name | Down Usage | Up Usage | Network Latency |</p>\n<p>Also, please don't link to another Stackoverflow question unless you know their solution works. I've looked through plenty already and none of them work, which is why I'm asking again.</p>\n", "AcceptedAnswerId": 72310057, "AcceptedAnswer": "<p>Following the third section of <a href=\"https://www.thepythoncode.com/article/make-a-network-usage-monitor-in-python\" rel=\"nofollow noreferrer\">this guide</a> provided me with all of the information listed in the post, minus latency. Given that you said you already had measuring latency figured out, I assume this isn't an issue.</p>\n<p>Logging this to csv/json/whatever is pretty easy, as all of the information is stored in panda data frames.</p>\n<p>As this shows the time the process was created, you can use datetime to generate a new timestamp at the time of logging.</p>\n<p>I tested this by logging to a csv after the printing_df variable was initialized, and had no issues.</p>\n"}
{"Id": 71102876, "PostTypeId": 1, "Title": "in ipython how do I accept and use an autocomplete suggestion?", "Body": "<p>I'm using Python 3.8.9 with IPython 8.0.1 on macOS. When I type anything whatsoever, it displays a predicted suggestion based on past commands. Cool.</p>\n<p>However, how do I actually accept that suggestion? I tried the obvious: tab, which does <em>not</em> accept the suggestion, but rather opens up a menu with <em>different</em> suggestions, while the original suggestion is still there (see screenshot).</p>\n<p>I also tried space, and return, but both of those act as if the suggestion was never made. How the heck do I actually <em>use</em> the ipython autosuggestion? Or is tab supposed to work and something is wrong with my ipython build or something?</p>\n<p><a href=\"https://i.stack.imgur.com/0x5Au.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/0x5Au.png\" alt=\"enter image description here\" /></a></p>\n", "AcceptedAnswerId": 71459528, "AcceptedAnswer": "<p><code>CTRL-E</code>, <code>CTRL-F</code>, or <code>Right Arrow Key</code>\n<a href=\"https://ipython.readthedocs.io/en/6.x/config/shortcuts/index.html\" rel=\"noreferrer\">https://ipython.readthedocs.io/en/6.x/config/shortcuts/index.html</a></p>\n"}
{"Id": 71803409, "PostTypeId": 1, "Title": "VSCode: how to interrupt a running Python test?", "Body": "<p>I'm using VSCode Test Explorer to run my Python unit tests. There was a bug in my code and my tested method never finishes.</p>\n<p>How do I interrupt my test? I can't find how to do it using the GUI. I had to close VSCode to interrupt it.</p>\n<p>I'm using pytest framework.</p>\n", "AcceptedAnswerId": 71803605, "AcceptedAnswer": "<p>Silly me, here is the <em>Stop button</em> at the top right of the the Testing tab:</p>\n<p><a href=\"https://i.stack.imgur.com/a71uQ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/a71uQ.png\" alt=\"Test stop button\" /></a></p>\n"}
{"Id": 71630563, "PostTypeId": 1, "Title": "Syntax for making objects callable in python", "Body": "<p>I understand that in python user-defined objects can be made callable by defining a <code>__call__()</code> method in the class definition. For example,</p>\n<pre><code>class MyClass:\n  def __init__(self):\n    pass\n\n  def __call__(self, input1):\n    self.my_function(input1)\n\n  def my_function(self, input1):\n    print(f&quot;MyClass - print {input1}&quot;)\n\nmy_obj = MyClass()\n# same as calling my_obj.my_function(&quot;haha&quot;)\nmy_obj(&quot;haha&quot;) # prints &quot;MyClass - print haha&quot;\n</code></pre>\n<p>I was looking at how <code>pytorch</code> makes the <code>forward()</code> method of a <code>nn.Module</code> object be called implicitly when the object is called and saw some syntax I didn't understand.</p>\n<p>In <a href=\"https://github.com/pytorch/pytorch/blob/1c5a8125798392f8d7c57e88735f43a14ae0beca/torch/nn/modules/module.py#L1156\" rel=\"noreferrer\">the line</a> that supposedly defines the <code>__call__</code> method the syntax used is,</p>\n<pre><code>__call__ : Callable[..., Any] = _call_impl\n</code></pre>\n<p>This seemed like a combination of an annotation (keyword <code>Callable[</code> following <code>:</code> ignored by python) and a value of <code>_call_impl</code> which we want to be called when <code>__call__</code> is invoked, and my guess is that this is a shorthand for,</p>\n<pre><code>def __call__(self, *args, **kwargs):\n    return self._call_impl(*args, **kwargs)\n</code></pre>\n<p>but wanted to understand clearly how this method of defining functions worked.</p>\n<p>My question is: When would we want to use such a definition of callable attributes of a class instead of the usual <code>def myfunc(self, *args, **kwargs)</code></p>\n", "AcceptedAnswerId": 71630606, "AcceptedAnswer": "<p>Functions are normal first-class objects in python. The name to with which you define a function object, e.g. with a <code>def</code> statement, is not set in stone, any more than it would be for an <code>int</code> or <code>list</code>. Just as you can do</p>\n<pre><code>a = [1, 2, 3]\nb = a\n</code></pre>\n<p>to access the elements of <code>a</code> through the name <code>b</code>, you can do the same with functions. In your first example, you could replace</p>\n<pre><code>def __call__(self, input1):\n    self.my_function(input1)\n</code></pre>\n<p>with the much simpler</p>\n<pre><code>__call__ = my_function\n</code></pre>\n<p>You would need to put this line after the definition of <code>my_function</code>.</p>\n<p>The key differences between the two implementations is that <code>def __call__(...</code> creates a new function. <code>__call__ = ...</code> simply binds the name <code>__call__</code> to the same object as <code>my_function</code>. The noticeable difference is that if you do <code>__call__.__name__</code>, the first version will show <code>__call__</code>, while the second will show <code>my_function</code>, since that's what gets assigned by a <code>def</code> statement.</p>\n"}
{"Id": 71823279, "PostTypeId": 1, "Title": "Python Read huge file line per line and send it to multiprocessing or thread", "Body": "<p>I have been trying to get my code to work for many days,\nI am desperate.\nI've scoured the internet, but I still can't find it.</p>\n<p>I have a text file encoded in &quot;latin-1&quot; of 9GB -&gt; 737 022 387 lines, each line contains a string.</p>\n<p>I would like to read each line and send them in an http PUT request that waits for a response, and returns TRUE or FALSE if the response is 200 or 400\nThe PUT request takes about 1 to 3 seconds, so to speed up the processing time I would like to use either a Thread or a multiprocessing.</p>\n<p>To start, I simulate my PUT request with a sleep of 3 seconds.\nand even that I can't get it to work</p>\n<p>This code split my string into char, i don't know why...</p>\n<pre><code>from multiprocessing import Pool\nfrom time import sleep\n\n\ndef process_line(line):\n   sleep(3)\n   print(line)\n   return True\n\nif __name__ == &quot;__main__&quot;:\n    pool = Pool(2)\n    peon =  open(r'D:\\txtFile',encoding=&quot;latin-1&quot;)\n    for line in peon:\n        res = pool.map(process_line,line )\n        print(res)\n</code></pre>\n<p>This give error : TypeError: process_line() takes 1 positional argument but 17 were given</p>\n<pre><code>import multiprocessing\nfrom multiprocessing import Pool\nfrom time import sleep\n\n\ndef process_line(line):\n   sleep(3)\n   print(line)\n   return True\n\nif __name__ == &quot;__main__&quot;:\n    pool = Pool(2)\n    with open(r&quot;d:\\txtFile&quot;,encoding=&quot;latin-1&quot;) as file:\n        res = pool.apply(process_line,file.readline() )\n        print(res)\n</code></pre>\n<p>that : Crash the computer</p>\n<pre><code>from multiprocessing import Pool\nfrom time import sleep\n\n\ndef process_line(line):\n   sleep(3)\n   print(line)\n   return True\n\nif __name__ == &quot;__main__&quot;:\n    pool = Pool(2)\n    peon =  open(r'D:\\txtFile',encoding=&quot;latin-1&quot;)\n    for line in peon:\n        res = pool.map(process_line,peon )\n        print(res)\n</code></pre>\n", "AcceptedAnswerId": 71824107, "AcceptedAnswer": "<p>Although the problem seems unrealistic though. shooting 737,022,387 requests! calculate how many months it'll take from single computer!!</p>\n<p>Still, Better way to do this task is to read line by line from file in a separate thread and insert into a queue. And then multi-process the queue.</p>\n<p><strong>Solution 1:</strong></p>\n<pre class=\"lang-py prettyprint-override\"><code>from multiprocessing import Queue, Process\nfrom threading import Thread\nfrom time import sleep\n\nurls_queue = Queue()\nmax_process = 4\n\ndef read_urls():\n    with open('urls_file.txt', 'r') as f:\n        for url in f:\n            urls_queue.put(url.strip())\n            print('put url: {}'.format(url.strip()))\n\n    # put DONE to tell send_request_processor to exit\n    for i in range(max_process):\n        urls_queue.put(&quot;DONE&quot;)\n\n\ndef send_request(url):\n    print('send request: {}'.format(url))\n    sleep(1)\n    print('recv response: {}'.format(url))\n\n\ndef send_request_processor():\n    print('start send request processor')\n    while True:\n        url = urls_queue.get()\n        if url == &quot;DONE&quot;:\n            break\n        else:\n            send_request(url)\n\n\ndef main():\n    file_reader_thread = Thread(target=read_urls)\n    file_reader_thread.start()\n\n    procs = []\n    for i in range(max_process):\n        p = Process(target=send_request_processor)\n        procs.append(p)\n        p.start()\n\n    for p in procs:\n        p.join()\n\n    print('all done')\n    # wait for all tasks in the queue\n    file_reader_thread.join()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<p>Demo: <a href=\"https://onlinegdb.com/Elfo5bGFz\" rel=\"nofollow noreferrer\">https://onlinegdb.com/Elfo5bGFz</a></p>\n<p><strong>Solution 2:</strong></p>\n<p>You can use <a href=\"https://www.tornadoweb.org/en/stable/queues.html\" rel=\"nofollow noreferrer\">tornado</a> asynchronous networking library</p>\n<pre class=\"lang-py prettyprint-override\"><code>from tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.queues import Queue\n\nq = Queue(maxsize=2)\n\nasync def consumer():\n    async for item in q:\n        try:\n            print('Doing work on %s' % item)\n            await gen.sleep(0.01)\n        finally:\n            q.task_done()\n\nasync def producer():\n    with open('urls_file.txt', 'r') as f:\n        for url in f:\n            await q.put(url)\n            print('Put %s' % item)\n\nasync def main():\n    # Start consumer without waiting (since it never finishes).\n    IOLoop.current().spawn_callback(consumer)\n    await producer()     # Wait for producer to put all tasks.\n    await q.join()       # Wait for consumer to finish all tasks.\n    print('Done')\n    # producer and consumer can run in parallel\n\nIOLoop.current().run_sync(main)\n</code></pre>\n"}
{"Id": 71656644, "PostTypeId": 1, "Title": "Python type hint for Iterable[str] that isn't str", "Body": "<p>In Python, is there a way to distinguish between strings and other iterables of strings?</p>\n<p>A <code>str</code> is valid as an <code>Iterable[str]</code> type, but that may not be the correct input for a function. For example, in this trivial example that is intended to operate on sequences of filenames:</p>\n<pre><code>from typing import Iterable\n\ndef operate_on_files(file_paths: Iterable[str]) -&gt; None:\n    for path in file_paths:\n        ...\n</code></pre>\n<p>Passing in a single filename would produce the wrong result but would not be caught by type checking. I know that I can check for string or byte types at runtime, but I want to know if it's possible to catch silly mistakes like that with a type-checking tool.</p>\n<p>I've looked over the <code>collections.abc</code> module and there doesn't seem to be any abc that would include typical iterables (e.g. lists, tuples) but exclude strings. Similarly, for the <code>typing</code> module, there doesn't seem to be a type for iterables that don't include strings.</p>\n", "AcceptedAnswerId": 71657094, "AcceptedAnswer": "<h2>As of March 2022, the answer is <strong>no</strong>.</h2>\n<p>This issue has been discussed since at least July 2016. On a proposal to distinguish between <code>str</code> and <code>Iterable[str]</code>, <a href=\"https://github.com/python/typing/issues/256\" rel=\"nofollow noreferrer\">Guido van Rossum</a> writes:</p>\n<blockquote>\n<p>Since <code>str</code> <em>is</em> a valid iterable of <code>str</code> this is tricky. Various proposals have been made but they don't fit easily in the type system.</p>\n</blockquote>\n<p><strong>You'll need to list out all of the types that you want your functions to accept explicitly</strong>, using <code>Union</code> (pre-3.10) or <code>|</code> (3.10 and higher).</p>\n<p>e.g. For pre-3.10, use:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from typing import Union\n## Heading ##\ndef operate_on_files(file_paths: Union[TypeOneName, TypeTwoName, etc.]) -&gt; None:\n    for path in file_paths:\n        ...\n</code></pre>\n<p>For 3.10 and higher, use:</p>\n<pre class=\"lang-py prettyprint-override\"><code>## Heading ##\ndef operate_on_files(file_paths: TypeOneName | TypeTwoName | etc.) -&gt; None:\n    for path in file_paths:\n        ...\n</code></pre>\n<p>If you happen to be using Pytype, <a href=\"https://github.com/google/pytype/blob/main/docs/faq.md#why-doesnt-str-match-against-string-iterables\" rel=\"nofollow noreferrer\">it will not treat <code>str</code> as an <code>Iterable[str]</code></a> (as pointed out by <a href=\"https://stackoverflow.com/users/12671057/kelly-bundy\">Kelly Bundy</a>). But, this behavior is typechecker-specific, and isn't widely supported in other typecheckers.</p>\n"}
{"Id": 71818149, "PostTypeId": 1, "Title": "POST request gets blocked on Python backend. GET request works fine", "Body": "<p>I am building a web app where the front-end is done with Flutter while the back-end is with Python.\nGET requests work fine while POST requests get blocked because of CORS, I get this error message:</p>\n<pre><code>Access to XMLHttpRequest at 'http://127.0.0.1:8080/signal' from origin 'http://localhost:57765' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n</code></pre>\n<p>Below is my flutter function I used to send GET and POST requests:</p>\n<pre><code>  Future&lt;dynamic&gt; sendResponse() async {\n    final url = 'http://127.0.0.1:8080/signal';\n    var data = {\n      &quot;signal&quot;: '8',\n    };\n    var header = {\n      'Access-Control-Allow-Origin': '*',\n      &quot;Accept&quot;: &quot;application/x-www-form-urlencoded, '*'&quot;\n    };\n\n\n    http.Response response = await http.post(Uri.parse(url), body: data, headers: header);//http.post(Uri.parse(url), body: data, headers: header);//http.get(Uri.parse(url));\n    if (response.statusCode == 200) {\n      print(json.decode(response.body));\n      return jsonDecode(response.body);\n      //print(json.decode(credentials.body));\n    } else {\n      print(response.statusCode);\n      throw Exception('Failed to load Entry');\n    }\n\n   // var ResponseFromPython = await response.body;//jsonDecode(credentials.body);\n\n   // return ResponseFromPython;\n  }\n</code></pre>\n<p>Below is my Python backend code using Flask:</p>\n<pre><code>   from flask import Flask,jsonify, request, make_response\n   import json\n\n\n   from flask_cors import CORS, cross_origin\n\n\n   #declared an empty variable for reassignment\n   response = ''\n\n   app = Flask(__name__)\n\n   #CORS(app, resources={r&quot;/signal&quot;: {&quot;origins&quot;: &quot;*, http://localhost:59001&quot;}}) \n   #http://localhost:52857\n   #CORS(app, origins=['*'])\n   app.config['CORS_HEADERS'] = ['Content-Type','Authorization']\n\n\n\n   @app.route(&quot;/&quot;)\n   def index():\n    \n    return &quot;Congratulations, it worked&quot;\n\n   @app.route(&quot;/signal&quot;, methods = ['POST', 'GET']) #,\n   @cross_origin(origins='http://localhost:57765',headers=['Content-Type','Authorization', \n   'application/x-www-form-urlencoded','*'], upports_credentials=True)# allow all origins all \n   methods.\n   def multbytwo():\n       &quot;&quot;&quot;multiple signal by 2 just to test.&quot;&quot;&quot;\n       global response\n       if (request.method=='POST'):\n       # request.headers.add(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)\n           request_data = request.data #getting the response data\n           request_data = json.loads(request_data.decode('utf-8')) #converting it from json to key \n   value pair\n           comingSignal = request_data['signal']\n           response = make_response(comingSignal, 201)#jsonify(comingSignal*2)\n           response.headers.add('Access-Control-Allow-Origin', '*')\n           response.headers.add('Access-Control-Allow-Methods&quot;, &quot;DELETE, POST, GET, OPTIONS')\n           response.headers.add('Access-Control-Allow-Headers&quot;, &quot;Content-Type, Authorization, X- \n  Requested-With')\n           return response\n       else:\n           try:\n        #scaler = request.args.get(&quot;signal&quot;)\n               out = 9 * 2 \n         \n               response = jsonify(out)\n               response.headers.add(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;) \n               return response #sending data back to your frontend app\n\n           except ValueError:\n               return &quot;invalid input xyz&quot;\n\n   if __name__ == &quot;__main__&quot;:\n       app.run(host=&quot;127.0.0.1&quot;, port=8080, debug=True)\n</code></pre>\n<p>Below are the troubleshooting steps I made:\n<strong>-Added the flask_CORS package in python</strong>\nI tried here different combination from using general parameters like <code>CORS(app, resources={r&quot;/signal&quot;: {&quot;origins&quot;: &quot;*&quot;}}) </code> did not help. Also tried the decorator <code>@cross-origin</code> and did not help</p>\n<p><strong>-Added some headers to the response itself to indicate that it accepts cross-origin</strong>\nYou see in my python code I tried adding a lot of headers to the response, nothing seem to respond.</p>\n<p><strong>-Tried installing an extension in Chrome that by-passes the CORS check</strong>\nI tried the <code>allow CORS</code> and <code>CORS unblock</code> extensions and I used the steps described in this answer: <a href=\"https://stackoverflow.com/questions/67958169/how-chrome-extensions-be-enabled-when-flutter-web-debugging\">How chrome extensions be enabled when flutter web debugging?</a>. Although these extensions are supposed to add the CORS allow header to the response, I still got the same error.</p>\n<p>I still do not fully understand the CORS concept but I tried a lot of work-arounds and nothing works! please help.</p>\n", "AcceptedAnswerId": 71882248, "AcceptedAnswer": "<p>I finally figured out what was going on.\n<strong>First I disabled the same origin policy in chrome using this command:</strong> this is run clicking the start button in windows and typing this command directly..</p>\n<pre><code>chrome.exe  --disable-site-isolation-trials --disable-web-security --user-data-dir=&quot;D:\\anything&quot;\n</code></pre>\n<p>This fired a separate chrome window that does not block cross-origin, we will call this the CORS free window. This allowed me to finally communicate with my python code and understand what is going on.\n<a href=\"https://i.stack.imgur.com/lfi1i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lfi1i.png\" alt=\"You can see the \" /></a></p>\n<p>You can see that the chrome default setting were not even showing me anything related to the response, just showing a 500 code error.</p>\n<p><strong>I copied the localhost link and port and pasted them in my other CORS free chrome window</strong>\nThe other CORS free chrome window showed helpful information:\n<a href=\"https://i.stack.imgur.com/z2JI3.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/z2JI3.png\" alt=\"enter image description here\" /></a></p>\n<p><strong>It was a simple JSON decoding error!</strong> I went back to my flutter code and I changed the http post request, adding a <code>jsonEncode</code> function on the post body:</p>\n<pre><code>http.Response response = await http.post(Uri.parse(url), body:jsonEncode(data), headers: header);\n</code></pre>\n<p>Now the post request returns a correct response on the default chrome settings.\n<a href=\"https://i.stack.imgur.com/1PvlY.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1PvlY.png\" alt=\"enter image description here\" /></a>\nIt was just this CORS blocking the response completely that made me handi-capped.</p>\n"}
{"Id": 72782100, "PostTypeId": 1, "Title": "For loop in c# vs For loop in python", "Body": "<p>I was writing a method that would calculate the value of e^x. The way I implemented this in python was as follows.</p>\n<pre><code>import math\n\ndef exp(x):\n    return sum([\n        x**n/math.factorial(n)\n        for n in range(0, 100)\n    ])\n</code></pre>\n<p>This would return the value of e^x very well. But when I tried to implement the same method in c#, it didn't output the same value as it did in python. The following was the implementation in c#.</p>\n<pre><code>static double exp(int x)\n{\n    double FinalAnswer = 0;\n    for (int j = 0; j &lt;= 100; j++)\n    {\n        FinalAnswer += (Math.Pow(x, j))/Factorial(j);\n    }\n    return FinalAnswer;\n}\n</code></pre>\n<p>The output for this code was an infinity symbol at first. To resolve this I just reduced the number of times the loop ran. The output of the code in c# where the loop only ran 10 times was pretty close to the output in python where the loop ran 100 times. My question is that what is going on between the two loops in different programming languages. At first I thought that the expression that I was using in my method to calculate e^x was converging quickly. But how does a loop that runs 10 times produce an output that matches the output of a loop that runs 100 times.</p>\n<p>Also, When I increased the for loop in c# to 20 and 30, the values of e^x for x &gt; 3 were way off. Could someone explain what is going on here?</p>\n", "AcceptedAnswerId": 72782395, "AcceptedAnswer": "<p>What you're likely running into here is <strong>integer overflow</strong> with the C# version of the Factorial function (at least your implementation of it, or wherever its coming from).</p>\n<p>In C#, an <code>int</code> is a numerical type stored in 32 bits of memory, which means it's bounded by <code>-2^31 &lt;= n &lt;= 2^31 - 1</code> which is around +/- 2.1 billion. You could try using a <code>long</code> type, which is a 64 bit numerical type, however for even larger upper bounds in your for loop, like getting close to 100, you're going to overflow <code>long</code> as well.</p>\n<p>When you run the Factorial function in C#, it starts off normally for the first little while, however if you keep going, you'll see that it all of a sudden jumps into negative numbers, and if you keep going even further than that, it'll get to 0 and stop changing. You're seeing the output of infinity due to division by 0, and C# has a way of handling that with doubles; that being to just return <code>double.PositiveInfinity</code>.</p>\n<p>The reason why this doesn't happen in python is that it uses a variable number of bits to store its numerical values.</p>\n<p><strong>Added note:</strong> What you might also want to try is using a Factorial function that works with the <code>double</code> type instead of <code>int</code> or <code>long</code>, however by doing this, you'll lose precision on what the exact value is, but you get more range as the magnitude of the number you can store is larger</p>\n<p><strong>Further Note:</strong> As mentioned in the comments, C# has a type called <code>BigInteger</code> which is designed to handle huge numbers like the values you would expect from large inputs to a Factorial function. You can find a reference to the BigInteger docs <a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.numerics.biginteger?view=net-6.0\" rel=\"nofollow noreferrer\">here</a></p>\n<hr />\n<p>What you can do is calculate each component of the factorial function separately with the power you're using. Here's what I mean:</p>\n<pre><code>public decimal Exp(decimal power, int accuracy = 100)\n{\n    decimal runningTotal = 1;\n    decimal finalValue = 1;\n    for (int i = 1; i &lt;= accuracy; i++)\n    {\n        runningTotal *= power/i;\n        finalValue += runningTotal;\n    }\n    return finalValue;\n}\n</code></pre>\n"}
{"Id": 71671866, "PostTypeId": 1, "Title": "Python: What is the difference between `lambda` and `lambda_`?", "Body": "<p>I know the function of <code>lambda:</code> and <code>lambda var:</code> , but what does <code>lambda_:</code> means acutally?</p>\n", "AcceptedAnswerId": 71671890, "AcceptedAnswer": "<p><code>lambda_</code> is just a variable name, like any other. Like <code>foo</code> or <code>x</code>.</p>\n<p>If you saw:</p>\n<pre><code>lambda_: Something\n</code></pre>\n<p>Then that is actually a <em>variable annotation</em>, for type hints, so the same as:</p>\n<pre><code>num: int\nnum = 0\n</code></pre>\n"}
{"Id": 71641609, "PostTypeId": 1, "Title": "How does CPython implement os.environ?", "Body": "<p>I was looking through <a href=\"https://github.com/python/cpython/blob/main/Lib/os.py\" rel=\"noreferrer\">source</a> and noticed that it references a variable <code>environ</code> in methods before its defined:</p>\n<pre><code>def _createenviron():\n    if name == 'nt':\n        # Where Env Var Names Must Be UPPERCASE\n        def check_str(value):\n            if not isinstance(value, str):\n                raise TypeError(&quot;str expected, not %s&quot; % type(value).__name__)\n            return value\n        encode = check_str\n        decode = str\n        def encodekey(key):\n            return encode(key).upper()\n        data = {}\n        for key, value in environ.items():\n            data[encodekey(key)] = value\n    else:\n        # Where Env Var Names Can Be Mixed Case\n        encoding = sys.getfilesystemencoding()\n        def encode(value):\n            if not isinstance(value, str):\n                raise TypeError(&quot;str expected, not %s&quot; % type(value).__name__)\n            return value.encode(encoding, 'surrogateescape')\n        def decode(value):\n            return value.decode(encoding, 'surrogateescape')\n        encodekey = encode\n        data = environ\n    return _Environ(data,\n        encodekey, decode,\n        encode, decode)\n\n# unicode environ\nenviron = _createenviron()\ndel _createenviron\n</code></pre>\n<p>So how does <code>environ</code> get setup? I cant seem to reason about where its initialized and declared so that <code>_createenviron</code> can use it?</p>\n", "AcceptedAnswerId": 71682620, "AcceptedAnswer": "<p>TLDR search for <code>from posix import *</code> in <code>os</code> module content.</p>\n<p>The <code>os</code> module imports all public symbols from <code>posix</code> (Unix) or <code>nt</code> (Windows) low-level module at the beginning of <code>os.py</code>.</p>\n<p><code>posix</code> exposes <code>environ</code> as a plain Python <code>dict</code>.\n<code>os</code> wraps it with <code>_Environ</code> dict-like object that updates environment variables on <code>_Environ</code> items changing.</p>\n"}
{"Id": 72235819, "PostTypeId": 1, "Title": "How can I redirect module imports with modern Python?", "Body": "<p>I am maintaining a python package in which I did some restructuring. Now, I want to support clients who still do <code>from my_package.old_subpackage.foo import Foo</code> instead of the new <code>from my_package.new_subpackage.foo import Foo</code>, without explicitly reintroducing many files that do the forwarding.  (<code>old_subpackage</code> still exists, but no longer contains <code>foo.py</code>.)</p>\n<p>I have learned that there are &quot;loaders&quot; and &quot;finders&quot;, and my impression was that I should implement a <em>loader</em> for my purpose, but I only managed to implement a <em>finder</em> so far:</p>\n<pre class=\"lang-py prettyprint-override\"><code>RENAMED_PACKAGES = {\n    'my_package.old_subpackage.foo': 'my_package.new_subpackage.foo',\n}\n\n# TODO: ideally, we would not just implement a &quot;finder&quot;, but also a &quot;loader&quot;\n# (using the importlib.util.module_for_loader decorator); this would enable us\n# to get module contents that also pass identity checks\nclass RenamedFinder:\n\n    @classmethod\n    def find_spec(cls, fullname, path, target=None):\n        renamed = RENAMED_PACKAGES.get(fullname)\n        if renamed is not None:\n            sys.stderr.write(\n                f'WARNING: {fullname} was renamed to {renamed}; please adapt import accordingly!\\n')\n            return importlib.util.find_spec(renamed)\n        return None\n\nsys.meta_path.append(RenamedFinder())\n</code></pre>\n<p><a href=\"https://docs.python.org/3.5/library/importlib.html#importlib.util.module_for_loader\" rel=\"nofollow noreferrer\">https://docs.python.org/3.5/library/importlib.html#importlib.util.module_for_loader</a> and related functionality, however, seem to be deprecated.  I know it's not a very pythonic thing I am trying to achieve, but I would be glad to learn that it's achievable.</p>\n", "AcceptedAnswerId": 72244240, "AcceptedAnswer": "<p>On import of your package's <code>__init__.py</code>, you can place whatever objects you want into <code>sys.modules</code>, the values you put in there will be returned by <code>import</code> statements:</p>\n<pre><code>from . import new_package\nfrom .new_package import module1, module2\nimport sys\n\nsys.modules[&quot;my_lib.old_package&quot;] = new_package\nsys.modules[&quot;my_lib.old_package.module1&quot;] = module1\nsys.modules[&quot;my_lib.old_package.module2&quot;] = module2\n</code></pre>\n<p>If someone now uses <code>import my_lib.old_package</code> or <code>import my_lib.old_package.module1</code> they will obtain a reference to <code>my_lib.new_package.module1</code>. Since the import machinery already finds the keys in the <code>sys.modules</code> dictionary, it never even begins looking for the old files.</p>\n<p>If you want to avoid importing all the submodules immediately, you can emulate a bit of lazy loading by placing a module with a <code>__getattr__</code> in <code>sys.modules</code>:</p>\n<pre><code>from types import ModuleType\nimport importlib\nimport sys\n\nclass LazyModule(ModuleType):\n def __init__(self, name, mod_name):\n  super().__init__(name)\n  self.__mod_name = name\n\n def __getattr__(self, attr):\n  if &quot;_lazy_module&quot; not in self.__dict__:\n    self._lazy_module = importlib.import(self.__mod_name, package=&quot;my_lib&quot;)\n  return self._lazy_module.__getattr__(attr)\n\nsys.modules[&quot;my_lib.old_package&quot;] = LazyModule(&quot;my_lib.old_package&quot;, &quot;my_lib.new_package&quot;)\n</code></pre>\n"}
{"Id": 72795799, "PostTypeId": 1, "Title": "How to solve 403 error with Flask in Python?", "Body": "<p>I made a simple server using python flask in mac. Please find below the code.</p>\n<pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/', methods=['GET', 'POST'])\ndef hello():\n    print(&quot;request received&quot;)\n    return &quot;Hello world!&quot;\n\n    \nif __name__ == &quot;__main__&quot;:\n    app.run(debug=True)\n</code></pre>\n<p>I run it using <code>python3 main.py</code> command.</p>\n<p>While calling above API on url  <code>http://localhost:5000/</code> from Postman using GET / POST method, it always returns http 403 error.</p>\n<blockquote>\n<p>Python version : 3.8.9</p>\n<p>OS : Mac OS 12.4</p>\n<p>Flask : 2.1.2</p>\n</blockquote>\n", "AcceptedAnswerId": 72797062, "AcceptedAnswer": "<p>Mac OSX Monterey (12.x) currently uses ports 5000 and 7000 for its Control centre hence the issue.</p>\n<p>Try running your app from port other than <code>5000</code> and <code>7000</code></p>\n<p>use this:</p>\n<pre><code>if __name__ == &quot;__main__&quot;:\n    app.run(port=8000, debug=True)\n</code></pre>\n<p>and then run your flask file, eg: <code>app.py</code></p>\n<p><code>python app.py</code></p>\n<p>You can also run using the <code>flask</code> command line interface using this command provided you have set the environment variable necessary for flask CLI.</p>\n<p><code>flask run --port 8000</code></p>\n<p>You can also turn off <code>AirPlay Receiver</code> in the <code>Sharing</code> via System Preference.</p>\n<p>Related discussion here: <a href=\"https://developer.apple.com/forums/thread/682332\" rel=\"noreferrer\">https://developer.apple.com/forums/thread/682332</a></p>\n<p><strong>Update(November 2022):</strong></p>\n<p>Mac OSX Ventura(13.x) still has this problem and is fixed with the change in default port as mentioned above.</p>\n"}
{"Id": 71739870, "PostTypeId": 1, "Title": "How to install Python 2 on macOS 12.3+", "Body": "<p>macOS 12.3 update drops Python 2 and replaces it with version 3:</p>\n<p><a href=\"https://developer.apple.com/documentation/macos-release-notes/macos-12_3-release-notes\" rel=\"noreferrer\">https://developer.apple.com/documentation/macos-release-notes/macos-12_3-release-notes</a></p>\n<blockquote>\n<p>Python\nDeprecations\nPython 2.7 was removed from macOS in this update. Developers should use Python 3 or an alternative language instead. (39795874)</p>\n</blockquote>\n<p>I understand we need to migrate to version 3, but in the meantime we still need version 2. Homebrew does not seem to have it anymore:</p>\n<pre class=\"lang-none prettyprint-override\"><code>brew install python@2.7\nWarning: No available formula with the name &quot;python@2.7&quot;. Did you mean python@3.7, python@3.9, python@3.8, python@3.10 or python-yq?\n\nbrew install python2\nWarning: No available formula with the name &quot;python2&quot;. Did you mean ipython, bpython, jython or cython?\n</code></pre>\n<p>What gives?</p>\n", "AcceptedAnswerId": 71740144, "AcceptedAnswer": "<p>You can get any Python release, including the last Python 2, from the official download site:</p>\n<p><a href=\"https://www.python.org/downloads/release/python-2718/\" rel=\"noreferrer\">https://www.python.org/downloads/release/python-2718/</a> \u2192 <a href=\"https://www.python.org/ftp/python/2.7.18/python-2.7.18-macosx10.9.pkg\" rel=\"noreferrer\">macOS 64-bit installer</a></p>\n"}
{"Id": 72236445, "PostTypeId": 1, "Title": "How can I wrap a python function in a way that works with with inspect.signature?", "Body": "<p>Some uncontroversial background experimentation up front:</p>\n<pre><code>import inspect\n\ndef func(foo, bar):\n  pass\n\nprint(inspect.signature(func))  # Prints &quot;(foo, bar)&quot; like you'd expect\n\ndef decorator(fn):\n  def _wrapper(baz, *args, *kwargs):\n    fn(*args, **kwargs)\n\n  return _wrapper\n\nwrapped = decorator(func)\nprint(inspect.signature(wrapped))  # Prints &quot;(baz, *args, **kwargs)&quot; which is totally understandable\n</code></pre>\n<h2>The Question</h2>\n<p>How can implement my decorator so that <code>print(inspect.signature(wrapped))</code> spits out &quot;(baz, foo, bar)&quot;?  Can I build <code>_wrapper</code> dynamically somehow by adding the arguments of whatever <code>fn</code> is passed in, then gluing <code>baz</code> on to the list?</p>\n<p>The answer is NOT</p>\n<pre><code>def decorator(fn):\n  @functools.wraps(fn)\n  def _wrapper(baz, *args, *kwargs):\n    fn(*args, **kwargs)\n\n  return _wrapper\n</code></pre>\n<p>That give &quot;(foo, bar)&quot; again - which is totally wrong.  Calling <code>wrapped(foo=1, bar=2)</code> is a type error - &quot;Missing 1 required positional argument: 'baz'&quot;</p>\n<p>I don't think it's necessary to be this pedantic, but</p>\n<pre><code>def decorator(fn):\n  def _wrapper(baz, foo, bar):\n    fn(foo=foo, bar=bar)\n\n  return _wrapper\n</code></pre>\n<p>Is also not the answer I'm looking for - I'd like the decorator to work for all functions.</p>\n", "AcceptedAnswerId": 72242606, "AcceptedAnswer": "<p>You can use <code>__signature__</code> (<a href=\"https://peps.python.org/pep-0362/\" rel=\"nofollow noreferrer\">PEP</a>) attribute to modify returned signature of wrapped object. For example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import inspect\n\n\ndef func(foo, bar):\n    pass\n\n\ndef decorator(fn):\n    def _wrapper(baz, *args, **kwargs):\n        fn(*args, **kwargs)\n\n    f = inspect.getfullargspec(fn)\n\n    fn_params = []\n    if f.args:\n        for a in f.args:\n            fn_params.append(\n                inspect.Parameter(a, inspect.Parameter.POSITIONAL_OR_KEYWORD)\n            )\n\n    if f.varargs:\n        fn_params.append(\n            inspect.Parameter(f.varargs, inspect.Parameter.VAR_POSITIONAL)\n        )\n\n    if f.varkw:\n        fn_params.append(\n            inspect.Parameter(f.varkw, inspect.Parameter.VAR_KEYWORD)\n        )\n\n    _wrapper.__signature__ = inspect.Signature(\n        [\n            inspect.Parameter(&quot;baz&quot;, inspect.Parameter.POSITIONAL_OR_KEYWORD),\n            *fn_params,\n        ]\n    )\n    return _wrapper\n\n\nwrapped = decorator(func)\nprint(inspect.signature(wrapped))\n</code></pre>\n<p>Prints:</p>\n<pre class=\"lang-py prettyprint-override\"><code>(baz, foo, bar)\n</code></pre>\n<hr />\n<p>If the func is:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def func(foo, bar, *xxx, **yyy):\n    pass\n</code></pre>\n<p>Then <code>print(inspect.signature(wrapped))</code> prints:</p>\n<pre class=\"lang-py prettyprint-override\"><code>(baz, foo, bar, *xxx, **yyy)\n</code></pre>\n"}
{"Id": 72193393, "PostTypeId": 1, "Title": "Find the value of variables to maximize return of function in Python", "Body": "<p>I'd want to achieve similar result as how the Solver-function in Excel is working. I've been reading of Scipy optimization and been trying to build a function which outputs what I would like to find the maximal value of. The equation is based on four different variables which, see my code below:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\nfrom scipy import optimize\n\ncols = {\n    'Dividend2': [9390, 7448, 177], \n    'Probability': [341, 376, 452], \n    'EV': [0.53, 0.60, 0.55], \n    'Dividend': [185, 55, 755], \n    'EV2': [123, 139, 544],\n}\n\ndf = pd.DataFrame(cols)\n\ndef myFunc(params):\n    &quot;&quot;&quot;myFunc metric.&quot;&quot;&quot;\n    (ev, bv, vc, dv) = params\n    df['Number'] = np.where(df['Dividend2'] &lt;= vc, 1, 0) \\\n                    + np.where(df['EV2'] &lt;= dv, 1, 0)\n    df['Return'] =  np.where(\n        df['EV'] &lt;= ev, 0, np.where(\n            df['Probability'] &gt;= bv, 0, df['Number'] * df['Dividend'] - (vc + dv)\n        )\n    )\n    return -1 * (df['Return'].sum())\n\nb1 = [(0.2,4), (300,600), (0,1000), (0,1000)]\nstart = [0.2, 600, 1000, 1000]\nresult = optimize.minimize(fun=myFunc, bounds=b1, x0=start)\nprint(result)\n</code></pre>\n<p>So I'd like to find the maximum value of the column Return in df when changing the variables ev,bv,vc &amp; dv. I'd like them to be between in the intervals of ev: 0.2-4, bv: 300-600, vc: 0-1000 &amp; dv: 0-1000.</p>\n<p>When running my code it seem like the function stops at x0.</p>\n", "AcceptedAnswerId": 72252081, "AcceptedAnswer": "<h1>Solution</h1>\n<p>I will use <code>optuna</code> library to give you a solution to the type of problem you are trying to solve. I have tried using <code>scipy.optimize.minimize</code> and it appears that the loss-landscape is probably quite flat in most places, and hence the tolerances enforce the minimizing algorithm (<code>L-BFGS-B</code>) to stop prematurely.</p>\n<ul>\n<li>Optuna Docs: <a href=\"https://optuna.readthedocs.io/en/stable/index.html\" rel=\"nofollow noreferrer\">https://optuna.readthedocs.io/en/stable/index.html</a></li>\n</ul>\n<p>With optuna, it rather straight forward. Optuna only requires an <code>objective</code> function and a <code>study</code>. The study send various <code>trials</code> to the <code>objective</code> function, which in turn, evaluates the metric of your choice.</p>\n<p>I have defined another metric function <code>myFunc2</code> by mostly removing the <code>np.where</code> calls, as you can do-away with them (reduces number of steps) and make the function slightly faster.</p>\n<pre class=\"lang-sh prettyprint-override\"><code># install optuna with pip\npip install -Uqq optuna\n</code></pre>\n<p>Although I looked into using a rather smooth loss landscape, sometimes it is necessary to visualize the landscape itself. The answer in section <code>B</code> elaborates on visualization. But, what if you want to use a smoother metric function? Section <strong><code>D</code></strong> sheds some light on this.</p>\n<p>Order of code-execution should be:</p>\n<ul>\n<li>Sections: <strong><code>C</code></strong> &gt;&gt; <strong><code>B</code></strong> &gt;&gt; <strong><code>B.1</code></strong> &gt;&gt; <strong><code>B.2</code></strong> &gt;&gt; <strong><code>B.3</code></strong> &gt;&gt; <strong><code>A.1</code></strong> &gt;&gt; <strong><code>A.2</code></strong> &gt;&gt; <strong><code>D</code></strong></li>\n</ul>\n<h2>A. Building Intuition</h2>\n<p>If you create a hiplot (also known as a plot with parallel-coordinates) with all the possible parameter values as mentioned in the <code>search_space</code> for Section <code>B.2</code>, and plot the lowest 50 outputs of <code>myFunc2</code>, it would look like this:</p>\n<p><a href=\"https://i.stack.imgur.com/MibyN.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MibyN.png\" alt=\"hiplot-search-space-subset\" /></a></p>\n<p>Plotting all such points from the <code>search_space</code> would look like this:</p>\n<p><a href=\"https://i.stack.imgur.com/mKXRa.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mKXRa.png\" alt=\"hiplot-search-space-full\" /></a></p>\n<h3>A.1. Loss Landscape Views for Various Parameter-Pairs</h3>\n<p>These figures show that mostly the loss-landscape is flat for any two of the four parameters <code>(ev, bv, vc, dv)</code>. This could be a reason why, only <strong><code>GridSampler</code></strong> (which brute-forces the searching process) does better, compared to the other two samplers (<code>TPESampler</code> and <code>RandomSampler</code>). Please click on any of the images below to view them enlarged. This could also be the reason why <code>scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)</code> fails right off the bat.</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/9UJ4h.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9UJ4h.png\" alt=\"01-dv-vc\" /></a> <br/><br/> <strong><code>01. dv-vc</code></strong></th>\n<th style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/seWOk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/seWOk.png\" alt=\"02-dv-bv\" /></a> <br/><br/> <strong><code>02. dv-bv</code></strong></th>\n<th style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/y2KnW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/y2KnW.png\" alt=\"03-dv-ev\" /></a> <br/><br/> <strong><code>03. dv-ev</code></strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/86hhs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/86hhs.png\" alt=\"04-bv-ev\" /></a> <br/><br/> <strong><code>04. bv-ev</code></strong></td>\n<td style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/9HDEy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9HDEy.png\" alt=\"05-cv-ev\" /></a> <br/><br/> <strong><code>05. cv-ev</code></strong></td>\n<td style=\"text-align: center;\"><a href=\"https://i.stack.imgur.com/sUXHd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sUXHd.png\" alt=\"06-vc-bv\" /></a> <br/><br/> <strong><code>06. vc-bv</code></strong></td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre class=\"lang-py prettyprint-override\"><code># Create contour plots for parameter-pairs\nstudy_name = &quot;GridSampler&quot;\nstudy = studies.get(study_name)\n\nviews = [(&quot;dv&quot;, &quot;vc&quot;), (&quot;dv&quot;, &quot;bv&quot;), (&quot;dv&quot;, &quot;ev&quot;), \n         (&quot;bv&quot;, &quot;ev&quot;), (&quot;vc&quot;, &quot;ev&quot;), (&quot;vc&quot;, &quot;bv&quot;)]\n\nfor i, (x, y) in enumerate(views):\n    print(f&quot;Figure: {i}/{len(views)}&quot;)\n    study_contour_plot(study=study, params=(x, y))\n</code></pre>\n<h3>A.2. Parameter Importance</h3>\n<p><a href=\"https://i.stack.imgur.com/IucEA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/IucEA.png\" alt=\"07-param-importance\" /></a></p>\n<pre class=\"lang-py prettyprint-override\"><code>study_name = &quot;GridSampler&quot;\nstudy = studies.get(study_name)\n\nfig = optuna.visualization.plot_param_importances(study)\nfig.update_layout(title=f'Hyperparameter Importances: {study.study_name}', \n                  autosize=False,\n                  width=800, height=500,\n                  margin=dict(l=65, r=50, b=65, t=90))\nfig.show()\n</code></pre>\n<h2>B. Code</h2>\n<p>Section <strong><code>B.3.</code></strong> finds the lowest metric <code>-88.333</code> for:</p>\n<ul>\n<li><code>{'ev': 0.2, 'bv': 500.0, 'vc': 222.2222, 'dv': 0.0}</code></li>\n</ul>\n<pre class=\"lang-py prettyprint-override\"><code>import warnings\nfrom functools import partial\nfrom typing import Iterable, Optional, Callable, List\n\nimport pandas as pd\nimport numpy as np\nimport optuna\nfrom tqdm.notebook import tqdm\n\nwarnings.filterwarnings(&quot;ignore&quot;, category=optuna.exceptions.ExperimentalWarning)\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nPARAM_NAMES: List[str] = [&quot;ev&quot;, &quot;bv&quot;, &quot;vc&quot;, &quot;dv&quot;,]\nDEFAULT_METRIC_FUNC: Callable = myFunc2\n\n\ndef myFunc2(params):\n    &quot;&quot;&quot;myFunc metric v2 with lesser steps.&quot;&quot;&quot;\n    global df # define as a global variable\n    (ev, bv, vc, dv) = params\n    df['Number'] = (df['Dividend2'] &lt;= vc) * 1 + (df['EV2'] &lt;= dv) * 1\n    df['Return'] =  (\n        (df['EV'] &gt; ev) \n        * (df['Probability'] &lt; bv) \n        * (df['Number'] * df['Dividend'] - (vc + dv))\n    )\n    return -1 * (df['Return'].sum())\n\n\ndef make_param_grid(\n        bounds: List[Tuple[float, float]], \n        param_names: Optional[List[str]]=None, \n        num_points: int=10, \n        as_dict: bool=True,\n    ) -&gt; Union[pd.DataFrame, Dict[str, List[float]]]:\n    &quot;&quot;&quot;\n    Create parameter search space.\n\n    Example:\n    \n        grid = make_param_grid(bounds=b1, num_points=10, as_dict=True)\n    \n    &quot;&quot;&quot;\n    if param_names is None:\n        param_names = PARAM_NAMES # [&quot;ev&quot;, &quot;bv&quot;, &quot;vc&quot;, &quot;dv&quot;]\n    bounds = np.array(bounds)\n    grid = np.linspace(start=bounds[:,0], \n                       stop=bounds[:,1], \n                       num=num_points, \n                       endpoint=True, \n                       axis=0)\n    grid = pd.DataFrame(grid, columns=param_names)\n    if as_dict:\n        grid = grid.to_dict()\n        for k,v in grid.items():\n            grid.update({k: list(v.values())})\n    return grid\n\n\ndef objective(trial, \n              bounds: Optional[Iterable]=None, \n              func: Optional[Callable]=None, \n              param_names: Optional[List[str]]=None):\n    &quot;&quot;&quot;Objective function, necessary for optimizing with optuna.&quot;&quot;&quot;\n    if param_names is None:\n        param_names = PARAM_NAMES\n    if (bounds is None):\n        bounds = ((-10, 10) for _ in param_names)\n    if not isinstance(bounds, dict):\n        bounds = dict((p, (min(b), max(b))) \n                        for p, b in zip(param_names, bounds))\n    if func is None:\n        func = DEFAULT_METRIC_FUNC\n\n    params = dict(\n        (p, trial.suggest_float(p, bounds.get(p)[0], bounds.get(p)[1])) \n        for p in param_names        \n    )\n    # x = trial.suggest_float('x', -10, 10)\n    return func((params[p] for p in param_names))\n\n\ndef optimize(objective: Callable, \n             sampler: Optional[optuna.samplers.BaseSampler]=None, \n             func: Optional[Callable]=None, \n             n_trials: int=2, \n             study_direction: str=&quot;minimize&quot;,\n             study_name: Optional[str]=None,\n             formatstr: str=&quot;.4f&quot;,\n             verbose: bool=True):\n    &quot;&quot;&quot;Optimizing function using optuna: creates a study.&quot;&quot;&quot;\n    if func is None:\n        func = DEFAULT_METRIC_FUNC\n    study = optuna.create_study(\n        direction=study_direction, \n        sampler=sampler, \n        study_name=study_name)\n    study.optimize(\n        objective, \n        n_trials=n_trials, \n        show_progress_bar=True, \n        n_jobs=1,\n    )\n    if verbose:\n        metric = eval_metric(study.best_params, func=myFunc2)\n        msg = format_result(study.best_params, metric, \n                            header=study.study_name, \n                            format=formatstr)\n        print(msg)\n    return study\n\n\ndef format_dict(d: Dict[str, float], format: str=&quot;.4f&quot;) -&gt; Dict[str, float]:\n    &quot;&quot;&quot;\n    Returns formatted output for a dictionary with \n    string keys and float values.\n    &quot;&quot;&quot;\n    return dict((k, float(f'{v:{format}}')) for k,v in d.items())\n\n\ndef format_result(d: Dict[str, float], \n                  metric_value: float, \n                  header: str='', \n                  format: str=&quot;.4f&quot;): \n    &quot;&quot;&quot;Returns formatted result.&quot;&quot;&quot;\n    msg = f&quot;&quot;&quot;Study Name: {header}\\n{'='*30}\n    \n    \u2705 study.best_params: \\n\\t{format_dict(d)}\n    \u2705 metric: {metric_value} \n    &quot;&quot;&quot;\n    return msg\n\n\ndef study_contour_plot(study: optuna.Study, \n                       params: Optional[List[str]]=None, \n                       width: int=560, \n                       height: int=500):\n    &quot;&quot;&quot;\n    Create contour plots for a study, given a list or \n    tuple of two parameter names.\n    &quot;&quot;&quot;\n    if params is None:\n        params = [&quot;dv&quot;, &quot;vc&quot;]\n    fig = optuna.visualization.plot_contour(study, params=params)\n    fig.update_layout(\n        title=f'Contour Plot: {study.study_name} ({params[0]}, {params[1]})', \n        autosize=False,\n        width=width, \n        height=height,\n        margin=dict(l=65, r=50, b=65, t=90))\n    fig.show()\n\n\nbounds = [(0.2, 4), (300, 600), (0, 1000), (0, 1000)]\nparam_names = PARAM_NAMES # [&quot;ev&quot;, &quot;bv&quot;, &quot;vc&quot;, &quot;dv&quot;,]\npobjective = partial(objective, bounds=bounds)\n\n# Create an empty dict to contain \n# various subsequent studies.\nstudies = dict()\n</code></pre>\n<p>Optuna comes with a few different types of Samplers. Samplers provide the strategy of how optuna is going to sample points from the parametr-space and evaluate the objective function.</p>\n<ul>\n<li><a href=\"https://optuna.readthedocs.io/en/stable/reference/samplers.html\" rel=\"nofollow noreferrer\">https://optuna.readthedocs.io/en/stable/reference/samplers.html</a></li>\n</ul>\n<h3>B.1 Use <code>TPESampler</code></h3>\n<pre class=\"lang-py prettyprint-override\"><code>from optuna.samplers import TPESampler\n\nsampler = TPESampler(seed=42)\n\nstudy_name = &quot;TPESampler&quot;\nstudies[study_name] = optimize(\n    pobjective, \n    sampler=sampler, \n    n_trials=100, \n    study_name=study_name,\n)\n\n# Study Name: TPESampler\n# ==============================\n#    \n#     \u2705 study.best_params: \n#   {'ev': 1.6233, 'bv': 585.2143, 'vc': 731.9939, 'dv': 598.6585}\n#     \u2705 metric: -0.0 \n</code></pre>\n<h3>B.2. Use <code>GridSampler</code></h3>\n<p><strong>GridSampler</strong> requires a parameter search grid. Here we are using the following <code>search_space</code>.</p>\n<p><a href=\"https://i.stack.imgur.com/YEw1U.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/YEw1U.png\" alt=\"search_space\" /></a></p>\n<pre class=\"lang-py prettyprint-override\"><code>from optuna.samplers import GridSampler\n\n# create search-space\nsearch_space = make_param_grid(bounds=bounds, num_points=10, as_dict=True)\n\nsampler = GridSampler(search_space)\n\nstudy_name = &quot;GridSampler&quot;\nstudies[study_name] = optimize(\n    pobjective, \n    sampler=sampler, \n    n_trials=2000, \n    study_name=study_name,\n)\n\n# Study Name: GridSampler\n# ==============================\n#    \n#     \u2705 study.best_params: \n#   {'ev': 0.2, 'bv': 500.0, 'vc': 222.2222, 'dv': 0.0}\n#     \u2705 metric: -88.33333333333337 \n</code></pre>\n<h3>B.3. Use <code>RandomSampler</code></h3>\n<pre class=\"lang-py prettyprint-override\"><code>from optuna.samplers import RandomSampler\n\nsampler = RandomSampler(seed=42)\n\nstudy_name = &quot;RandomSampler&quot;\nstudies[study_name] = optimize(\n    pobjective, \n    sampler=sampler, \n    n_trials=300, \n    study_name=study_name,\n)\n\n# Study Name: RandomSampler\n# ==============================\n#    \n#     \u2705 study.best_params: \n#   {'ev': 1.6233, 'bv': 585.2143, 'vc': 731.9939, 'dv': 598.6585}\n#     \u2705 metric: -0.0 \n</code></pre>\n<h2>C. Dummy Data</h2>\n<p>For the sake of reproducibility, I am keeping a record of the dummy data used here.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport numpy as np\nfrom scipy import optimize\n\ncols = {\n    'Dividend2': [9390, 7448, 177], \n    'Probability': [341, 376, 452], \n    'EV': [0.53, 0.60, 0.55], \n    'Dividend': [185, 55, 755], \n    'EV2': [123, 139, 544],\n}\n\ndf = pd.DataFrame(cols)\n\ndef myFunc(params):\n    &quot;&quot;&quot;myFunc metric.&quot;&quot;&quot;\n    (ev, bv, vc, dv) = params\n    df['Number'] = np.where(df['Dividend2'] &lt;= vc, 1, 0) \\\n                    + np.where(df['EV2'] &lt;= dv, 1, 0)\n    df['Return'] =  np.where(\n        df['EV'] &lt;= ev, 0, np.where(\n            df['Probability'] &gt;= bv, 0, df['Number'] * df['Dividend'] - (vc + dv)\n        )\n    )\n    return -1 * (df['Return'].sum())\n\nb1 = [(0.2,4), (300,600), (0,1000), (0,1000)]\nstart = [0.2, 600, 1000, 1000]\nresult = optimize.minimize(fun=myFunc, bounds=b1, x0=start)\nprint(result)\n</code></pre>\n<h3>C.1. An Observation</h3>\n<p>So, it seems at first glance that the code executed properly and did not throw any error. It says it had success in finding the minimized solution.</p>\n<pre class=\"lang-sh prettyprint-override\"><code>      fun: -0.0\n hess_inv: &lt;4x4 LbfgsInvHessProduct with dtype=float64&gt;\n      jac: array([0., 0., 3., 3.])\n  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL' # \ud83d\udca1\n     nfev: 35\n      nit: 2\n   status: 0\n  success: True\n        x: array([2.e-01, 6.e+02, 0.e+00, 0.e+00]) # \ud83d\udd25\n</code></pre>\n<p>A close observation reveals that the solution (see \ud83d\udd25) is no different from the starting point <code>[0.2, 600, 1000, 1000]</code>. So, seems like nothing really happened and the algorithm just finished prematurely?!!</p>\n<p>Now look at the <code>message</code> above (see \ud83d\udca1). If we run a google search on this, you could find something like this:</p>\n<ul>\n<li><p><strong>Summary</strong></p>\n<blockquote>\n<p><code>b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL'</code></p>\n<p>If the loss-landscape does not have a smoothely changing topography, the gradient descent algorithms will soon find that from one iteration to the next, there isn't much change happening and hence, will terminate further seeking. Also, if the loss-landscape is rather flat, this could see similar fate and get early-termination.</p>\n</blockquote>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/60725549/scipy-optimize-minimize-does-not-perform-the-optimization-convergence-norm-of\">scipy-optimize-minimize does not perform the optimization - <code>CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL</code></a></li>\n</ul>\n</li>\n</ul>\n<h2>D. Making the Loss Landscape Smoother</h2>\n<p>A binary evaluation of <code>value = 1 if x&gt;5 else 0</code> is essentially a step-function that assigns <code>1</code> for all values of <code>x</code> that are greater than <code>5</code> and <code>0</code> otherwise. But this introduces a kink - a discontinuity in smoothness and this could potentially introduce problems in traversing the loss-landscape.</p>\n<p>What if we use a <code>sigmoid</code> function to introduce some smoothness?</p>\n\n<img src=\"https://latex.codecogs.com/svg.image?%5Clarge&space;%7B%5Ccolor%7BPink%7D&space;%5Csigma(x)&space;=&space;%5Cfrac%7B1%7D%7B1&space;&plus;&space;e%5E%7B-x%7D%7D%7D\" title=\"https://latex.codecogs.com/svg.image?\\large {\\color{Pink} \\sigma(x) = \\frac{1}{1 + e^{-x}}}\" />\n</p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Define sigmoid function\ndef sigmoid(x):\n    &quot;&quot;&quot;Sigmoid function.&quot;&quot;&quot;\n    return 1 / (1 + np.exp(-x))\n</code></pre>\n<p>For the above example, we could modify it as follows.</p>\n\n\n<img src=\"https://latex.codecogs.com/svg.image?%5Clarge&space;%7B%5Ccolor%7BPink%7D&space;%5Csigma((x&space;-&space;5))&space;=&space;%5Cfrac%7B1%7D%7B1&space;&plus;&space;e%5E%7B-(x&space;-&space;5)%7D%7D%7D\" title=\"https://latex.codecogs.com/svg.image?\\large {\\color{Pink} \\sigma((x - 5)) = \\frac{1}{1 + e^{-(x - 5)}}}\" />\n</p>\n<p>You can additionally introduce another factor (<code>gamma</code>: \u03b3) as follows and try to optimize it to make the landscape smoother. Thus by controlling the <em><code>gamma</code></em> factor, you could make the function smoother and change how quickly it changes around <code>x = 5</code></p>\n\n\n<img src=\"https://latex.codecogs.com/svg.image?%5Clarge&space;%7B%5Ccolor%7BPink%7D&space;%5Csigma((x&space;-&space;5)/%5Cgamma)&space;=&space;%5Cfrac%7B1%7D%7B1&space;&plus;&space;e%5E%7B-(x&space;-&space;5)/%5Cgamma%7D%7D%7D\" title=\"https://latex.codecogs.com/svg.image?\\large {\\color{Pink} \\sigma((x - 5)/\\gamma) = \\frac{1}{1 + e^{-(x - 5)/\\gamma}}}\" />\n</p>\n<p><a href=\"https://i.stack.imgur.com/D0BU7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/D0BU7.png\" alt=\"sigmoid-demo\" /></a></p>\n<p>The above figure is created with the following code-snippet.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import matplotlib.pyplot as plt\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'svg' # 'svg', 'retina' \nplt.style.use('seaborn-white')\n\ndef make_figure(figtitle: str=&quot;Sigmoid Function&quot;):\n    &quot;&quot;&quot;Make the demo figure for using sigmoid.&quot;&quot;&quot;\n\n    x = np.arange(-20, 20.01, 0.01)\n    y1 = sigmoid(x)\n    y2 = sigmoid(x - 5)\n    y3 = sigmoid((x - 5)/3)\n    y4 = sigmoid((x - 5)/0.3)\n    fig, ax = plt.subplots(figsize=(10,5))\n    plt.sca(ax)\n    plt.plot(x, y1, ls=&quot;-&quot;, label=&quot;$\\sigma(x)$&quot;)\n    plt.plot(x, y2, ls=&quot;--&quot;, label=&quot;$\\sigma(x - 5)$&quot;)\n    plt.plot(x, y3, ls=&quot;-.&quot;, label=&quot;$\\sigma((x - 5) / 3)$&quot;)\n    plt.plot(x, y4, ls=&quot;:&quot;, label=&quot;$\\sigma((x - 5) / 0.3)$&quot;)\n    plt.axvline(x=0, ls=&quot;-&quot;, lw=1.3, color=&quot;cyan&quot;, alpha=0.9)\n    plt.axvline(x=5, ls=&quot;-&quot;, lw=1.3, color=&quot;magenta&quot;, alpha=0.9)\n    plt.legend()\n    plt.title(figtitle)\n    plt.show()\n\nmake_figure()\n</code></pre>\n<h3>D.1. Example of Metric Smoothing</h3>\n<p>The following is an example of how you could apply function smoothing.</p>\n<pre class=\"lang-py prettyprint-override\"><code>from functools import partial\n\ndef sig(x, gamma: float=1.):\n    return sigmoid(x/gamma)\n\ndef myFunc3(params, gamma: float=0.5):\n    &quot;&quot;&quot;myFunc metric v3 with smoother metric.&quot;&quot;&quot;\n    (ev, bv, vc, dv) = params\n    _sig = partial(sig, gamma=gamma)\n    df['Number'] = _sig(x = -(df['Dividend2'] - vc)) * 1 \\\n                    + _sig(x = -(df['EV2'] - dv)) * 1\n    df['Return'] = (\n        _sig(x = df['EV'] - ev) \n        * _sig(x = -(df['Probability'] - bv))\n        * _sig(x = df['Number'] * df['Dividend'] - (vc + dv))\n    )\n    return -1 * (df['Return'].sum())\n</code></pre>\n"}
{"Id": 71814658, "PostTypeId": 1, "Title": "Python typing: Does TypedDict allow additional / extra keys?", "Body": "<p>Does <code>typing.TypedDict</code> allow extra keys? Does a value pass the typechecker, if it has keys which are not present on the definition of the TypedDict?</p>\n", "AcceptedAnswerId": 71814659, "AcceptedAnswer": "<p>It depends.</p>\n<p><a href=\"https://peps.python.org/pep-0589/\" rel=\"noreferrer\">PEP-589, the specification of <code>TypedDict</code>,</a> explicitely forbids extra keys:</p>\n<blockquote>\n<p>Extra keys included in TypedDict <strong>object construction</strong> should also be caught. In this example, the director key is not defined in Movie and is expected to generate an error from a type checker:</p>\n<pre class=\"lang-py prettyprint-override\"><code>m: Movie = dict(\n      name='Alien',\n      year=1979,\n      director='Ridley Scott')  # error: Unexpected key 'director'\n</code></pre>\n</blockquote>\n<p>[highlighting by me]</p>\n<p>The typecheckers mypy, pyre, pyright implement this according to the specification.</p>\n<p>However, it is possible that a value with extra keys is accepted. This is because subtyping of TypedDicts is allowed, and the subtype might implement the extra key. PEP-589 only forbids extra keys in object construction, i.e. in literal assignment. As any value that complies with a subtype is always deemed to comply with the parent type and can be upcasted from the subtype to the parent type, an extra key can be introduced through a subtype:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from typing import TypedDict\n\nclass Movie(TypedDict):\n    name: str\n    year: int\n\nclass MovieWithDirector(Movie):\n    director: str\n\n\n# This is illegal:\nmovie: Movie = {\n    'name': 'Ash is purest white', \n    'year': 2018, \n    'director': 'Jia Zhangke',\n}    \n\n# This is legal:\nmovie_with_director: MovieWithDirector = {\n    'name': 'Ash is purest white', \n    'year': 2018, \n    'director': 'Jia Zhangke',\n}\n\n# This is legal, MovieWithDirector is a subtype of Movie\nmovie: Movie = movie_with_director  \n</code></pre>\n<p>In the example above, we see that the same value can sometimes be considered complying with <code>Movie</code> by the typing system, and sometimes not.</p>\n<p>As a consequence of subtyping, typing a parameter as a certain TypedDict is not a safeguard against extra keys, because they could have been introduced through a subtype.</p>\n<p>If your code is sensitive with regard to the presence of extra keys (for instance, if it makes use of <code>param.keys()</code>, <code>param.values()</code> or <code>len(param)</code> on the <code>TypedDict</code> parameter <code>param</code>), this could lead to problems when extra keys are present. A solution to this problem is to either handle the exceptional case that extra keys are actually present on the parameter or to make your code insensitive against extra keys.</p>\n<p>If you want to test that your code is robust against extra keys, you cannot simply add a key in the test value:</p>\n<pre><code>def some_movie_function(movie: Movie):\n    # ...\n\ndef test_some_movie_function():\n    # this will not be accepted by the type checker:\n    result = some_movie_function({\n        'name': 'Ash is purest white', \n        'year': 2018, \n        'director': 'Jia Zhangke',\n        'genre': 'drama',\n    })    \n</code></pre>\n<p>Workarounds are to either make the type checkers ignore the line or to create a subtype for your test, introducing the extra keys only for your test:</p>\n<pre><code>class ExtendedMovie(Movie):\n     director: str\n     genre: str\n\n\ndef test_some_movie_function():\n    extended_movie: ExtendedMovie = {\n        'name': 'Ash is purest white', \n        'year': 2018, \n        'director': 'Jia Zhangke',\n        'genre': 'drama',\n    }\n\n    result = some_movie_function(test_some_movie_function)\n    # run assertions against result\n} \n</code></pre>\n"}
{"Id": 72373093, "PostTypeId": 1, "Title": "How to define \"python_requires\" in pyproject.toml using setuptools?", "Body": "<p>Setuptools allows you to specify the minimum python version <a href=\"https://stackoverflow.com/a/48777286/2135504\">as such</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from setuptools import setup\n\n[...]\n\nsetup(name=&quot;my_package_name&quot;,\n      python_requires='&gt;3.5.2',\n      [...]\n\n</code></pre>\n<p>However, how can you do this with the <a href=\"https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html\" rel=\"noreferrer\">pyproject.toml</a>? The following two things did NOT work:</p>\n<pre><code>[project]\n...\n# ERROR: invalid key \npython_requires = &quot;&gt;=3&quot;\n\n# ERROR: no matching distribution found\ndependencies = [&quot;python&gt;=3&quot;]\n</code></pre>\n", "AcceptedAnswerId": 72462723, "AcceptedAnswer": "<p>According to <a href=\"https://peps.python.org/pep-0621/\" rel=\"noreferrer\">PEP 621</a>, the equivalent field in the <code>[project]</code> table is <a href=\"https://peps.python.org/pep-0621/#requires-python\" rel=\"noreferrer\"><code>requires-python</code></a>.</p>\n<p>More information about the list of valid configuration fields can be found in: <a href=\"https://packaging.python.org/en/latest/specifications/declaring-project-metadata/\" rel=\"noreferrer\">https://packaging.python.org/en/latest/specifications/declaring-project-metadata/</a>.</p>\n<p>The equivalent <code>pyproject.toml</code> of your example would be:</p>\n<pre class=\"lang-ini prettyprint-override\"><code>[project]\nname = &quot;my_package_name&quot;\nrequires-python = &quot;&gt;3.5.2&quot;\n...\n</code></pre>\n"}
{"Id": 73062386, "PostTypeId": 1, "Title": "Adding single integer to numpy array faster if single integer has python-native int type", "Body": "<p>I add a single integer to an array of integers with 1000 elements. This is faster by 25% when I first cast the single integer from <code>numpy.int64</code> to the python-native <code>int</code>.</p>\n<p>Why? Should I, as a general rule of thumb convert the single number to native python formats for single-number-to-array operations with arrays of about this size?</p>\n<p>Note: may be related to my previous question <a href=\"https://stackoverflow.com/q/73053617/5269892\">Conjugating a complex number much faster if number has python-native complex type</a>.</p>\n<pre><code>import numpy as np\n\nnnu = 10418\nnnu_use = 5210\na = np.random.randint(nnu,size=1000)\nb = np.random.randint(nnu_use,size=1)[0]\n\n%timeit a + b                            # --&gt; 3.9 \u00b5s \u00b1 19.9 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n%timeit a + int(b)                       # --&gt; 2.87 \u00b5s \u00b1 8.07 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n</code></pre>\n<hr />\n<p>Note that the speed-up can be enormous (<strong>factor 50</strong>) for scalar-to-scalar-operations as well, as seen below:</p>\n<pre><code>np.random.seed(100)\n\na = (np.random.rand(1))[0]\na_native = float(a)\nb = complex(np.random.rand(1)+1j*np.random.rand(1))\nc = (np.random.rand(1)+1j*np.random.rand(1))[0]\nc_native = complex(c)\n\n%timeit a * (b - b.conjugate() * c)                # 6.48 \u00b5s \u00b1 49.7 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n%timeit a_native * (b - b.conjugate() * c_native)  # 283 ns \u00b1 7.78 ns per loop (mean \u00b1 std. dev. of 7 runs, 1000000 loops each)\n%timeit a * b                                      # 5.07 \u00b5s \u00b1 17.7 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n%timeit a_native * b                               # 94.5 ns \u00b1 0.868 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000000 loops each)\n</code></pre>\n<hr />\n<p><strong>Update:</strong> Could it be that the latest numpy release fixes the speed difference? The release notes of numpy <code>1.23</code> mention that scalar operations are now much faster, see <a href=\"https://numpy.org/devdocs/release/1.23.0-notes.html#performance-improvements-and-changes\" rel=\"nofollow noreferrer\">https://numpy.org/devdocs/release/1.23.0-notes.html#performance-improvements-and-changes</a> and <a href=\"https://github.com/numpy/numpy/pull/21188\" rel=\"nofollow noreferrer\">https://github.com/numpy/numpy/pull/21188</a>. I am using <code>python 3.7.6, numpy 1.21.2</code>.</p>\n", "AcceptedAnswerId": 73070306, "AcceptedAnswer": "<p>On my Windows PC with CPython 3.8.1, I get:</p>\n<pre class=\"lang-none prettyprint-override\"><code>[Old] Numpy 1.22.4:\n - First test: 1.65 \u00b5s VS 1.43 \u00b5s\n - Second:     2.03 \u00b5s VS 0.17 \u00b5s\n\n[New] Numpy 1.23.1:\n - First test: 1.38 \u00b5s VS 1.24 \u00b5s    &lt;----  A bit better than Numpy 1.22.4\n - Second:     0.38 \u00b5s VS 0.17 \u00b5s    &lt;----  Much better than Numpy 1.22.4\n</code></pre>\n\n<p>While the new version of Numpy gives a good boost, native type should always be faster than Numpy ones with the (default) CPython <strong>interpreter</strong>. Indeed, the interpreter needs to call C function of Numpy. This is not needed with native types. Additionally, the Numpy checks and wrapping is not optimal but Numpy is not designed for fast scalar computation in the first place (though the overhead was previously not reasonable). In fact, scalar computations are very inefficient and the interpreter prevent any fast execution.</p>\n<p>If you plan to do many scalar operation you need to use a natively compiled code, possibly using Cython, Numba, or even a raw C/C++ module. Note that Cython do not optimize/inline Numpy calls but can operate on native types faster. A native code can do this certainly in one or even two order of magnitude less time.</p>\n<p>Note that in the first case, the path in Numpy functions is not the same and Numpy does additional check that are a bit more expensive then the value is not a CPython object. Still, it should be a constant overhead (and now relatively small). Otherwise, it would be a bug (and should be reported).</p>\n<p>Related: <a href=\"https://stackoverflow.com/questions/69584027/why-is-np-sumrangen-very-slow/69587888#69587888\">Why is <code>np.sum(range(N))</code> very slow?</a></p>\n"}
{"Id": 72258087, "PostTypeId": 1, "Title": "unexpected keyword argument 'tenant_id' while accessing Azure Key Vault in Python", "Body": "<p>I was trying to accessing my key vault, but I got always the same error:</p>\n<pre><code>AppServiceCredential.get_token failed: request() got an unexpected keyword argument 'tenant_id'\nManagedIdentityCredential.get_token failed: request() got an unexpected keyword argument 'tenant_id'\n</code></pre>\n<p>This was the code I used in an Azure Machine Learning notebook, copied from the docs:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from azure.identity import ManagedIdentityCredential\nfrom azure.keyvault.secrets import SecretClient\n\ncredential = ManagedIdentityCredential()\nsecret_client = SecretClient(vault_url=&quot;https://XXXX.vault.azure.net/&quot;, credential=credential)\n\nsecretName = 'test'\nretrieved_secret = secret_client.get_secret(secretName) # here's the error\nretrieved_secret\n</code></pre>\n<p>What is wrong? Could you help me?\nThank you in advance.</p>\n", "AcceptedAnswerId": 72262694, "AcceptedAnswer": "<p>This error is because of a bug that has since been fixed in <code>azure-identity</code>'s <code>ManagedIdentityCredential</code>. Key Vault clients in recent packages include a tenant ID in token requests to support cross-tenant authentication, but some <code>azure-identity</code> credentials didn't correctly handle this keyword argument until the bug was fixed in <a href=\"https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/identity/azure-identity/CHANGELOG.md#180-2022-03-01\" rel=\"noreferrer\">version 1.8.0</a>. Installing <code>azure-identity</code>&gt;=1.8.0 should fix the error you're getting.</p>\n<p>(Disclaimer: I work for the Azure SDK for Python)</p>\n"}
{"Id": 73136808, "PostTypeId": 1, "Title": "AWS Glue error - Invalid input provided while running python shell program", "Body": "<p>I have Glue job, a python shell code. When I try to run it I end up getting the below error.\n<code>Job Name : xxxxx Job Run Id : yyyyyy failed to execute with exception Internal service error : Invalid input provided</code>\nIt is not specific to code, even if I just put</p>\n<pre><code>import boto3\nprint('loaded')\n</code></pre>\n<p>I am getting the error right after clicking the run job option. What is the issue here?</p>\n", "AcceptedAnswerId": 73162640, "AcceptedAnswer": "<p>I think Quatermass is right, the jobs started working out of the blue the next day without any changes.</p>\n"}
{"Id": 72571235, "PostTypeId": 1, "Title": "Can I install node.js 18 on Centos 7 and do I need python 3 install too?", "Body": "<p>I'm not sure if node.js 18 supports centos 7 and is it a requirement to install python 3 for node.js 18?</p>\n", "AcceptedAnswerId": 72571789, "AcceptedAnswer": "<p>Step 1 - <code>curl --silent --location https://rpm.nodesource.com/setup_18.x | sudo bash -</code></p>\n<p>Step 2 - <code>sudo yum -y install nodejs</code></p>\n<p>I don't think you need Python 3.</p>\n<p>Reference - <a href=\"https://computingforgeeks.com/install-node-js-on-centos-rhel-rocky-linux/\" rel=\"nofollow noreferrer\">https://computingforgeeks.com/install-node-js-on-centos-rhel-rocky-linux/</a></p>\n"}
{"Id": 72059380, "PostTypeId": 1, "Title": "Python fuctional style iterative algoritm?", "Body": "<p>In Haskell there is a simple list function available</p>\n<pre><code>iterate :: (a -&gt; a) -&gt; a -&gt; [a]\niterate f x =  x : iterate f (f x)\n</code></pre>\n<p>In python it could be implemented as following:</p>\n<pre><code>def iterate(f, init):\n  while True:\n    yield init\n    init = f(init)\n</code></pre>\n<p>I was kinda surprised that something basic like this is not part of the functools/itertools modules. Could it be simply costructed in functional style (i.e. without the loop) using the tools provided in these libraries? (Mostly code golf, trying to learn about functional style in Python.)</p>\n", "AcceptedAnswerId": 72059725, "AcceptedAnswer": "<p>You can do it using some of the functions in <code>itertools</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from itertools import accumulate, repeat\n\ndef iterate(func, initial):\n    return accumulate(repeat(None), func=lambda tot, _: func(tot), initial=initial)\n</code></pre>\n<p>Although it's clearly not very clean. Itertools is missing some fundamental functions for constructing streams, like <code>unfoldr</code>. Most of the <code>itertools</code> functions could be defined in terms of <code>unfoldr</code>, as it happens, but functional programming is a little uncomfortable in Python anyways so that might not be much of a benefit.</p>\n"}
{"Id": 71861779, "PostTypeId": 1, "Title": "MWAA - Airflow - PythonVirtualenvOperator requires virtualenv", "Body": "<p>I am using AWS's <a href=\"https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html\" rel=\"nofollow noreferrer\">MWAA service</a> (2.2.2) to run a variety of DAGs, most of which are implemented with standard PythonOperator types. I bundle the DAGs into an S3 bucket alongside any shared requirements, then point MWAA to the relevant objects &amp; versions. Everything runs smoothly so far.</p>\n<p>I would now like to implement a DAG using the <a href=\"https://registry.astronomer.io/providers/apache-airflow/modules/pythonvirtualenvoperator\" rel=\"nofollow noreferrer\">PythonVirtualenvOperator</a> type, which AWS acknowledge is not supported out of the box. I am following <a href=\"https://docs.aws.amazon.com/mwaa/latest/userguide/samples-virtualenv.html\" rel=\"nofollow noreferrer\">their guide</a> on how to patch the behaviour using a custom plugin, but continue to receive an error from Airflow, shown at the top of the dashboard in big red writing:</p>\n<blockquote>\n<p>DAG Import Errors (1)\n... ...\nAirflowException: PythonVirtualenvOperator requires virtualenv, please install it.</p>\n</blockquote>\n<p>I've confirmed that the plugin is indeed being picked up by Airflow (I see it referenced in the admin screen), and for the avoidance of doubt I am using the exact code provided by AWS in their examples for the DAG. AWS's documentation on this is pretty light and I've yet to stumble across any community discussion for the same.</p>\n<p>From AWS's docs, we'd expect the plugin to run at startup prior to any DAGs being processed. The plugin itself appears to effectively rewrite the venv command to use the pip-installed version, rather than that which is installed on the machine, however I've struggled to verify that things are happening in the order I expect. Any pointers on debugging the instance's behavior would be very much appreciated.</p>\n<p>Has anyone faced a similar issue? Is there a gap in the MWAA documentation that needs addressing? Am I missing something incredibly obvious?</p>\n<p>Possibly related, but I do see this warning in the scheduler's logs, which may indicate why MWAA is struggling to resolve the dependency?</p>\n<blockquote>\n<p>WARNING: The script virtualenv is installed in '/usr/local/airflow/.local/bin' which is not on PATH.</p>\n</blockquote>\n", "AcceptedAnswerId": 72203130, "AcceptedAnswer": "<p>Airflow uses shutil.which to look for virtualenv. The installed virtualenv via requirements.txt isn't on the PATH. Adding the path to virtualenv to PATH solves this.</p>\n<p>The doc here is wrong <a href=\"https://docs.aws.amazon.com/mwaa/latest/userguide/samples-virtualenv.html\" rel=\"nofollow noreferrer\">https://docs.aws.amazon.com/mwaa/latest/userguide/samples-virtualenv.html</a></p>\n<pre><code>import os\nfrom airflow.plugins_manager import AirflowPlugin\nimport airflow.utils.python_virtualenv \nfrom typing import List\ndef _generate_virtualenv_cmd(tmp_dir: str, python_bin: str, system_site_packages: bool) -&gt; List[str]:\n    cmd = ['python3','/usr/local/airflow/.local/lib/python3.7/site-packages/virtualenv', tmp_dir]\n    if system_site_packages:\n        cmd.append('--system-site-packages')\n    if python_bin is not None:\n        cmd.append(f'--python={python_bin}')\n    return cmd\nairflow.utils.python_virtualenv._generate_virtualenv_cmd=_generate_virtualenv_cmd\n#This is the added path code\nos.environ[&quot;PATH&quot;] = f&quot;/usr/local/airflow/.local/bin:{os.environ['PATH']}&quot;\nclass VirtualPythonPlugin(AirflowPlugin):                \n    name = 'virtual_python_plugin'\n</code></pre>\n"}
{"Id": 73457379, "PostTypeId": 1, "Title": "Python regex and leading 0 in capturing group", "Body": "<p>I'm writing a script in python 3 to automatically rename files. But I have a problem with the captured group in a regex.</p>\n<p>I have these kinds of files :</p>\n<pre><code>test tome 01 something.cbz\ntest tome 2 something.cbz\ntest tome 20 something.cbz\n</code></pre>\n<p>And I would like to have :</p>\n<pre><code>test 001 something.cbz\ntest 002 something.cbz\ntest 020 something.cbz\n</code></pre>\n<p>I tried several bits of code:</p>\n<p><strong>Example 1</strong>:</p>\n<pre><code>name = re.sub('tome [0]{0,1}(\\d{1,})', str('\\\\1').zfill(3), name)\n</code></pre>\n<p>The result is:</p>\n<pre><code>test 01 something.cbz\ntest 02 something.cbz\ntest 020 something.cbz\n</code></pre>\n<p><strong>Example 2</strong>:</p>\n<pre><code>name = re.sub('tome (\\d{1,})', str('\\\\1').lstrip(&quot;0&quot;).zfill(3), name)\n</code></pre>\n<p>The result is:</p>\n<pre><code>test 001 something.cbz\ntest 02 something.cbz\ntest 020 something.cbz\n</code></pre>\n", "AcceptedAnswerId": 73457472, "AcceptedAnswer": "<p>You can run the <code>zfill(3)</code> on the <code>.group(1)</code> value after stripping the zeroes from the left side:</p>\n<pre><code>import re\n\ns = (&quot;test tome 01 something.cbz\\n&quot;\n            &quot;test tome 2 something.cbz\\n&quot;\n            &quot;test tome 20 something.cbz&quot;)\n\nresult = re.sub(\n    r'tome (\\d+)',\n    lambda x: x.group(1).lstrip(&quot;0&quot;).zfill(3),\n    s\n)\nprint(result)\n</code></pre>\n<p>Output</p>\n<pre><code>test 001 something.cbz\ntest 002 something.cbz\ntest 020 something.cbz\n</code></pre>\n"}
{"Id": 72604922, "PostTypeId": 1, "Title": "How to convert Python dataclass to dictionary of string literal?", "Body": "<p>Given a dataclass like below:</p>\n<pre><code>class MessageHeader(BaseModel):\n    message_id: uuid.UUID\n\n    def dict(self, **kwargs):\n        return json.loads(self.json())\n</code></pre>\n<p>I would like to get a dictionary of string literal when I call <code>dict</code> on <code>MessageHeader</code>\nThe desired outcome of dictionary is like below:</p>\n<pre><code>{'message_id': '383b0bfc-743e-4738-8361-27e6a0753b5a'}\n</code></pre>\n<p>I want to avoid using 3rd party library like <code>pydantic</code> &amp; I do not want to use <code>json.loads(self.json())</code> as there are extra round trips</p>\n<p>Is there any better way to convert a dataclass to a dictionary with string literal like above?</p>\n", "AcceptedAnswerId": 72605423, "AcceptedAnswer": "<p>You can use <a href=\"https://docs.python.org/3/library/dataclasses.html#dataclasses.asdict\" rel=\"noreferrer\"><code>dataclasses.asdict</code></a>:</p>\n<pre><code>from dataclasses import dataclass, asdict\n\nclass MessageHeader(BaseModel):\n    message_id: uuid.UUID\n\n    def dict(self):\n        return {k: str(v) for k, v in asdict(self).items()}\n</code></pre>\n<p>If you're sure that your class only has string values, you can skip the dictionary comprehension entirely:</p>\n<pre><code>class MessageHeader(BaseModel):\n    message_id: uuid.UUID\n\n    dict = asdict\n</code></pre>\n"}
{"Id": 73206810, "PostTypeId": 1, "Title": "Faker Python generating chinese/pinyin names", "Body": "<p>I am trying to generate random chinese names using Faker (Python), but it generates the names in chinese characters instead of pinyin.</p>\n<p>I found this :\n<img src=\"https://i.stack.imgur.com/bimJ0.png\" alt=\"enter image description here\" /></p>\n<p>and it show that it generates them in pinyin, while when I try the same code, it gives me only chinese characters.</p>\n<p>how to get the pinyin ??</p>\n", "AcceptedAnswerId": 73206894, "AcceptedAnswer": "<p><code>fake.romanized_name()</code> worked for me.</p>\n<p>I got lucky by looking through <code>dir(fake)</code>. Doesn't seem to have a method for pinyin address that I can see...</p>\n"}
{"Id": 73166250, "PostTypeId": 1, "Title": "Why does a recursive Python program not crash my system?", "Body": "<p>I've written an <strong>R.py</strong> script which contains the following two lines:</p>\n<pre><code>import os\n\nos.system(&quot;python3 R.py&quot;)\n</code></pre>\n<p>I expected my system to run out of memory after running this script for a few minutes, but it is still surprisingly responsive. Does someone know, what kind of Python interpreter magic is happening here?</p>\n", "AcceptedAnswerId": 73216511, "AcceptedAnswer": "<h1>Preface</h1>\n<p><code>os.system()</code> is actually a call to C\u2019s <code>system()</code>.</p>\n<p>Here is what the documentation states:</p>\n<blockquote>\n<p>The system() function shall behave as if a child process were created\nusing fork(), and the child process invoked the sh utility using\nexecl() as follows:</p>\n<p>execl(, &quot;sh&quot;, &quot;-c&quot;, command, (char *)0);</p>\n<p>where  is an unspecified pathname for the sh utility. It\nis unspecified whether the handlers registered with pthread_atfork()\nare called as part of the creation of the child process.</p>\n<p>The system() function shall ignore the SIGINT and SIGQUIT signals, and\nshall block the SIGCHLD signal, while waiting for the command to\nterminate. If this might cause the application to miss a signal that\nwould have killed it, then the application should examine the return\nvalue from system() and take whatever action is appropriate to the\napplication if the command terminated due to receipt of a signal.</p>\n<p>The system() function shall not affect the termination status of any\nchild of the calling processes other than the process or processes it\nitself creates.</p>\n<p>The system() function shall not return until the child process has\nterminated. [Option End]</p>\n<p>The system() function need not be thread-safe.</p>\n</blockquote>\n<h1>Solution</h1>\n<p><code>system()</code> creates a child process and exits, there is no stack to be resolved, therefore one would expect this to run as long as resources to do so are available. Furthermore, the operation being of creating a child process is not an intensive one\u2014 the processes aren't using up much resources, but if allowed to run long enough the script will to start to affect general performance and eventually run out of memory to spawn a new child process. Once this occurs the processes will exit.</p>\n<h1>Example</h1>\n<p>To demonstrate this, set recursion depth limit to 10 and allow the program to run:</p>\n<pre><code>import os, sys, inspect\n\nsys.setrecursionlimit(10)\n\nargs = sys.argv[1:]\narg = int(args[0]) if len(args) else 0\n\nstack_depth = len(inspect.stack(0))\n\nprint(f&quot;Iteration {arg} - at stack depth of {stack_depth}&quot;)\n\narg += 1\n\nos.system(f&quot;python3 main.py {arg}&quot;)\n\n</code></pre>\n<p>Outputs:</p>\n<pre><code>Iteration 0 - at stack depth of 1 - avaialable memory 43337904128 \nIteration 1 - at stack depth of 1 - avaialable memory 43370692608 \nIteration 2 - at stack depth of 1 - avaialable memory 43358756864 \nIteration 3 - at stack depth of 1 - avaialable memory 43339202560 \nIteration 4 - at stack depth of 1 - avaialable memory 43354894336 \nIteration 5 - at stack depth of 1 - avaialable memory 43314974720 \nIteration 6 - at stack depth of 1 - avaialable memory 43232366592 \nIteration 7 - at stack depth of 1 - avaialable memory 43188719616 \nIteration 8 - at stack depth of 1 - avaialable memory 43173384192 \nIteration 9 - at stack depth of 1 - avaialable memory 43286093824 \nIteration 10 - at stack depth of 1 - avaialable memory 43288162304\nIteration 11 - at stack depth of 1 - avaialable memory 43310637056\nIteration 12 - at stack depth of 1 - avaialable memory 43302408192\nIteration 13 - at stack depth of 1 - avaialable memory 43295440896\nIteration 14 - at stack depth of 1 - avaialable memory 43303870464\nIteration 15 - at stack depth of 1 - avaialable memory 43303870464\nIteration 16 - at stack depth of 1 - avaialable memory 43296256000\nIteration 17 - at stack depth of 1 - avaialable memory 43286032384\nIteration 18 - at stack depth of 1 - avaialable memory 43246657536\nIteration 19 - at stack depth of 1 - avaialable memory 43213336576\nIteration 20 - at stack depth of 1 - avaialable memory 43190259712\nIteration 21 - at stack depth of 1 - avaialable memory 43133902848\nIteration 22 - at stack depth of 1 - avaialable memory 43027984384\nIteration 23 - at stack depth of 1 - avaialable memory 43006255104\n...\n</code></pre>\n<p><a href=\"https://replit.com/@pygeek1/os-system-recursion#main.py\" rel=\"nofollow noreferrer\">https://replit.com/@pygeek1/os-system-recursion#main.py</a></p>\n<h1>References</h1>\n<p><a href=\"https://pubs.opengroup.org/onlinepubs/9699919799/functions/system.html\" rel=\"nofollow noreferrer\">https://pubs.opengroup.org/onlinepubs/9699919799/functions/system.html</a></p>\n"}
{"Id": 73699500, "PostTypeId": 1, "Title": "python-polars split string column into many columns by delimiter", "Body": "<p>In pandas, the following code will split the string from col1 into many columns. is there a way to do this in polars?</p>\n<pre><code>d = {'col1': [&quot;a/b/c/d&quot;, &quot;a/b/c/d&quot;]}\ndf= pd.DataFrame(data=d)\ndf[[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]]=df[&quot;col1&quot;].str.split('/',expand=True)\n</code></pre>\n", "AcceptedAnswerId": 73703650, "AcceptedAnswer": "<p>Here's an algorithm that will automatically adjust for the required number of columns -- and should be quite performant.</p>\n<p>Let's start with this data.  Notice that I've purposely added the empty string <code>&quot;&quot;</code> and a null value - to show how the algorithm handles these values.  Also, the number of split strings varies widely.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import polars as pl\ndf = pl.DataFrame(\n    {\n        &quot;my_str&quot;: [&quot;cat&quot;, &quot;cat/dog&quot;, None, &quot;&quot;, &quot;cat/dog/aardvark/mouse/frog&quot;],\n    }\n)\ndf\n</code></pre>\n<pre><code>shape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 my_str                      \u2502\n\u2502 ---                         \u2502\n\u2502 str                         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 cat                         \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 cat/dog                     \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 null                        \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502                             \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 cat/dog/aardvark/mouse/frog \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<h4>The Algorithm</h4>\n<p>The algorithm below may be a bit more than you need, but you can edit/delete/add as you need.</p>\n<pre class=\"lang-py prettyprint-override\"><code>(\n    df\n    .with_row_count('id')\n    .with_column(pl.col(&quot;my_str&quot;).str.split(&quot;/&quot;).alias(&quot;split_str&quot;))\n    .explode(&quot;split_str&quot;)\n    .with_column(\n        (&quot;string_&quot; + pl.arange(0, pl.count()).cast(pl.Utf8).str.zfill(2))\n        .over(&quot;id&quot;)\n        .alias(&quot;col_nm&quot;)\n    )\n    .pivot(\n        index=['id', 'my_str'],\n        values='split_str',\n        columns='col_nm',\n    )\n    .with_column(\n        pl.col('^string_.*$').fill_null(&quot;&quot;)\n    )\n)\n</code></pre>\n<pre><code>shape: (5, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 my_str                      \u2506 string_00 \u2506 string_01 \u2506 string_02 \u2506 string_03 \u2506 string_04 \u2502\n\u2502 --- \u2506 ---                         \u2506 ---       \u2506 ---       \u2506 ---       \u2506 ---       \u2506 ---       \u2502\n\u2502 u32 \u2506 str                         \u2506 str       \u2506 str       \u2506 str       \u2506 str       \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 cat                         \u2506 cat       \u2506           \u2506           \u2506           \u2506           \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 cat       \u2506 dog       \u2506           \u2506           \u2506           \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2   \u2506 null                        \u2506           \u2506           \u2506           \u2506           \u2506           \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 3   \u2506                             \u2506           \u2506           \u2506           \u2506           \u2506           \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 cat       \u2506 dog       \u2506 aardvark  \u2506 mouse     \u2506 frog      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n</code></pre>\n<h4>How it works</h4>\n<p>We first assign a row number <code>id</code> (which we'll need later), and use <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.internals.expr.string.ExprStringNameSpace.split.html#polars.internals.expr.string.ExprStringNameSpace.split\" rel=\"noreferrer\"><code>split</code></a> to separate the strings.  Note that the split strings form a list.</p>\n<pre class=\"lang-py prettyprint-override\"><code>(\n    df\n    .with_row_count('id')\n    .with_column(pl.col(&quot;my_str&quot;).str.split(&quot;/&quot;).alias(&quot;split_str&quot;))\n)\n</code></pre>\n<pre><code>shape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 my_str                      \u2506 split_str                  \u2502\n\u2502 --- \u2506 ---                         \u2506 ---                        \u2502\n\u2502 u32 \u2506 str                         \u2506 list[str]                  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 cat                         \u2506 [&quot;cat&quot;]                    \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 [&quot;cat&quot;, &quot;dog&quot;]             \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2   \u2506 null                        \u2506 null                       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 3   \u2506                             \u2506 [&quot;&quot;]                       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 [&quot;cat&quot;, &quot;dog&quot;, ... &quot;frog&quot;] \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<p>Next, we'll use <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.explode.html\" rel=\"noreferrer\"><code>explode</code></a> to put each string on its own row.  (Notice how the <code>id</code> column tracks the original row that each string came from.)</p>\n<pre class=\"lang-py prettyprint-override\"><code>(\n    df\n    .with_row_count('id')\n    .with_column(pl.col(&quot;my_str&quot;).str.split(&quot;/&quot;).alias(&quot;split_str&quot;))\n    .explode(&quot;split_str&quot;)\n)\n</code></pre>\n<pre><code>shape: (10, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 my_str                      \u2506 split_str \u2502\n\u2502 --- \u2506 ---                         \u2506 ---       \u2502\n\u2502 u32 \u2506 str                         \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 cat                         \u2506 cat       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 cat       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 dog       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2   \u2506 null                        \u2506 null      \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 3   \u2506                             \u2506           \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 cat       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 dog       \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 aardvark  \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 mouse     \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 frog      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<p>In the next step, we're going to generate our column names.  I chose to call each column <code>string_XX</code> where <code>XX</code> is the offset with regards to the original string.</p>\n<p>I've used the handy <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.internals.expr.string.ExprStringNameSpace.zfill.html\" rel=\"noreferrer\"><code>zfill</code></a> expression so that <code>1</code> becomes <code>01</code>.  (This makes sure that <code>string_02</code> comes before <code>string_10</code> if you decide to sort your columns later.)</p>\n<p>You can substitute your own naming in this step as you need.</p>\n<pre class=\"lang-py prettyprint-override\"><code>(\n    df\n    .with_row_count('id')\n    .with_column(pl.col(&quot;my_str&quot;).str.split(&quot;/&quot;).alias(&quot;split_str&quot;))\n    .explode(&quot;split_str&quot;)\n    .with_column(\n        (&quot;string_&quot; + pl.arange(0, pl.count()).cast(pl.Utf8).str.zfill(2))\n        .over(&quot;id&quot;)\n        .alias(&quot;col_nm&quot;)\n    )\n)\n</code></pre>\n<pre><code>shape: (10, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 my_str                      \u2506 split_str \u2506 col_nm    \u2502\n\u2502 --- \u2506 ---                         \u2506 ---       \u2506 ---       \u2502\n\u2502 u32 \u2506 str                         \u2506 str       \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 cat                         \u2506 cat       \u2506 string_00 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 cat       \u2506 string_00 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 dog       \u2506 string_01 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2   \u2506 null                        \u2506 null      \u2506 string_00 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 3   \u2506                             \u2506           \u2506 string_00 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 cat       \u2506 string_00 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 dog       \u2506 string_01 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 aardvark  \u2506 string_02 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 mouse     \u2506 string_03 \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 frog      \u2506 string_04 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<p>In the next step, we'll use the <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.DataFrame.pivot.html\" rel=\"noreferrer\"><code>pivot</code></a> function to place each string in its own column.</p>\n<pre class=\"lang-py prettyprint-override\"><code>(\n    df\n    .with_row_count('id')\n    .with_column(pl.col(&quot;my_str&quot;).str.split(&quot;/&quot;).alias(&quot;split_str&quot;))\n    .explode(&quot;split_str&quot;)\n    .with_column(\n        (&quot;string_&quot; + pl.arange(0, pl.count()).cast(pl.Utf8).str.zfill(2))\n        .over(&quot;id&quot;)\n        .alias(&quot;col_nm&quot;)\n    )\n    .pivot(\n        index=['id', 'my_str'],\n        values='split_str',\n        columns='col_nm',\n    )\n)\n</code></pre>\n<pre><code>shape: (5, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id  \u2506 my_str                      \u2506 string_00 \u2506 string_01 \u2506 string_02 \u2506 string_03 \u2506 string_04 \u2502\n\u2502 --- \u2506 ---                         \u2506 ---       \u2506 ---       \u2506 ---       \u2506 ---       \u2506 ---       \u2502\n\u2502 u32 \u2506 str                         \u2506 str       \u2506 str       \u2506 str       \u2506 str       \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 cat                         \u2506 cat       \u2506 null      \u2506 null      \u2506 null      \u2506 null      \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 1   \u2506 cat/dog                     \u2506 cat       \u2506 dog       \u2506 null      \u2506 null      \u2506 null      \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 2   \u2506 null                        \u2506 null      \u2506 null      \u2506 null      \u2506 null      \u2506 null      \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 3   \u2506                             \u2506           \u2506 null      \u2506 null      \u2506 null      \u2506 null      \u2502\n\u251c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u253c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u254c\u2524\n\u2502 4   \u2506 cat/dog/aardvark/mouse/frog \u2506 cat       \u2506 dog       \u2506 aardvark  \u2506 mouse     \u2506 frog      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<p>All that remains is to use <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.Expr.fill_null.html\" rel=\"noreferrer\"><code>fill_null</code></a> to replace the <code>null</code> values with an empty string <code>&quot;&quot;</code>.  Notice that I've used a regex expression in the <a href=\"https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.col.html\" rel=\"noreferrer\"><code>col</code></a> expression to target only those columns whose names start with &quot;string_&quot;.  (Depending on your other data, you may not want to replace null with <code>&quot;&quot;</code> everywhere in your data.)</p>\n"}
{"Id": 73143854, "PostTypeId": 1, "Title": "Linking opencv-python to opencv-cuda in Arch", "Body": "<p>I'm trying to to get OpenCV with CUDA to be used in Python open-cv on Arch Linux, but I'm not sure how to link it.</p>\n<p>Arch provides a package <a href=\"https://archlinux.org/packages/extra/x86_64/opencv-cuda/\" rel=\"noreferrer\">opencv-cuda</a>, which provides <a href=\"https://archlinux.org/packages/extra/x86_64/opencv-cuda/files/\" rel=\"noreferrer\">these files</a>.</p>\n<p>Guides I've found said to link the python cv2.so to the one provided, but the package doesn't provide that. My python <code>site_packages</code> has <code>cv2.abi3.so</code> in it, and I've tried linking that to <code>core.so</code> and <code>cvv.so</code> to no avail.</p>\n<p>Do I need to build it differently to support Python? Or is there another step I'm missing?</p>\n", "AcceptedAnswerId": 73227581, "AcceptedAnswer": "<p>On Arch, opencv-cuda <strong>provides</strong> <code>opencv=4.6.0</code>, but you still need the python bindings. Fortunately though, installing <code>python-opencv</code> after installling <code>opencv-cuda</code> works, since it leverages it.</p>\n<p>I just set up my Python virtual environment to allow system site packages (<code>python -m venv .venv --system-site-packages</code>), and it works like a charm! Neural net image detection runs ~300% as fast now.</p>\n"}
{"Id": 72839263, "PostTypeId": 1, "Title": "Access python interpreter in VSCode version controll when using pre-commit", "Body": "<p>I'm using pre-commit for most of my Python projects, and in many of them, I need to use pylint as a local repo. When I want to commit, I always have to activate python venv and then commit; otherwise, I'll get the following error:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>black....................................................................Passed\npylint...................................................................Failed\n- hook id: pylint\n- exit code: 1\n\nExecutable `pylint` not found\n</code></pre>\n<p>When I use vscode version control to commit, I get the same error; I searched about the problem and didn't find any solution to avoid the error in VSCode.</p>\n<p>This is my typical <code>.pre-commit-config.yaml</code>:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>repos:\n-   repo: https://github.com/ambv/black\n    rev: 21.9b0\n    hooks:\n    - id: black\n      language_version: python3.8\n      exclude: admin_web/urls\\.py\n-   repo: local\n    hooks:\n    -   id: pylint\n        name: pylint\n        entry: pylint\n        language: python\n        types: [python]\n        args: \n         - --rcfile=.pylintrc\n\n</code></pre>\n", "AcceptedAnswerId": 72839338, "AcceptedAnswer": "<p>you have ~essentially two options here -- neither are great (<code>language: system</code> is kinda the unsupported escape hatch so it's on you to make those things available on <code>PATH</code>)</p>\n<p>you could use a specific path to the virtualenv <code>entry: venv/bin/pylint</code> -- though that will reduce the portability.</p>\n<p>or you could start vscode with your virtualenv activated (usually <code>code .</code>) -- this doesn't always work if vscode is already running</p>\n<hr />\n<p>disclaimer: I created pre-commit</p>\n"}
{"Id": 73271404, "PostTypeId": 1, "Title": "How to find the average of the differences between all the numbers of a Python List", "Body": "<p>I have a python list like this,</p>\n<pre><code>arr = [110, 60, 30, 10, 5] \n</code></pre>\n<p>What I need to do is actually find the difference of every number with all the other numbers and then find the average of all those differences.</p>\n<p>So, for this case, it would first find the difference between <code>110</code> and then all the remaining elements, i.e. <code>60, 30, 10, 5</code>, and then it will find the difference of <code>60</code> with the remaining elements, i.e. <code>30, 10, 5</code> and etc.</p>\n<p>After which, it will compute the Average of all these differences.</p>\n<p>Now, this can easily be done with two For Loops but in <code>O(n^2)</code> time complexity and also a little bit of &quot;messy&quot; code. I was wondering if there was a faster and more efficient way of doing this same thing?</p>\n", "AcceptedAnswerId": 73271447, "AcceptedAnswer": "<p>I'll just give the formula first:</p>\n<pre><code>n = len(arr)\nout = np.sum(arr * np.arange(n-1, -n, -2) ) / (n*(n-1) / 2)\n# 52\n</code></pre>\n<p>Explanation: You want to find the mean of</p>\n<pre><code>a[0] - a[1], a[0] - a[2],..., a[0] - a[n-1]\n             a[1] - a[2],..., a[1] - a[n-1]\n                         ...\n</code></pre>\n<p>there, your</p>\n<pre><code>`a[0]` occurs `n-1` times with `+` sign, `0` with `-` -&gt; `n-1` times\n`a[1]` occurs `n-2` times with `+` sign, `1` with `-` -&gt; `n-3` times\n... and so on \n</code></pre>\n"}
{"Id": 72497046, "PostTypeId": 1, "Title": "skipping a certain range of a list at time in python", "Body": "<p>I have a array, I want to pick first 2 or range, skip the next 2, pick the next 2 and continue this until the end of the list</p>\n<pre><code>list = [2, 4, 6, 7, 9,10, 13, 11, 12,2]\nresults_wanted = [2,4,9,10,12,2] # note how it skipping 2. 2 is used here as and example\n</code></pre>\n<p>Is there way to achieve this in python?</p>\n", "AcceptedAnswerId": 72497107, "AcceptedAnswer": "<p>Taking <code>n</code> number of elements and skipping the next <code>n</code>.</p>\n<pre class=\"lang-py prettyprint-override\"><code>l = [2, 4, 6, 7, 9, 10, 13, 11, 12, 2]\nn = 2\nwanted = [x for i in range(0, len(l), n + n) for x in l[i: i + n]]\n### Output : [2, 4, 9, 10, 12, 2]\n</code></pre>\n"}
{"Id": 72409563, "PostTypeId": 1, "Title": "Unsupported hash type ripemd160 with hashlib in Python", "Body": "<p>After a thorough search, I have not found a complete explanation and solution to this very common problem on the entire web. All scripts that need to encode with hashlib give me error:</p>\n<p><strong>Python 3.10</strong></p>\n<pre><code>import hashlib\nh = hashlib.new('ripemd160')\n</code></pre>\n<p>return:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;/usr/lib/python3.10/hashlib.py&quot;, line 166, in __hash_new\n    return __get_builtin_constructor(name)(data)\n  File &quot;/usr/lib/python3.10/hashlib.py&quot;, line 123, in __get_builtin_constructor\n    raise ValueError('unsupported hash type ' + name)\nValueError: unsupported hash type ripemd160\n</code></pre>\n<p>I already tried to check if that hash exists in the library, and if I have it:</p>\n<p><code>print(hashlib.algorithms_available)</code>: {'md5', 'sm3', 'sha3_512', 'sha384', 'sha256', 'sha1', 'shake_128', 'sha224', 'sha512_224', 'sha512_256', 'blake2b', <strong>'ripemd160'</strong>, 'md5-sha1', 'sha512', 'sha3_256', 'shake_256', 'sha3_384', 'whirlpool', 'md4', 'blake2s', 'sha3_224'}</p>\n<p>I am having this problem in a vps with linux, but in my pc I use Windows and I don't have this problem.</p>\n<p>I sincerely appreciate any help or suggestion.</p>\n", "AcceptedAnswerId": 72508879, "AcceptedAnswer": "<p>Hashlib uses OpenSSL for ripemd160 and apparently OpenSSL disabled some older crypto algos around version 3.0 in November 2021. All the functions are still there but require manual enabling. See <a href=\"https://github.com/openssl/openssl/issues/16994\" rel=\"noreferrer\">issue 16994 of OpenSSL github project</a> for details.</p>\n<p>To quickly enable it, find the directory that holds your OpenSSL config file or a symlink to it, by running the below command:</p>\n<pre><code>openssl version -d\n</code></pre>\n<p>You can now go to the directory and edit the config file (it may be necessary to use sudo):</p>\n<pre><code>nano openssl.cnf\n</code></pre>\n<p>Make sure that the config file contains following lines:</p>\n<pre><code>openssl_conf = openssl_init\n\n[openssl_init]\nproviders = provider_sect\n\n[provider_sect]\ndefault = default_sect\nlegacy = legacy_sect\n\n[default_sect]\nactivate = 1\n\n[legacy_sect]\nactivate = 1\n</code></pre>\n<p>Tested on: OpenSSL 3.0.2, Python 3.10.4, Linux Ubuntu 22.04 LTS aarch64, I have no access to other platforms at the moment.</p>\n"}
{"Id": 73739158, "PostTypeId": 1, "Title": "NodeJS convert to Byte Array code return different results compare to python", "Body": "<p>I got the following Javascript code and I need to convert it to Python(I'm not an expert in hashing so sorry for my knowledge on this subject)</p>\n<pre><code>function generateAuthHeader(dataToSign) {\n    let apiSecretHash = new Buffer(&quot;Rbju7azu87qCTvZRWbtGqg==&quot;, 'base64');\n    let apiSecret = apiSecretHash.toString('ascii');\n    var hash = CryptoJS.HmacSHA256(dataToSign, apiSecret);\n    return hash.toString(CryptoJS.enc.Base64);\n}\n</code></pre>\n<p>when I ran <code>generateAuthHeader(&quot;abc&quot;)</code> it returned <code>+jgBeooUuFbhMirhh1KmQLQ8bV4EXjRorK3bR/oW37Q=</code></p>\n<p>So I tried writing the following Python code:</p>\n<pre><code>def generate_auth_header(data_to_sign):\n    api_secret_hash = bytearray(base64.b64decode(&quot;Rbju7azu87qCTvZRWbtGqg==&quot;))\n    hash = hmac.new(api_secret_hash, data_to_sign.encode(), digestmod=hashlib.sha256).digest()\n    return base64.b64encode(hash).decode()\n</code></pre>\n<p>But when I ran <code>generate_auth_header(&quot;abc&quot;)</code> it returned a different result <code>aOGo1XCa5LgT1CIR8C1a10UARvw2sqyzWWemCJBJ1ww=</code></p>\n<p>Can someone tell me what is wrong with my Python code and what I need to change?</p>\n<p>The base64 is the string I generated myself for this post</p>\n<p>UPDATE:\nthis is the document I'm working with</p>\n<pre><code>//Converting the Rbju7azu87qCTvZRWbtGqg== (key) into byte array \n//Converting the data_to_sign into byte array \n//Generate the hmac signature\n</code></pre>\n<p>it seems like <code>apiSecretHash</code> and <code>api_secret_hash</code> is different, but I don't quite understand as the equivalent of <code>new Buffer()</code> in NodeJS is <code>bytearray()</code> in python</p>\n", "AcceptedAnswerId": 73769662, "AcceptedAnswer": "<p>It took me 2 days to look it up and ask for people in python discord and I finally got an answer. Let me summarize the problems:</p>\n<ul>\n<li>API secret hash from both return differents hash of the byte array\njavascript</li>\n</ul>\n<p>Javascript</p>\n<pre><code>apiSecret = &quot;E8nm,ns:\\u0002NvQY;F*&quot;\n</code></pre>\n<p>Python</p>\n<pre><code>api_secret_hash = b'E\\xb8\\xee\\xed\\xac\\xee\\xf3\\xba\\x82N\\xf6QY\\xbbF\\xaa'\n</code></pre>\n<p>once we replaced the hash with python code it return the same result</p>\n<pre><code>def generate_auth_header(data_to_sign):\n    api_secret_hash = &quot;E8nm,ns:\\u0002NvQY;F*&quot;.encode()\n\n    hash = hmac.new(api_secret_hash, data_to_sign.encode(), digestmod=hashlib.sha256).digest()\n    return base64.b64encode(hash).decode()\n</code></pre>\n<p>encoding for ASCII in node.js you can find here <a href=\"https://github.com/nodejs/node/blob/a2a32d8beef4d6db3a8c520572e8a23e0e51a2f8/src/string_bytes.cc#L636-L647\" rel=\"noreferrer\">https://github.com/nodejs/node/blob/a2a32d8beef4d6db3a8c520572e8a23e0e51a2f8/src/string_bytes.cc#L636-L647</a></p>\n<pre><code>case ASCII:\n  if (contains_non_ascii(buf, buflen)) {\n    char* out = node::UncheckedMalloc(buflen);\n    if (out == nullptr) {\n      *error = node::ERR_MEMORY_ALLOCATION_FAILED(isolate);\n      return MaybeLocal&lt;Value&gt;();\n    }\n    force_ascii(buf, out, buflen);\n    return ExternOneByteString::New(isolate, out, buflen, error);\n  } else {\n    return ExternOneByteString::NewFromCopy(isolate, buf, buflen, error);\n  }\n</code></pre>\n<p>there is this force_ascii() function that is called when the data contains non-ASCII characters which is implemented here <a href=\"https://github.com/nodejs/node/blob/a2a32d8beef4d6db3a8c520572e8a23e0e51a2f8/src/string_bytes.cc#L531-L573\" rel=\"noreferrer\">https://github.com/nodejs/node/blob/a2a32d8beef4d6db3a8c520572e8a23e0e51a2f8/src/string_bytes.cc#L531-L573</a></p>\n<p>so we need to check for the hash the same as NodeJS one, so we get the final version of the Python code:</p>\n<pre><code>def generate_auth_header(data_to_sign):\n    # convert to bytearray so the for loop below can modify the values\n    api_secret_hash = bytearray(base64.b64decode(&quot;Rbju7azu87qCTvZRWbtGqg==&quot;))\n    \n    # &quot;force&quot; characters to be in ASCII range\n    for i in range(len(api_secret_hash)):\n        api_secret_hash[i] &amp;= 0x7f;\n\n    hash = hmac.new(api_secret_hash, data_to_sign.encode(), digestmod=hashlib.sha256).digest()\n    return base64.b64encode(hash).decode()\n</code></pre>\n<p>now it returned the same result as NodeJS one</p>\n<p>Thank you Mark from the python discord for helping me understand and fix this!</p>\n<p>Hope anyone in the future trying to convert byte array from javascript to python know about this different of NodeJS Buffer() function</p>\n"}
{"Id": 72199354, "PostTypeId": 1, "Title": "Python type hinting for a generic mutable tuple / fixed length sequence with multiple types", "Body": "<p>I am currently working on adding type hints to a project and can't figure out how to get this right. I have a list of lists, with the nested list containing two elements of type int and float. The first element of the nested list is always an int and the second is always a float.</p>\n<pre><code>my_list = [[1000, 5.5], [1432, 2.2], [1234, 0.3]]\n</code></pre>\n<p>I would like to type annotate it so that unpacking the inner list in for loops or loop comprehensions keeps the type information. I could change the inner lists to tuples and would get what I'm looking for:</p>\n<pre><code>def some_function(list_arg: list[tuple[int, float]]): pass\n\n</code></pre>\n<p>However, I need the inner lists to be mutable. Is there a nice way to do this for lists? I know that abstract classes like Sequence and Collection do not support multiple types.</p>\n", "AcceptedAnswerId": 73817809, "AcceptedAnswer": "<p>I think the question highlights a fundamental difference between statically typed Python and dynamically typed Python. For someone who is used to dynamically typed Python (or Perl or JavaScript or any number of other scripting languages), it's perfectly normal to have diverse data types in a list. It's convenient, flexible, and doesn't require you to define custom data types. However, when you introduce static typing, you step into a tighter box that requires more rigorous design.</p>\n<p>As several others have already pointed out, type annotations for lists require all elements of the list to be the same type, and don't allow you to specify a length. Rather than viewing this as a shortcoming of the type system, you should consider that the flaw is in your own design. What you are really looking for is a class with two data members. The first data member is named <code>0</code>, and has type <code>int</code>, and the second is named <code>1</code>, and has type <code>float</code>. As your friend, I would recommend that you define a proper class, with meaningful names for these data members. As I'm not sure what your data type represents, I'll make up names, for illustration.</p>\n<pre><code>class Sample:\n    def __init__(self, atomCount: int, atomicMass: float):\n        self.atomCount = atomCount\n        self.atomicMass = atomicMass\n</code></pre>\n<p>This not only solves the typing problem, but also gives a major boost to readability. Your code would now look more like this:</p>\n<pre><code>my_list = [Sample(1000, 5.5), Sample(1432, 2.2), Sample(1234, 0.3)]\n\ndef some_function(list_arg: list[Sample]): pass\n</code></pre>\n<p>I do think it's worth highlighting Stef's comment, which points to <a href=\"https://stackoverflow.com/q/29290359/6284025\">this</a> question. The answers given highlight two useful features related to this.</p>\n<p>First, as of Python 3.7, you can mark a class as a data class, which will automatically generate methods like <code>__init__()</code>. The <code>Sample</code> class would look like this, using the <code>@dataclass</code> decorator:</p>\n<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Sample:\n    atomCount: int\n    atomicMass: float\n</code></pre>\n<p>Another answer to that question mentions a PyPi package called recordclass, which it says is basically a mutable <code>namedtuple</code>. The typed version is called <code>RecordClass</code></p>\n<pre><code>from recordclass import RecordClass\n\nclass Sample(RecordClass):\n    atomCount: int\n    atomicMass: float\n</code></pre>\n"}
{"Id": 72876146, "PostTypeId": 1, "Title": "Handling GIL when calling python lambda from C++ function", "Body": "<h2>The question</h2>\n<p>Is pybind11 somehow magically doing the work of <code>PyGILState_Ensure()</code> and <code>PyGILState_Release()</code>? And if not, how should I do it?</p>\n<h2>More details</h2>\n<p><a href=\"https://stackoverflow.com/questions/42521830/call-a-python-function-from-c-using-pybind11\">There</a> <a href=\"https://stackoverflow.com/questions/45054860/extending-c-to-python-using-pybind11\">are</a> <a href=\"https://stackoverflow.com/questions/70603855/how-to-set-python-function-as-callback-for-c-using-pybind11\">many</a> questions regarding passing a python function to C++ as a callback using pybind11, but I haven't found one that explains the use of the GIL with pybind11.</p>\n<p>The <a href=\"https://docs.python.org/2/c-api/init.html#non-python-created-threads\" rel=\"nofollow noreferrer\">documentation</a> is pretty clear about the GIL:</p>\n<blockquote>\n<p>[...] However, when threads are created from C (for example by a third-party library with its own thread management), they don\u2019t hold the GIL, nor is there a thread state structure for them.</p>\n<p>If you need to call Python code from these threads (often this will be part of a callback API provided by the aforementioned third-party library), you must first register these threads with the interpreter by creating a thread state data structure, then acquiring the GIL, and finally storing their thread state pointer, before you can start using the Python/C API.</p>\n</blockquote>\n<p>I can easily bind a C++ function that takes a callback:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>py::class_&lt;SomeApi&gt; some_api(m, &quot;SomeApi&quot;); \nsome_api\n    .def(py::init&lt;&gt;())\n    .def(&quot;mode&quot;, &amp;SomeApi::subscribe_mode, &quot;Subscribe to 'mode' updates.&quot;);\n</code></pre>\n<p>With the corresponding C++ function being something like:</p>\n<pre class=\"lang-cpp prettyprint-override\"><code>void subscribe_mode(const std::function&lt;void(Mode mode)&gt;&amp; mode_callback);\n</code></pre>\n<p>But because pybind11 cannot know about the threading happening in my C++ implementation, I suppose it cannot handle the GIL for me. Therefore, if <code>mode_callback</code> is called by a thread created from C++, does that mean that I should write a wrapper to <code>SomeApi::subscribe_mode</code> that uses <code>PyGILState_Ensure()</code> and <code>PyGILState_Release()</code> for each call?</p>\n<p><a href=\"https://stackoverflow.com/a/60417929/1368342\">This answer</a> seems to be doing something similar, but still slightly different: instead of &quot;taking the GIL&quot; when calling the callback, it seems like it &quot;releases the GIL&quot; when starting/stopping the thread. Still I'm wondering if there exists something like <code>py::call_guard&lt;py::gil_scoped_acquire&gt;()</code> that would do exactly what I (believe I) need, i.e. wrapping my callback with <code>PyGILState_Ensure()</code> and <code>PyGILState_Release()</code>.</p>\n", "AcceptedAnswerId": 72933328, "AcceptedAnswer": "<h2>In general</h2>\n<p>pybind11 tries to do the Right Thing and the GIL will be held when pybind11 knows that it is calling a python function, or in C++ code that is called from python via pybind11. The only time that you need to explicitly acquire the GIL when using pybind11 is when you are writing C++ code that accesses python and will be called from other C++ code, or if you have explicitly dropped the GIL.</p>\n<h2>std::function wrapper</h2>\n<p>The wrapper for <code>std::function</code> always acquires the GIL via <code>gil_scoped_acquire</code> <a href=\"https://github.com/pybind/pybind11/blob/f9f00495a3f0ef6037c215c42bd2d919590ff11f/include/pybind11/functional.h#L100\" rel=\"nofollow noreferrer\">when the function is called</a>, so your python callback will always be called with the GIL held, regardless which thread it is called from.</p>\n<p>If <code>gil_scoped_acquire</code> is called from a thread that does not currently have a GIL thread state associated with it, then it will <a href=\"https://github.com/pybind/pybind11/blob/f9f00495a3f0ef6037c215c42bd2d919590ff11f/include/pybind11/gil.h#L64\" rel=\"nofollow noreferrer\">create a new thread state</a>. As a side effect, if nothing else in the thread acquires the thread state and increments the reference count, then once your function exits the GIL will be released by the destructor of <code>gil_scoped_acquire</code> and then <a href=\"https://github.com/pybind/pybind11/blob/f9f00495a3f0ef6037c215c42bd2d919590ff11f/include/pybind11/gil.h#L101\" rel=\"nofollow noreferrer\">it will delete the thread state associated with that thread</a>.</p>\n<p>If you're only calling the function once from another thread, this isn't a problem. If you're calling the callback often, it will create/delete the thread state a lot, which probably isn't great for performance. It would be better to cause the thread state to be created when your thread starts (or even easier, start the thread from Python and call your C++ code from python).</p>\n"}
{"Id": 74097901, "PostTypeId": 1, "Title": "meaning of `__all__` inside Python class", "Body": "<p>I am aware of the use of <code>__all__</code> at module scope. However I came across the usage of <code>__all__</code> inside classes. This is done e.g. in the <a href=\"https://github.com/python/cpython/blob/1863302d61a7a5dd8b8d345a00f0ee242c7c10bf/Lib/typing.py#L3328-L3333\" rel=\"noreferrer\">Python standardlib</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class re(metaclass=_DeprecatedType):\n    &quot;&quot;&quot;Wrapper namespace for re type aliases.&quot;&quot;&quot;\n\n    __all__ = ['Pattern', 'Match']\n    Pattern = Pattern\n    Match = Match\n</code></pre>\n<p>What does <code>__all__</code> achieve in this context?</p>\n", "AcceptedAnswerId": 74098046, "AcceptedAnswer": "<p>The <code>typing</code> module does some unorthodox things to patch existing modules (like <code>re</code>). Basically, the built-in module <code>re</code> is being replaced with this class <code>re</code> defined using a custom metaclass that intercepts attribute lookups on the underlying object. <code>__all__</code> doesn't really have any special meaning to the <em>class</em> (it's just another class attribute), but it effectively becomes the <code>__all__</code> attribute of the <code>re</code> module. It's the metaclass's definition of <code>__getattribute__</code> that accomplishes this.</p>\n"}
{"Id": 74202814, "PostTypeId": 1, "Title": "In python, create index from flat representation of nested structure in a list, sorting by alphabetical order", "Body": "<p>I have lists where each entry is representing a nested structure, where <code>/</code> represents each level in the structure.</p>\n<pre><code>['a','a/b/a','a/b','a/b/d',....]\n</code></pre>\n<p>I want to take such a list and return an index list where each level is sorted in alphabetical order.</p>\n<p>If we had the following list</p>\n<pre><code>['a','a/b','a/b/a','a/c','a/c/a','b']\n</code></pre>\n<p>It represents the nested structure</p>\n<pre><code>'a':                   #1\n\n    'b':               #1.1\n         'a': ...      #1.1.1\n    'c':               #1.2\n         'a': ...      #1.2.1\n'b' : ...              #2\n</code></pre>\n<p>I am trying to get the output</p>\n<pre><code> ['1','1.1','1.1.1', '1.2','1.2.1','2']\n</code></pre>\n<p>But I am having real issue on how to tackle the problem, would it be solved recursively? Or what would be a way to solve this for any generic list where each level is separated by <code>/</code>? The list is originally not necessarily sorted, and each level can be any generic word.</p>\n", "AcceptedAnswerId": 74204355, "AcceptedAnswer": "<p>Since the goal is to simply convert the paths to indices according to their respective positions against other paths of the same prefix, there is no need to build a tree at all. Instead, iterate over the paths in alphabetical order while using a dict of sets to keep track of the prefixes at each level of paths, and join the lengths of sets at each level for output:</p>\n<pre><code>def indices(paths):\n    output = {}\n    names = {}\n    for index, path in sorted(enumerate(paths), key=lambda t: t[1]):\n        counts = []\n        prefixes = tuple(path.split('/'))\n        for level, name in enumerate(prefixes):\n            prefix = prefixes[:level]\n            names.setdefault(prefix, set()).add(name)\n            counts.append(len(names[prefix]))\n        output[index] = '.'.join(map(str, counts))\n    return list(map(output.get, range(len(output))))\n</code></pre>\n<p>so that:</p>\n<pre><code>print(indices(['a', 'a/b', 'a/b/a', 'a/c', 'a/c/a', 'b']))\nprint(indices(['a', 'c', 'b', 'a/b']))\nprint(indices(['a/b/c/d', 'a/b/d', 'a/b/c']))\nprint(indices(['abc/d', 'bcc/d']))\nprint(indices(['apple/cat','apple/dog', 'banana/dog']))\n</code></pre>\n<p>outputs:</p>\n<pre><code>['1', '1.1', '1.1.1', '1.2', '1.2.1', '2']\n['1', '3', '2', '1.1']\n['1.1.1.1', '1.1.2', '1.1.1']\n['1.1', '2.1']\n['1.1', '1.2', '2.1']\n</code></pre>\n<p>Demo: <a href=\"https://replit.com/@blhsing/StainedMassivePi\" rel=\"nofollow noreferrer\">https://replit.com/@blhsing/StainedMassivePi</a></p>\n"}
{"Id": 73647685, "PostTypeId": 1, "Title": "Why does a temporary variable in Python change how this Pass-By-Sharing variable behaves?", "Body": "<p>first-time questioner here so do highlight my mistakes.</p>\n<p>I was grinding some Leetcode and came across a behavior (not related to the problem) in Python I couldn't quite figure out nor google-out. It's especially difficult because I'm not sure if my lack of understanding is in:</p>\n<ol>\n<li>recursion</li>\n<li>the <code>+=</code> operator in Python or variable assignment in general</li>\n<li>or Python's pass-by-sharing behavior</li>\n<li>or just something else entirely</li>\n</ol>\n<p>Here's the simplified code:</p>\n<pre><code>class Holder:\n    def __init__(self, val=0):\n         self.val = val\n\nclass Solution:\n    def runThis(self):\n        holder = Holder()\n        self.diveDeeper(holder, 5)\n        return \n        \n    def diveDeeper(self, holder, n):\n        if n==0:\n            return 1\n\n        # 1) Doesn't result in mutation\n        holder.val += self.diveDeeper(holder, n-1)\n\n        # 2) Also doesn't result in mutation\n        # holder.val = holder.val + self.diveDeeper(holder, n-1)\n\n        # 3) !! Results in mutations\n        # returnVal = self.diveDeeper(holder, n-1)\n        # holder.val += returnVal\n\n        print(holder.val)\n        return 1\n\na = Solution()\na.runThis()\n</code></pre>\n<p>So yeah my main source of confusion is how (1) and (3) look semantically identical to me but results in two completely different outcomes:</p>\n<pre><code>================ RESTART: Case 1 ===============\n1\n1\n1\n1\n1\n&gt;&gt;&gt; \n================ RESTART: Case 3 ===============\n\n1\n2\n3\n4\n5\n&gt;&gt;&gt; \n</code></pre>\n<p>From (2), it doesn't seem related to the <code>+=</code> operator and for brevity, I haven't included the tens of variations I've tried but none of them have given me any leads so far. Would really appreciate any pointers in the right direction (especially in case I get blindsided in job interviews lmao)</p>\n<p>PS: In case this is relevant, I'm using Python 3.8.2</p>\n", "AcceptedAnswerId": 73648204, "AcceptedAnswer": "<p>In Python, if you have <code>expression1() + expression2()</code>, <code>expression1()</code> is evaluated first.</p>\n<p>So 1 and 2 are really equivalent to:</p>\n<pre><code>left = holder.val\nright = self.diveDeeper(holder, n - 1)\nholder.val = left + right\n</code></pre>\n<p>Now, <code>holder.val</code> is only ever modified after the recursive call, but you use the value from before the recursive call, which means that no matter the iteration, <code>left == 0</code>.</p>\n<p>Your solution 3 is equivalent to:</p>\n<pre><code>right = self.diveDeeper(holder, n - 1)\nleft = holder.val\nholder.val = left + right\n</code></pre>\n<p>So the recursive call is made before <code>left = holder.val</code> is evaluated, which means <code>left</code> is now the result of the sum of the previous iteration.</p>\n<p>This is why you have to be careful with mutable state, you got to understand the order of operations perfectly.</p>\n"}
{"Id": 73157383, "PostTypeId": 1, "Title": "How do you create a fully-fledged Python package?", "Body": "<p>When creating a Python package, you can simply write the code, build the package, and share it on PyPI. But how do you do that?</p>\n<ol>\n<li>How do you create a Python package?</li>\n<li>How do you publish it?</li>\n</ol>\n<p>And then, what if you want to go further?</p>\n<ol start=\"3\">\n<li>How do you set up CI/CD for it?</li>\n<li>How do you test it and check code coverage?</li>\n<li>How do you lint it?</li>\n<li>How do you automate everything you can?</li>\n</ol>\n", "AcceptedAnswerId": 73157490, "AcceptedAnswer": "<h1>Preamble</h1>\n<p>When you've published dozens of packages, you know how to answer these questions in ways that suit your workflow(s) and taste. But answering these questions for the first time can be quite difficult, time consuming, and frustrating!</p>\n<p>That's why I spent days researching ways of doing these things, which I then published as a blog article called <a href=\"https://mathspp.com/blog/how-to-create-a-python-package-in-2022\" rel=\"noreferrer\">How to create a Python package in 2022</a>.</p>\n<p>That article, and this answer, document my findings for when I wanted to publish my package <a href=\"https://github.com/mathspp/extendedjson\" rel=\"noreferrer\">extendedjson</a></p>\n<h1>Overview</h1>\n<p>Here is an overview of some tools you can use and the steps you can take, in the order I followed them while discovering all of this.</p>\n<p>Disclaimer: other alternative tools exist (usually) &amp; most of the steps here are not mandatory.</p>\n<ul>\n<li>Use <a href=\"https://python-poetry.org/\" rel=\"noreferrer\">Poetry</a> for dependency management</li>\n<li>Use <a href=\"https://github.com/\" rel=\"noreferrer\">GitHub</a> to host the code</li>\n<li>Use <a href=\"https://pre-commit.com/\" rel=\"noreferrer\">pre-commit</a> to ensure committed code is linted &amp; formatted well</li>\n<li>Use <a href=\"https://test.pypi.org/\" rel=\"noreferrer\">Test PyPI</a> to test uploading your package (which will make it installable with <code>pip</code>)</li>\n<li>Use <a href=\"https://scriv.readthedocs.io/en/latest/\" rel=\"noreferrer\">Scriv</a> for changelog management</li>\n<li>Upload to the real <a href=\"https://pypi.org\" rel=\"noreferrer\">PyPI</a></li>\n<li>Use <a href=\"https://docs.pytest.org/en/\" rel=\"noreferrer\">pytest</a> to test your Python code</li>\n<li>Use <a href=\"https://tox.wiki/en/latest/\" rel=\"noreferrer\">tox</a> to automate linting, formatting, and testing across Python versions\n<ul>\n<li><a href=\"https://github.com/psf/black\" rel=\"noreferrer\">black</a></li>\n<li><a href=\"https://pycqa.github.io/isort/\" rel=\"noreferrer\">isort</a></li>\n<li><a href=\"https://pylint.pycqa.org/en/latest/\" rel=\"noreferrer\">pylint</a></li>\n<li><a href=\"https://flake8.pycqa.org/en/latest/\" rel=\"noreferrer\">flake8</a> with <a href=\"https://github.com/PyCQA/mccabe\" rel=\"noreferrer\">mccabe</a></li>\n</ul>\n</li>\n<li>Add code coverage with <a href=\"https://coverage.readthedocs.io/\" rel=\"noreferrer\">coverage.py</a></li>\n<li>Set up CI/CD with GitHub Actions\n<ul>\n<li>run linters and tests</li>\n<li>trigger automatically on pull requests and commits</li>\n<li>integrate with <a href=\"https://about.codecov.io/\" rel=\"noreferrer\">Codecov</a> for coverage reports</li>\n<li>publish to PyPI automatically</li>\n</ul>\n</li>\n<li>Add cool README badges</li>\n<li>Tidy up a bit\n<ul>\n<li>set tox to use pre-commit</li>\n<li>remove duplicate work between tox and pre-commit hooks</li>\n<li>remove some redundancy in CI/CD</li>\n</ul>\n</li>\n</ul>\n<h1>Steps</h1>\n<p>Here is an overview of the things you can do and more or less how to do it. Again, thorough instructions plus the rationale of why I picked certain tools, methods, etc, can be found in <a href=\"https://mathspp.com/blog/how-to-create-a-python-package-in-2022\" rel=\"noreferrer\">the reference article</a>.</p>\n<ul>\n<li><p>Use <a href=\"https://python-poetry.org/\" rel=\"noreferrer\">Poetry</a> for dependency management.</p>\n<ul>\n<li><code>poetry init</code> initialises a project in a directory or <code>poetry new dirname</code> creates a new directory structure for you</li>\n<li>do <code>poetry install</code> to install all your dependencies</li>\n<li><code>poetry add packagename</code> can be used to add <code>packagename</code> as a dependency, use <code>-D</code> if it's a development dependency (i.e., you need it while developing the package, but the package users won't need it. For example, <code>black</code> is a nice example of a development dependency)</li>\n</ul>\n</li>\n<li><p>Set up a repository on <a href=\"https://github.com/\" rel=\"noreferrer\">GitHub</a> to host your code.</p>\n</li>\n<li><p>Set up pre-commit hooks to ensure your code is always properly formatted and it passes linting. This goes on <code>.pre-commit-config.yaml</code>. E.g., the YAML below checks TOML and YAML files, ensures all files end with a newline, makes sure the end-of-line marker is consistent across all files, and then runs <a href=\"https://github.com/psf/black\" rel=\"noreferrer\">black</a> and <a href=\"https://pycqa.github.io/isort/\" rel=\"noreferrer\">isort</a> on your code.</p>\n</li>\n</ul>\n<pre class=\"lang-yaml prettyprint-override\"><code># See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n\u00a0 - repo: https://github.com/pre-commit/pre-commit-hooks\n\u00a0 \u00a0 rev: v4.0.1\n\u00a0 \u00a0 hooks:\n\u00a0 \u00a0 \u00a0 - id: check-toml\n\u00a0 \u00a0 \u00a0 - id: check-yaml\n\u00a0 \u00a0 \u00a0 - id: end-of-file-fixer\n\u00a0 \u00a0 \u00a0 - id: mixed-line-ending\n\u00a0 - repo: https://github.com/psf/black\n\u00a0 \u00a0 rev: 22.3.0\n\u00a0 \u00a0 hooks:\n\u00a0 \u00a0 \u00a0 - id: black\n\u00a0 - repo: https://github.com/PyCQA/isort\n\u00a0 \u00a0 rev: 5.10.1\n\u00a0 \u00a0 hooks:\n\u00a0 \u00a0 \u00a0 - id: isort\n\u00a0 \u00a0 \u00a0 \u00a0 args: [&quot;--profile&quot;, &quot;black&quot;]\n</code></pre>\n<ul>\n<li><p>Configure <a href=\"https://python-poetry.org/\" rel=\"noreferrer\">Poetry</a> to use the <a href=\"https://test.pypi.org/\" rel=\"noreferrer\">Test PyPI</a> to make sure you can publish a package and it is downloadable &amp; installable.</p>\n<ul>\n<li>Tell <a href=\"https://python-poetry.org/\" rel=\"noreferrer\">Poetry</a> about Test PyPI with <code>poetry config repositories.testpypi https://test.pypi.org/legacy/</code></li>\n<li>Log in to Test PyPI, get an API token, and tell Poetry to use it with <code>poetry config http-basic.testpypi __token__ pypi-your-api-token-here</code> (the <code>__token__</code> is a literal and shouldn't be replaced, your token goes after that).</li>\n<li>Build <code>poetry build</code> and upload your package <code>poetry publish -r testpypi</code></li>\n</ul>\n</li>\n<li><p>Manage your CHANGELOG with <a href=\"https://scriv.readthedocs.io/en/latest/\" rel=\"noreferrer\">Scriv</a></p>\n<ul>\n<li>run <code>scriv create</code> before any substantial commit and edit the file that pops up</li>\n<li>run <code>scriv collect</code> before any release to collect all fragments into one changelog</li>\n</ul>\n</li>\n<li><p>Configure Poetry to use <a href=\"https://pypi.org\" rel=\"noreferrer\">PyPI</a></p>\n<ul>\n<li>login to PyPI and get an API token</li>\n<li>tell Poetry about it with <code>poetry config pypi-token.pypi pypi-your-token-here</code></li>\n<li>build &amp; publish your package in one fell swoop with <code>poetry publish --build</code></li>\n</ul>\n</li>\n<li><p>Do a victory lap: try <code>pip install yourpackagename</code> to make sure everything is going great ;)</p>\n</li>\n<li><p>Publish a GH release that matches what you uploaded to PyPI</p>\n</li>\n<li><p>Write tests. There are <em>many</em> options out there. <a href=\"https://docs.pytest.org/en/\" rel=\"noreferrer\">Pytest</a> is simple, versatile, and not too verbose.</p>\n<ul>\n<li>write tests in a directory <code>tests/</code></li>\n<li>start test files with <code>test_...</code></li>\n<li>actual tests are functions with a name starting with <code>test_...</code></li>\n<li>use assertions (<code>assert</code>) to check for things (tests fail when asserting something Falsy); notice sometimes you don't even need to import <code>pytest</code> in your test files; e.g.:</li>\n</ul>\n</li>\n</ul>\n<pre class=\"lang-py prettyprint-override\"><code># In tests/test_basic_example.py\n\ndef this_test_would_definitely_fail():\n\u00a0 \u00a0 assert 5 &gt; 10\n\ndef this_test_would_definitely_pass():\n\u00a0 \u00a0 assert 5 &gt; 0\n</code></pre>\n<ul>\n<li><p>run tests with the command <code>pytest</code></p>\n</li>\n<li><p>Automate testing, linting, and formatting, with <a href=\"https://tox.wiki/en/latest/\" rel=\"noreferrer\">tox</a>.</p>\n<ul>\n<li>tox creates virtual environments for separate Python versions and can run essentially what you tell it to. Configuration goes in <code>tox.ini</code>. You can also embed it in the file <code>pyproject.toml</code>, but as of writing this, that's only supported if you add a string that actually represents the <code>.ini</code> configuration, which is ugly. Example <code>tox.ini</code>:</li>\n</ul>\n</li>\n</ul>\n<pre class=\"lang-ini prettyprint-override\"><code>[tox]\nisolated_build = True\nenvlist = py38,py39,py310\n\n[testenv]\ndeps =\n\u00a0 \u00a0 black\n\u00a0 \u00a0 pytest\ncommands =\n\u00a0 \u00a0 black --check extendedjson\n\u00a0 \u00a0 pytest .\n</code></pre>\n<p>The environments <code>py38</code> to <code>py310</code> are automatically understood by <a href=\"https://tox.wiki/en/latest/\" rel=\"noreferrer\">tox</a> to represent different Python versions (you guess which ones). The header <code>[testenv]</code> defines configurations for all those environments that <a href=\"https://tox.wiki/en/latest/\" rel=\"noreferrer\">tox</a> knows about. We install the dependencies listed in <code>deps = ...</code> and then run the commands listed in <code>commands = ...</code>.</p>\n<ul>\n<li><p>run tox with <code>tox</code> for all environments or <code>tox -e py39</code> to pick a specific environment</p>\n</li>\n<li><p>Add code coverage with <a href=\"https://coverage.readthedocs.io/en/6.4.2/\" rel=\"noreferrer\">coverage.py</a></p>\n<ul>\n<li>run tests and check coverage with <code>coverage run --source=yourpackage --branch -m pytest .</code></li>\n<li>create a nice HTML report with <code>coverage html</code></li>\n<li>add this to tox</li>\n</ul>\n</li>\n<li><p>Create a GitHub action that runs linting and testing on commits and pull requests</p>\n<ul>\n<li>GH Actions are just YAML files in <code>.github/workflows</code></li>\n<li>this example GH action runs tox on multiple Python versions</li>\n</ul>\n</li>\n</ul>\n<pre class=\"lang-yaml prettyprint-override\"><code># .github/workflows/build.yaml\nname: Your amazing CI name\n\n# Run automatically on...\non:\n\u00a0 push: \u00a0# pushes...\n\u00a0 \u00a0 branches: [ main ] \u00a0# to the main branch... and\n\u00a0 pull_request: \u00a0# on pull requests...\n\u00a0 \u00a0 branches: [ main ] \u00a0# against the main branch.\n\n# What jobs does this workflow run?\njobs:\n\u00a0 build: \u00a0# There's a job called \u201cbuild\u201d which\n\u00a0 \u00a0 runs-on: ubuntu-latest \u00a0# runs on an Ubuntu machine\n\u00a0 \u00a0 strategy:\n\u00a0 \u00a0 \u00a0 matrix: \u00a0# that goes through\n\u00a0 \u00a0 \u00a0 \u00a0 python-version: [&quot;3.8&quot;, &quot;3.9&quot;, &quot;3.10&quot;] \u00a0# these Python versions.\n\n\u00a0 \u00a0 steps: \u00a0# The job \u201cbuild\u201d has multiple steps:\n\u00a0 \u00a0 \u00a0 - name: Checkout sources\n\u00a0 \u00a0 \u00a0 \u00a0 uses: actions/checkout@v2 \u00a0# Checkout the repository into the runner,\n\n\u00a0 \u00a0 \u00a0 - name: Setup Python\n\u00a0 \u00a0 \u00a0 \u00a0 uses: actions/setup-python@v2 \u00a0# then set up Python,\n\u00a0 \u00a0 \u00a0 \u00a0 with:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python-version: ${{ matrix.python-version }} \u00a0# with the version that is currently \u201cselected\u201d...\n\n\u00a0 \u00a0 \u00a0 - name: Install dependencies\n\u00a0 \u00a0 \u00a0 \u00a0 run: | \u00a0# Then run these commands\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python -m pip install --upgrade pip\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python -m pip install tox tox-gh-actions \u00a0# install two dependencies...\n\n\u00a0 \u00a0 \u00a0 - name: Run tox\n\u00a0 \u00a0 \u00a0 \u00a0 run: tox \u00a0# and finally run tox.\n</code></pre>\n<p>Notice that, above, we installed tox <strong>and</strong> a plugin called <code>tox-gh-actions</code>.\nThis plugin will make tox aware of the Python version that is set up in the GH action runner, which will allow us to specify which environments tox will run in that case.\nWe just need to set a correspondence in the file <code>tox.ini</code>:</p>\n<pre class=\"lang-ini prettyprint-override\"><code># tox.ini\n# ...\n[gh-actions]\npython =\n\u00a0 \u00a0 3.8: py38\n\u00a0 \u00a0 3.9: py39\n\u00a0 \u00a0 3.10: py310\n</code></pre>\n<ul>\n<li>Integrate with <a href=\"https://about.codecov.io/\" rel=\"noreferrer\">Codecov</a> for nice coverage reports in the pull requests.\n<ul>\n<li>log in to Codecov with GitHub and give permissions</li>\n<li>add Codecov's action to the YAML from before <strong>after</strong> tox runs (it's tox that generates the local coverage report data) and add/change a coverage command to generate an <code>xml</code> report (it's a format that Codecov understands)</li>\n</ul>\n</li>\n</ul>\n<pre class=\"lang-yaml prettyprint-override\"><code># ...\n\u00a0 \u00a0 \u00a0 - name: Upload coverage to Codecov\n\u00a0 \u00a0 \u00a0 \u00a0 uses: codecov/codecov-action@v2\n\u00a0 \u00a0 \u00a0 \u00a0 with:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fail_ci_if_error: true\n</code></pre>\n<ul>\n<li>Add a GH Action to publish to PyPI automatically\n<ul>\n<li>just set up a YAML file that does your manual steps of building and publishing with Poetry <strong>when</strong> a new release is made</li>\n<li>create a PyPI token to be used by GitHub</li>\n<li>add it as a secret in your repository</li>\n<li>configure Poetry in the action to use that secret</li>\n</ul>\n</li>\n</ul>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: Publish to PyPI\n\non:\n\u00a0 release:\n\u00a0 \u00a0 types: [ published ]\n\u00a0 \u00a0 branches: [ main ]\n\u00a0 workflow_dispatch:\n\njobs:\n\u00a0 build-and-publish:\n\u00a0 \u00a0 runs-on: ubuntu-latest\n\n\u00a0 \u00a0 steps:\n\u00a0 \u00a0 \u00a0 # Checkout and set up Python\n\n\u00a0 \u00a0 \u00a0 - name: Install poetry and dependencies\n\u00a0 \u00a0 \u00a0 \u00a0 run: |\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python -m pip install --upgrade pip\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python -m pip install poetry\n\n\u00a0 \u00a0 \u00a0 - name: Configure poetry\n\u00a0 \u00a0 \u00a0 \u00a0 env:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 pypi_token: ${{ secrets.PyPI_TOKEN }} \u00a0# You set this manually as a secret in your repository\n\u00a0 \u00a0 \u00a0 \u00a0 run: poetry config pypi-token.pypi $pypi_token\n\n\u00a0 \u00a0 \u00a0 - name: Build and publish\n\u00a0 \u00a0 \u00a0 \u00a0 run: poetry publish --build\n</code></pre>\n<ul>\n<li><p>Add cool badges to your README file like\n<a href=\"https://pypi.org/project/extendedjson/\" rel=\"noreferrer\"><img src=\"https://img.shields.io/pypi/v/extendedjson\" alt=\"PyPI version\" /></a>\n<a href=\"https://github.com/mathspp/extendedjson/actions/workflows/build.yaml\" rel=\"noreferrer\"><img src=\"https://github.com/mathspp/extendedjson/actions/workflows/build.yaml/badge.svg\" alt=\"Build status\" /></a>\n<a href=\"https://codecov.io/gh/mathspp/extendedjson/\" rel=\"noreferrer\"><img src=\"https://codecov.io/gh/mathspp/extendedjson/branch/main/graph/badge.svg\" alt=\"Code coverage\" /></a>\n<a href=\"https://github.com/mathspp/extendedjson\" rel=\"noreferrer\"><img src=\"https://img.shields.io/github/stars/mathspp/extendedjson\" alt=\"GitHub stars\" /></a>\n<a href=\"https://pypi.org/project/extendedjson/\" rel=\"noreferrer\"><img src=\"https://img.shields.io/pypi/pyversions/extendedjson\" alt=\"Support Python versions\" /></a></p>\n</li>\n<li><p>Tidy up a bit</p>\n<ul>\n<li>run linting through tox on pre-commit to deduplicate effort and run your preferred versions of the linters/formatters/...</li>\n<li>separate linting/formatting from testing in tox as a separate environment</li>\n<li>check coverage only once as a separate tox environment</li>\n</ul>\n</li>\n</ul>\n"}
{"Id": 74743233, "PostTypeId": 1, "Title": "What happens \"behind the scenes\" if I call `None == x` in Python?", "Body": "<p>I am learning and playing around with Python and I came up with the following test code (please be aware that <em>I would not write productive code like that</em>, but when learning new languages I like to play around with the language's corner cases):</p>\n<pre><code>a = None    \nprint(None == a) # I expected True, I got True\n\nb = 1\nprint(None == b) # I expected False, I got False\n\nclass MyNone:\n    # Called if I compare some myMyNone == somethingElse\n    def __eq__(self, __o: object) -&gt; bool:\n        return True\n\nc = MyNone()\nprint (None == c) # !!! I expected False, I got True !!!\n</code></pre>\n<p><strong>Please see the very last line of the code example.</strong></p>\n<p>How can it be that <code>None == something</code>, where something is clearly not <code>None</code>, return <code>True</code>? I would have expected that result for <code>something == None</code>, but not for <code>None == something</code>.</p>\n<p>I expected that it would call <code>None is something</code> behind the scenes.</p>\n<p>So I think the question boils down to: <strong>How does the <code>__eq__</code> method of the <code>None</code> singleton object look like and how could I have found that out?</strong></p>\n<hr />\n<p>PS: I am aware of <a href=\"https://peps.python.org/pep-0008/\" rel=\"nofollow noreferrer\">PEP-0008</a> and its quote</p>\n<blockquote>\n<p>Comparisons to singletons like None should always be done with is or is not, never the equality operators.</p>\n</blockquote>\n<p>but I <em>still</em> would like to know why <code>print (None == c)</code> in the above example returns <code>True</code>.</p>\n", "AcceptedAnswerId": 74743523, "AcceptedAnswer": "<p>In fact, <code>None</code>'s type does not have its own <code>__eq__</code> method; within Python we can see that it apparently inherits from the base class <code>object</code>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; type(None).__eq__\n&lt;slot wrapper '__eq__' of 'object' objects&gt;\n</code></pre>\n<p>But this is not really what's going on in the source code. The implementation of <code>None</code> can be found in <a href=\"https://github.com/python/cpython/blob/74d5f61ebd1cb14907bf7dae1ad9c1e676707bc5/Objects/object.c#L1681\" rel=\"noreferrer\"><code>Objects/object.c</code></a> in the CPython source, where we see:</p>\n<pre class=\"lang-c prettyprint-override\"><code>PyTypeObject _PyNone_Type = {\n    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)\n    &quot;NoneType&quot;,\n    0,\n    0,\n    none_dealloc,       /*tp_dealloc*/ /*never called*/\n    0,                  /*tp_vectorcall_offset*/\n    0,                  /*tp_getattr*/\n    0,                  /*tp_setattr*/\n    // ...\n    0,                  /*tp_richcompare */\n    // ...\n    0,                  /*tp_init */\n    0,                  /*tp_alloc */\n    none_new,           /*tp_new */\n};\n</code></pre>\n<p>I omitted most of the irrelevant parts. The important thing here is that <code>_PyNone_Type</code>'s <code>tp_richcompare</code> is <code>0</code>, i.e. a null pointer. This is checked for in the <a href=\"https://github.com/python/cpython/blob/74d5f61ebd1cb14907bf7dae1ad9c1e676707bc5/Objects/object.c#L643\" rel=\"noreferrer\"><code>do_richcompare</code></a> function:</p>\n<pre class=\"lang-c prettyprint-override\"><code>    if ((f = Py_TYPE(v)-&gt;tp_richcompare) != NULL) {\n        res = (*f)(v, w, op);\n        if (res != Py_NotImplemented)\n            return res;\n        Py_DECREF(res);\n    }\n    if (!checked_reverse_op &amp;&amp; (f = Py_TYPE(w)-&gt;tp_richcompare) != NULL) {\n        res = (*f)(w, v, _Py_SwappedOp[op]);\n        if (res != Py_NotImplemented)\n            return res;\n        Py_DECREF(res);\n    }\n</code></pre>\n<p>Translating for those who don't speak C:</p>\n<ul>\n<li>If the left-hand-side's <code>tp_richcompare</code> function is not null, call it, and if its result is not <code>NotImplemented</code> then return that result.</li>\n<li>Otherwise if the reverse hasn't already been checked*, and the right-hand-side's <code>tp_richcompare</code> function is not null, call it, and if the result is not <code>NotImplemented</code> then return that result.</li>\n</ul>\n<p>There are some other branches in the code, to fall back to in case none of those branches returns a result. But these two branches are enough to see what's going on. It's not that <code>type(None).__eq__</code> returns <code>NotImplemented</code>, rather the type doesn't have the corresponding function in the C source code at all. That means the second branch is taken, hence the result you observe.</p>\n<p><sub>*The flag <code>checked_reverse_op</code> is set if the reverse direction has already been checked; this happens if the right-hand-side is a strict subtype of the left-hand-side, in which case it takes priority. That doesn't apply in this case since there is no subtype relation between <code>type(None)</code> and your class.</sub></p>\n"}
{"Id": 73326570, "PostTypeId": 1, "Title": "Why is the float * int multiplication faster than int * float in CPython?", "Body": "<p>Basically, the expression <code>0.4 * a</code> is consistently, and surprisingly, significantly faster than <code>a * 0.4</code>. <code>a</code> being an integer. And I have no idea why.</p>\n<p>I speculated that it is a case of a <code>LOAD_CONST LOAD_FAST</code> bytecode pair being &quot;more specialized&quot; than the <code>LOAD_FAST LOAD_CONST</code> and I would be entirely satisfied with this explanation, except that this quirk seems to apply only to multiplications where types of multiplied variables differ. (By the way, I can no longer find the link to this &quot;bytecode instruction pair popularity ranking&quot; I once found on github, does anyone have a link?)</p>\n<p>Anyway, here are the micro benchmarks:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ python3.10 -m pyperf timeit -s&quot;a = 9&quot; &quot;a * 0.4&quot;\nMean +- std dev: 34.2 ns +- 0.2 ns\n</code></pre>\n<pre class=\"lang-bash prettyprint-override\"><code>$ python3.10 -m pyperf timeit -s&quot;a = 9&quot; &quot;0.4 * a&quot;\nMean +- std dev: 30.8 ns +- 0.1 ns\n</code></pre>\n<pre class=\"lang-bash prettyprint-override\"><code>$ python3.10 -m pyperf timeit -s&quot;a = 0.4&quot; &quot;a * 9&quot;\nMean +- std dev: 30.3 ns +- 0.3 ns\n</code></pre>\n<pre class=\"lang-bash prettyprint-override\"><code>$ python3.10 -m pyperf timeit -s&quot;a = 0.4&quot; &quot;9 * a&quot;\nMean +- std dev: 33.6 ns +- 0.3 ns\n</code></pre>\n<p>As you can see - in the runs where the float comes first (2nd and 3rd) - it is faster.<br>\nSo my question is where does this behavior come from? I'm 90% sure that it is an implementation detail of CPython, but I'm not that familiar with low level instructions to state that for sure.</p>\n", "AcceptedAnswerId": 73326827, "AcceptedAnswer": "<p>It's CPython's implementation of the <code>BINARY_MULTIPLY</code> opcode. It has no idea what the types are at compile-time, so everything has to be figured out at run-time. Regardless of what <code>a</code> and <code>b</code> may be, <code>BINARY_MULTIPLY</code> ends up inoking <code>a.__mul__(b)</code>.</p>\n<p>When <code>a</code> is of int type <code>int.__mul__(a, b)</code> has no idea what to do unless <code>b</code> is also of int type. It returns <code>Py_RETURN_NOTIMPLEMENTED</code> (an internal C constant). This is in <code>longobject.c</code>'s <code>CHECK_BINOP</code> macro. The interpreter sess that, and effectively says &quot;OK, <code>a.__mul__</code> has no idea what to do, so let's give <code>b.__rmul__</code> a shot at it&quot;. None of that is free - it all takes time.</p>\n<p><code>float.__mul__(b, a)</code> (same as <code>float.__rmul__</code>) does know what to do with an int (converts it to float first), so that succeeds.</p>\n<p>But when <code>a</code> is of float type to begin with, we go to <code>float.__mul__</code> first, and that's the end of it. No time burned figuring out that the int type doesn't know what to do.</p>\n<p>The actual code is quite a bit more involved than the above pretends, but that's the gist of it.</p>\n"}
{"Id": 73406581, "PostTypeId": 1, "Title": "python manage.py collectstatic error: cannot find rest_framework bootstrap.min.css.map (from book 'Django for APIs')", "Body": "<p>I am reading the book 'Django for APIs' from 'William S. Vincent' (current edition for Django 4.0)</p>\n<p>In chapter 4, I cannot run successfully the command python manage.py collectstatic.</p>\n<p>I get the following error:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/manage.py&quot;, line 22, in &lt;module&gt;\n    main()\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/manage.py&quot;, line 18, in main\n    execute_from_command_line(sys.argv)\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/core/management/__init__.py&quot;, line 446, in execute_from_command_line\n    utility.execute()\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/core/management/__init__.py&quot;, line 440, in execute\n    self.fetch_command(subcommand).run_from_argv(self.argv)\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/core/management/base.py&quot;, line 402, in run_from_argv\n    self.execute(*args, **cmd_options)\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/core/management/base.py&quot;, line 448, in execute\n    output = self.handle(*args, **options)\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/contrib/staticfiles/management/commands/collectstatic.py&quot;, line 209, in handle\n    collected = self.collect()\n  File &quot;/Users/my_name/Projects/django/django_for_apis/library/.venv/lib/python3.10/site-packages/django/contrib/staticfiles/management/commands/collectstatic.py&quot;, line 154, in collect\n    raise processed\nwhitenoise.storage.MissingFileError: The file 'rest_framework/css/bootstrap.min.css.map' could not be found with &lt;whitenoise.storage.CompressedManifestStaticFilesStorage object at 0x102fa07f0&gt;.\n\nThe CSS file 'rest_framework/css/bootstrap.min.css' references a file which could not be found:\n  rest_framework/css/bootstrap.min.css.map\n\nPlease check the URL references in this CSS file, particularly any\nrelative paths which might be pointing to the wrong location. \n</code></pre>\n<p>I have the exact same settings like in the book in settings.py:</p>\n<pre><code>STATIC_URL = &quot;static/&quot;\nSTATICFILES_DIRS = [BASE_DIR / &quot;static&quot;]  # new\nSTATIC_ROOT = BASE_DIR / &quot;staticfiles&quot;  # new\nSTATICFILES_STORAGE = &quot;whitenoise.storage.CompressedManifestStaticFilesStorage&quot;  # new\n</code></pre>\n<p>I couldn't find any explanation for it. maybe someone can point me in the right direction.</p>\n", "AcceptedAnswerId": 73411956, "AcceptedAnswer": "<p><strong>Update</strong>: <a href=\"https://www.django-rest-framework.org/community/release-notes/#3140\" rel=\"noreferrer\">DRF 3.14.0 now supports Django 4.1</a>. If you've added stubs to static as per below, be sure to remove them.</p>\n<p>This appears to be related to Django 4.1: either downgrade to Django 4.0 or <a href=\"https://github.com/encode/django-rest-framework/pull/8591#issuecomment-1220200518\" rel=\"noreferrer\">simply create the following empty files in one of your static directories</a>:</p>\n<pre><code>static/rest_framework/css/bootstrap-theme.min.css.map\nstatic/rest_framework/css/bootstrap.min.css.map\n</code></pre>\n<p><a href=\"https://docs.djangoproject.com/en/4.1/releases/4.1/#django-contrib-staticfiles\" rel=\"noreferrer\">There's a recent change to <code>ManifestStaticFilesStorage</code></a> where it now attempts to replace source maps with their hashed counterparts.</p>\n<p>Django REST framework has only recently added the bootstrap css source maps but is not yet released.</p>\n"}
{"Id": 72620996, "PostTypeId": 1, "Title": "Apple M1 - Symbol not found: _CFRelease while running Python app", "Body": "<p>I am hoping to run my app without any problem, but I got this attached error. Could someone help or point me into the right direction as to why this is happening?</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/Users/andre.sitorus/Documents/GitHub/nexus/automation-api/app/main.py&quot;, line 4, in &lt;module&gt;\n    from configurations import config  # noqa # pylint: disable=unused-import\n  File &quot;/Users/andre.sitorus/Documents/GitHub/nexus/automation-api/app/configurations/config.py&quot;, line 7, in &lt;module&gt;\n    from google.cloud import secretmanager\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/google/cloud/secretmanager.py&quot;, line 20, in &lt;module&gt;\n    from google.cloud.secretmanager_v1 import SecretManagerServiceClient\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/google/cloud/secretmanager_v1/__init__.py&quot;, line 24, in &lt;module&gt;\n    from google.cloud.secretmanager_v1.gapic import secret_manager_service_client\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/google/cloud/secretmanager_v1/gapic/secret_manager_service_client.py&quot;, line 25, in &lt;module&gt;\n    import google.api_core.gapic_v1.client_info\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/google/api_core/gapic_v1/__init__.py&quot;, line 18, in &lt;module&gt;\n    from google.api_core.gapic_v1 import config\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/google/api_core/gapic_v1/config.py&quot;, line 23, in &lt;module&gt;\n    import grpc\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/grpc/__init__.py&quot;, line 22, in &lt;module&gt;\n    from grpc import _compression\n  File &quot;/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/grpc/_compression.py&quot;, line 15, in &lt;module&gt;\n    from grpc._cython import cygrpc\nImportError: dlopen(/Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so, 2): Symbol not found: _CFRelease\n  Referenced from: /Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so\n  Expected in: flat namespace\n in /Users/andre.sitorus/opt/miniconda3/envs/nexus/lib/python3.9/site-packages/grpc/_cython/cygrpc.cpython-39-darwin.so\n</code></pre>\n<p>I'm running  this in Apple M1.</p>\n<p>I already upgraded pip and setuptools before installing all the requirements in my virtual environment using <code>conda</code>. Here is my <code>python</code>, <code>pip</code>, and <code>setuptools</code> version:</p>\n<pre><code>python 3.9.12\npip 21.2.4\nsetuptools 62.4.0\n</code></pre>\n", "AcceptedAnswerId": 73245207, "AcceptedAnswer": "<p>Had the same issue; turned out it's because of the grpcio build. Doing this helped:</p>\n<pre><code>pip uninstall grpcio\nconda install grpcio\n</code></pre>\n<p>(Make sure you use the conda-forge channel with conda; the community puts in work to make sure packages play well with M1/arm64)</p>\n"}
{"Id": 73464414, "PostTypeId": 1, "Title": "Why are generics in Python implemented using __class_getitem__ instead of __getitem__ on metaclass", "Body": "<p>I was reading python documentation and peps and couldn't find an answer for this.</p>\n<p>Generics in python are implemented by subscripting class objects. <code>list[str]</code> is a list where all elements are strings.<br />\nThis behaviour is achieved by implementing a special (dunder) classmethod called <code>__class_getitem__</code> which as the <a href=\"https://docs.python.org/3/reference/datamodel.html?highlight=__class_getitem__#class-getitem-versus-getitem\" rel=\"nofollow noreferrer\">documentation</a> states should return a GenericAlias.</p>\n<p>An example:</p>\n<pre><code>class MyGeneric:\n    def __class_getitem__(cls, key):\n        # implement generics\n        ...\n</code></pre>\n<p>This seems weird to me because the documentation also shows some code similar to what the interpreter does when faced with subscripting objects and shows that defining both <code>__getitem__</code> on object's metaclass and <code>__class_getitem__</code> on the object itself always chooses the metaclass' <code>__getitem__</code>. This means that a class with the same functionality as the one above can be implemented without introducing a new special method into the language.</p>\n<p>An example of a class with identical behaviour:</p>\n<pre><code>class GenericMeta(type):\n    def __getitem__(self, key):\n        # implement generics\n        ...\n\n\nclass MyGeneric(metaclass=GenericMeta):\n    ...\n</code></pre>\n<p>Later the documentation also shows an example of <code>Enum</code>s using a <code>__getitem__</code> of a metaclass as an example of a <code>__class_getitem__</code> not being called.</p>\n<p>My question is why was the <code>__class_getitem__</code> classmethod introduced in the first place?</p>\n<p>It seems to do the exact same thing as the metaclass' <code>__getitem__</code> but with the added complexity and the need for extra code in the interpreter for deciding which method to call. All of this comes with no extra benefit as defining both will simply call the same one every time unless specifically calling dunder methods (which should not be done in general).</p>\n<p>I know that implementing generics this way is discouraged. The general approach is to subclass a class that already defines a <code>__class_getitem__</code> like <code>typing.Generic</code> but I'm still curious as to why that functionality was implemented that way.</p>\n", "AcceptedAnswerId": 73464466, "AcceptedAnswer": "<p><code>__class_getitem__</code> exists because using multiple inheritance where multiple metaclasses are involved is very tricky and sets limitations that can\u2019t always be met when using 3rd-party libraries.</p>\n<p>Without <code>__class_getitem__</code> generics requires a metaclass, as defining a  <code>__getitem__</code> method on a class would only handle attribute access <strong>on instances</strong>, not on the class. Normally, <code>object[...]</code> syntax is handled by the <em>type</em> of <code>object</code>, not by <code>object</code> itself. For instances, that's the class, but for <em>classes</em>, that's the metaclass.</p>\n<p>So, the syntax:</p>\n<pre><code>ClassObject[some_type]\n</code></pre>\n<p>would translate to:</p>\n<pre><code>type(ClassObject).__getitem__(ClassObject, some_type)\n</code></pre>\n<p><code>__class_getitem__</code> exists to avoid having to give every class that needs to support generics, a metaclass.</p>\n<p>For how <code>__getitem__</code> and other special methods work, see the <a href=\"https://docs.python.org/3/reference/datamodel.html#special-method-lookup\" rel=\"noreferrer\"><em>Special method lookup</em> section</a> in the Python Datamodel chapter:</p>\n<blockquote>\n<p>For custom classes, implicit invocations of special methods are only guaranteed to work correctly if defined on an object\u2019s type, not in the object\u2019s instance dictionary.</p>\n</blockquote>\n<p>The same chapter also explicitly covers <a href=\"https://docs.python.org/3/reference/datamodel.html#the-purpose-of-class-getitem\" rel=\"noreferrer\"><code>__class_getitem__</code> versus <code>__getitem__</code></a>:</p>\n<blockquote>\n<p>Usually, the subscription of an object using square brackets will call the <code>__getitem__()</code> instance method defined on the object\u2019s class. However, if the object being subscribed is itself a class, the class method <code>__class_getitem__()</code> may be called instead.</p>\n</blockquote>\n<p>This section also covers what will happen if the class has both a metaclass with a <code>__getitem__</code> method, <em>and</em> a <code>__class_getitem__</code> method defined on the class itself. You found this section, but it <strong>only applies in this specific corner-case</strong>.</p>\n<p>As stated, using metaclasses can be tricky, especially when inheriting from classes with different metaclasses. See the original <a href=\"https://peps.python.org/pep-0560/\" rel=\"noreferrer\">PEP 560 - <em>Core support for typing module and generic types</em> proposal</a>:</p>\n<blockquote>\n<p>All generic types are instances of <code>GenericMeta</code>, so if a user uses a custom metaclass, then it is hard to make a corresponding class generic. This is particularly hard for library classes that a user doesn\u2019t control.</p>\n<p>...</p>\n<p>With the help of the proposed special attributes the <code>GenericMeta</code> metaclass will not be needed.</p>\n</blockquote>\n<p>When mixing multiple classes with different metaclasses, Python requires that the most specific metaclass derives from the other metaclasses, a requirement that can't easily be met if the metaclass is not your own; see the <a href=\"https://docs.python.org/3/reference/datamodel.html#determining-the-appropriate-metaclass\" rel=\"noreferrer\">documentation on determining the appropriate metaclass</a>.</p>\n<p>As a side note, if you do use a metaclass, then <code>__getitem__</code> should <strong>not</strong> be a classmethod:</p>\n<pre><code>class GenericMeta(type):\n    # not a classmethod! `self` here is a class, an instance of this\n    # metaclass.\n    def __getitem__(self, key):\n        # implement generics\n        ...\n</code></pre>\n<p>Before PEP 560, that's <a href=\"https://github.com/python/cpython/blob/8d999cbf4adea053be6dbb612b9844635c4dfb8e/Lib/typing.py#L1099-L1143\" rel=\"noreferrer\">basically what the <code>typing.GenericMeta</code> metaclass did</a>, albeit with a bit more complexity.</p>\n"}
{"Id": 74930922, "PostTypeId": 1, "Title": "How to load a custom Julia package in Python using Python's juliacall", "Body": "<p>I already know <a href=\"https://stackoverflow.com/questions/73070845/how-to-import-julia-packages-into-python\">How to import Julia packages into Python</a>.</p>\n<p>However, now I have created my own simple Julia package with the following command:\n<code>using Pkg;Pkg.generate(&quot;MyPack&quot;);Pkg.activate(&quot;MyPack&quot;);Pkg.add(&quot;StatsBase&quot;)</code>\nwhere the file <code>MyPack/src/MyPack.jl</code> has the following contents:</p>\n<pre><code>module MyPack\nusing StatsBase\n\nfunction f1(x, y)\n   return 3x + y\nend\ng(x) = StatsBase.std(x)\n\nexport f1\n\nend\n</code></pre>\n<p>Now I would like to load this Julia package in Python via <code>juliacall</code> and call <code>f1</code> and <code>g</code> functions.\nI have already run <code>pip3 install juliacall</code> from command line. How do I call the above functions from Python?</p>\n", "AcceptedAnswerId": 74930923, "AcceptedAnswer": "<p>You need to run the following code to load the <code>MyPack</code> package from Python via <code>juliacall</code></p>\n<pre><code>from juliacall import Main as jl\nfrom juliacall import Pkg as jlPkg\n\njlPkg.activate(&quot;MyPack&quot;)  # relative path to the folder where `MyPack/Project.toml` should be used here \n\njl.seval(&quot;using MyPack&quot;)\n</code></pre>\n<p>Now you can use the function (note that calls to non exported functions require package name):</p>\n<pre><code>&gt;&gt;&gt; jl.f1(4,7)\n19\n\n&gt;&gt;&gt; jl.f1([4,5,6],[7,8,9]).to_numpy()\narray([19, 23, 27], dtype=object)\n\n&gt;&gt;&gt; jl.MyPack.g(numpy.arange(0,3))\n1.0\n</code></pre>\n<p>Note another option for calling Julia from Python that seems to be more difficult to configure as of today is the <code>pip install julia</code> package which is described here: <a href=\"https://stackoverflow.com/questions/64241264/i-have-a-high-performant-function-written-in-julia-how-can-i-use-it-from-python\">I have a high-performant function written in Julia, how can I use it from Python?</a></p>\n"}
{"Id": 73599734, "PostTypeId": 1, "Title": "Python dataclass, one attribute referencing other", "Body": "<pre class=\"lang-py prettyprint-override\"><code>@dataclass\nclass Stock:\n    symbol: str\n    price: float = get_price(symbol)\n</code></pre>\n<p>Can a <code>dataclass</code> attribute access to the other one? In the above example, one can create a <code>Stock</code> by providing a symbol and the price. If price is not provided, it <strong>defaults</strong> to a price which we get from some function <code>get_price</code>. Is there a way to reference symbol?</p>\n<p>This example generates error <code>NameError: name 'symbol' is not defined</code>.</p>\n", "AcceptedAnswerId": 73599883, "AcceptedAnswer": "<p>You can use <a href=\"https://peps.python.org/pep-0557/#post-init-processing\" rel=\"noreferrer\"><code>__post_init__</code></a> here. Because it's going to be called after <code>__init__</code>, you have your attributes already populated so do whatever you want to do there:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from typing import Optional\nfrom dataclasses import dataclass\n\n\ndef get_price(name):\n    # logic to get price by looking at `name`.\n    return 1000.0\n\n\n@dataclass\nclass Stock:\n    symbol: str\n    price: Optional[float] = None\n\n    def __post_init__(self):\n        if self.price is None:\n            self.price = get_price(self.symbol)\n\n\nobj1 = Stock(&quot;boo&quot;, 2000.0)\nobj2 = Stock(&quot;boo&quot;)\nprint(obj1.price)  # 2000.0\nprint(obj2.price)  # 1000.0\n</code></pre>\n<p>So if user didn't pass <code>price</code> while instantiating, <code>price</code> is None. So you can check it in <code>__post_init__</code> and ask it from <code>get_price</code>.</p>\n"}
{"Id": 73599970, "PostTypeId": 1, "Title": "How to solve \"wkhtmltopdf reported an error: Exit with code 1 due to network error: ProtocolUnknownError\" in python pdfkit", "Body": "<p>I'm using Django. This is code is in views.py.</p>\n<pre><code>def download_as_pdf_view(request, doc_type, pk):\n    import pdfkit\n    file_name = 'invoice.pdf'\n    pdf_path = os.path.join(settings.BASE_DIR, 'static', 'pdf', file_name)\n\n    template = get_template(&quot;paypal/card_invoice_detail.html&quot;)\n    _html = template.render({})\n    pdfkit.from_string(_html, pdf_path)\n\n    return FileResponse(open(pdf_path, 'rb'), filename=file_name, content_type='application/pdf')\n</code></pre>\n<p>Traceback is below.</p>\n<pre><code>\n[2022-09-05 00:56:35,785] ERROR [django.request.log_response:224] Internal Server Error: /paypal/download_pdf/card_invoice/MTE0Nm1vamlva29zaGkz/\nTraceback (most recent call last):\n  File &quot;/usr/local/lib/python3.8/site-packages/django/core/handlers/exception.py&quot;, line 47, in inner\n    response = get_response(request)\n  File &quot;/usr/local/lib/python3.8/site-packages/django/core/handlers/base.py&quot;, line 181, in _get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File &quot;/opt/project/app/paypal/views.py&quot;, line 473, in download_as_pdf_view\n    pdfkit.from_string(str(_html), pdf_path)\n  File &quot;/usr/local/lib/python3.8/site-packages/pdfkit/api.py&quot;, line 75, in from_string\n    return r.to_pdf(output_path)\n  File &quot;/usr/local/lib/python3.8/site-packages/pdfkit/pdfkit.py&quot;, line 201, in to_pdf\n    self.handle_error(exit_code, stderr)\n  File &quot;/usr/local/lib/python3.8/site-packages/pdfkit/pdfkit.py&quot;, line 155, in handle_error\n    raise IOError('wkhtmltopdf reported an error:\\n' + stderr)\nOSError: wkhtmltopdf reported an error:\nExit with code 1 due to network error: ProtocolUnknownError\n\n[2022-09-05 00:56:35,797] ERROR [django.server.log_message:161] &quot;GET /paypal/download_pdf/card_invoice/MTE0Nm1vamlva29zaGkz/ HTTP/1.1&quot; 500 107486\n\n</code></pre>\n<p>This is work file.</p>\n<pre><code>pdfkit.from_url('https://google.com', 'google.pdf')\n</code></pre>\n<p>However <code>pdfkit.from_string</code> and <code>pdfkit.from_file</code> return &quot;ProtocolUnknownError&quot;</p>\n<p>Please help me!</p>\n<h2>Update</h2>\n<p>I tyied this code.</p>\n<pre><code>    _html = '''&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello world&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;'''\n    pdfkit.from_string(_html), pdf_path)\n</code></pre>\n<p>It worked fine. I saved above html as sample.html. Then run this code</p>\n<ul>\n<li>I added this parameter <code>options={&quot;enable-local-file-access&quot;: &quot;&quot;}</code></li>\n</ul>\n<pre><code>    _html = render_to_string('path/to/sample.html')\n    pdfkit.from_string(str(_html), pdf_path, options={&quot;enable-local-file-access&quot;: &quot;&quot;})\n</code></pre>\n<p>It worked fine! And the &quot;ProtocolUnknownError&quot; error is gone thanks to <code>options={&quot;enable-local-file-access&quot;: &quot;&quot;}</code>.</p>\n<p>So, I changed the HTML file path to the one I really want to use.</p>\n<pre><code>    _html = render_to_string('path/to/invoice.html')\n    pdfkit.from_string(_html, pdf_path, options={&quot;enable-local-file-access&quot;: &quot;&quot;})\n    return FileResponse(open(pdf_path, 'rb'), filename=file_name, content_type='application/pdf')\n</code></pre>\n<p>It does not finish convert pdf. When I run the code line by line.</p>\n<p><code>stdout, stderr = result.communicate(input=input)</code> does not return.</p>\n<p>It was processing long time.</p>\n", "AcceptedAnswerId": 73603802, "AcceptedAnswer": "<p>I solved this problem. Theare are 3 step to pass this problems.</p>\n<ol>\n<li><p>You need to set options <code>{&quot;enable-local-file-access&quot;: &quot;&quot;}</code>. <code>pdfkit.from_string(_html, pdf_path, options={&quot;enable-local-file-access&quot;: &quot;&quot;})</code></p>\n</li>\n<li><p><code>pdfkit.from_string()</code> can't load css from URL. It's something like this.\n<code>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://path/to/style.css&quot;&gt;</code> css path should be absolute path or write <code>style</code> in same file.</p>\n</li>\n<li><p>If css file load another file. ex: font file. It will be <code>ContentNotFoundError</code>.</p>\n</li>\n</ol>\n<h2>My solution</h2>\n<p>I used simple css file like this.</p>\n<pre><code>body {\n    font-size: 18px;\n    padding: 55px;\n}\n\nh1 {\n    font-size: 38px;\n}\n\nh2 {\n    font-size: 28px;\n}\n\nh3 {\n    font-size: 24px;\n}\n\nh4 {\n    font-size: 20px;\n}\n\ntable, th, td {\n    margin: auto;\n    text-align: center;\n    border: 1px solid;\n}\n\ntable {\n    width: 80%;\n}\n\n.text-right {\n    text-align: right;\n}\n\n\n.text-left {\n    text-align: left;\n}\n\n.text-center {\n    text-align: center;\n}\n</code></pre>\n<p>This code insert last css file as style in same html.</p>\n<pre><code>import os\n\nimport pdfkit\nfrom django.http import FileResponse\nfrom django.template.loader import render_to_string\n\nfrom paypal.models import Invoice\nfrom website import settings\n\n\ndef download_as_pdf_view(request, pk):\n    # create PDF from HTML template file with context.\n    invoice = Invoice.objects.get(pk=pk)\n    context = {\n        # please set your contexts as dict.\n    }\n    _html = render_to_string('paypal/card_invoice_detail.html', context)\n     # remove header\n    _html = _html[_html.find('&lt;body&gt;'):]  \n\n    # create new header\n    new_header = '''&lt;!DOCTYPE html&gt;\n    &lt;html lang=&quot;ja&quot;&gt;\n    &lt;head&gt;\n    &lt;meta charset=&quot;utf-8&quot;/&gt;\n    &lt;/head&gt;\n    &lt;style&gt;\n'''\n    # add style from css file. please change to your css file path.\n    css_path = os.path.join(settings.BASE_DIR, 'paypal', 'static', 'paypal', 'css', 'invoice.css')\n    with open(css_path, 'r') as f:\n        new_header += f.read()\n    new_header += '\\n&lt;/style&gt;'\n    print(new_header)\n\n    # add head to html\n    _html = new_header + _html[_html.find('&lt;body&gt;'):]\n    with open('paypal/sample.html', 'w') as f: f.write(_html)  # for debug\n\n    # convert html to pdf\n    file_name = 'invoice.pdf'\n    pdf_path = os.path.join(settings.BASE_DIR, 'static', 'pdf', file_name)\n    pdfkit.from_string(_html, pdf_path, options={&quot;enable-local-file-access&quot;: &quot;&quot;})\n    return FileResponse(open(pdf_path, 'rb'), filename=file_name, content_type='application/pdf')\n</code></pre>\n"}
{"Id": 73660050, "PostTypeId": 1, "Title": "How to achieve \"resumption semantics\" for Python exceptions?", "Body": "<p>I have a validator class with a method that performs multiple checks and may raise different exceptions:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something) -&gt; None:\n        if a:\n            raise ErrorA()\n        if b:\n            raise ErrorB()\n        if c:\n            raise ErrorC()\n</code></pre>\n<p>There's a place in the outside (caller) code where I want to customize its behaviour and prevent <code>ErrorB</code> from being raised, without preventing <code>ErrorC</code>. Something like <a href=\"https://en.m.wikipedia.org/wiki/Exception_handling#Termination_and_resumption_semantics\" rel=\"noreferrer\">resumption semantics</a> would be useful here. Hovewer, I haven't found a good way to achieve this.</p>\n<p>To clarify: I have the control over <code>Validator</code> source code, but prefer to preserve its existing interface as much as possible.</p>\n<p>Some possible solutions that I've considered:</p>\n<ol>\n<li><p>The obvious</p>\n<pre class=\"lang-py prettyprint-override\"><code>try:\n    validator.validate(something)\nexcept ErrorB:\n    ...\n</code></pre>\n<p>is no good because it also suppresses <code>ErrorC</code> in cases where both <code>ErrorB</code> and <code>ErrorC</code> should be raised.</p>\n</li>\n<li><p>Copy-paste the method and remove the check:</p>\n<pre class=\"lang-py prettyprint-override\"><code># In the caller module\n\nclass CustomValidator(Validator):\n    def validate(something) -&gt; None:\n        if a:\n            raise ErrorA()\n        if c:\n            raise ErrorC()\n</code></pre>\n<p>Duplicating the logic for <code>a</code> and <code>c</code> is a bad idea\nand will lead to bugs if <code>Validator</code> changes.</p>\n</li>\n<li><p>Split the method into separate checks:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something) -&gt; None:\n        self.validate_a(something)\n        self.validate_b(something)\n        self.validate_c(something)\n\n    def validate_a(something) -&gt; None:\n        if a:\n            raise ErrorA()\n\n    def validate_b(something) -&gt; None:\n        if b:\n            raise ErrorB()\n\n    def validate_c(something) -&gt; None:\n        if c:\n            raise ErrorC()\n\n# In the caller module\n\nclass CustomValidator(Validator):\n    def validate(something) -&gt; None:\n        super().validate_a(something)\n        super().validate_c(something)\n</code></pre>\n<p>This is just a slightly better copy-paste.\nIf some <code>validate_d()</code> is added later, we have a bug in <code>CustomValidator</code>.</p>\n</li>\n<li><p>Add some suppression logic by hand:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something, *, suppress: list[Type[Exception]] = []) -&gt; None:\n        if a:\n            self._raise(ErrorA(), suppress)\n        if b:\n            self._raise(ErrorB(), suppress)\n        if c:\n            self._raise(ErrorC(), suppress)\n\n    def _raise(self, e: Exception, suppress: list[Type[Exception]]) -&gt; None:\n        with contextlib.suppress(*suppress):\n            raise e\n</code></pre>\n<p>This is what I'm leaning towards at the moment.\nThere's a new optional parameter and the <code>raise</code> syntax becomes kinda ugly,\nbut this is an acceptable cost.</p>\n</li>\n<li><p>Add flags that disable some checks:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something, *, check_a: bool = True,\n                 check_b: bool = True, check_c: bool = True) -&gt; None:\n        if check_a and a:\n            raise ErrorA()\n        if check_b and b:\n            raise ErrorB()       \n        if check_c and c:\n            raise ErrorC()\n</code></pre>\n<p>This is good, because it allows to granually control different checks even\nif they raise the same exception.</p>\n<p>However, it feels verbose and will require additional maintainance\nas <code>Validator</code> changes. I actually have more than three checks there.</p>\n</li>\n<li><p>Yield exceptions by value:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something) -&gt; Iterator[Exception]:\n        if a:\n            yield ErrorA()\n        if b:\n            yield ErrorB()\n        if c:\n            yield ErrorC()\n</code></pre>\n<p>This is bad, because it's a breaking change for existing callers\nand it makes propagating the exception (the typical use) way more verbose:</p>\n<pre class=\"lang-py prettyprint-override\"><code># Instead of\n# validator.validate(something)\n\ne = next(validator.validate(something), None)\nif e is not None:\n    raise e\n</code></pre>\n<p>Even if we keep everything backwards-compatible</p>\n<pre class=\"lang-py prettyprint-override\"><code>class Validator:\n    def validate(something) -&gt; None:\n        e = next(self.iter_errors(something), None)\n        if e is not None:\n            raise e\n\n    def iter_errors(something) -&gt; Iterator[Exception]:\n        if a:\n            yield ErrorA()\n        if b:\n            yield ErrorB()\n        if c:\n            yield ErrorC()\n</code></pre>\n<p>The new suppressing caller still needs to write all this code:</p>\n<pre class=\"lang-py prettyprint-override\"><code>exceptions = validator.iter_errors(something)\ne = next(exceptions, None)\nif isinstance(e, ErrorB):\n    # Skip ErrorB, don't raise it.\n    e = next(exceptions, None)\nif e is not None:\n    raise e\n</code></pre>\n<p>Compared to the previous two options:</p>\n<pre class=\"lang-py prettyprint-override\"><code>validator.validate(something, suppress=[ErrorB])\n</code></pre>\n<pre class=\"lang-py prettyprint-override\"><code>validator.validate(something, check_b=False)\n</code></pre>\n</li>\n</ol>\n", "AcceptedAnswerId": 73662557, "AcceptedAnswer": "<p>With bare exceptions you are looking at the wrong tool for the job. In Python, to <code>raise</code> an exception means that execution hits an <em>exceptional case</em> in which resuming <em>is not possible</em>. Terminating the broken execution is an express purpose of exceptions.</p>\n<blockquote>\n<h3><a href=\"https://docs.python.org/3.10/reference/executionmodel.html#exceptions\" rel=\"nofollow noreferrer\">Execution Model: 4.3. Exceptions</a></h3>\n<p>Python uses the \u201ctermination\u201d model of error handling: an exception handler can find out what happened and continue execution at an outer level, but it cannot repair the cause of the error and retry the failing operation (except by re-entering the offending piece of code from the top).</p>\n</blockquote>\n<p>To get resumption semantics for exception handling, you can look at the generic tools for either <em>resumption</em> or for <em>handling</em>.</p>\n<hr />\n<h3>Resumption: Coroutines</h3>\n<p>Python's resumption model are <em>coroutines</em>: <code>yield</code> coroutine-generators or <code>async</code> coroutines both allow to pause and explicitly resume execution.</p>\n<pre><code>def validate(something) -&gt; Iterator[Exception]:\n    if a:\n        yield ErrorA()\n    if b:\n        yield ErrorB()\n    if c:\n        yield ErrorC()\n</code></pre>\n<p>It is important to distinguish between <code>send</code>-style &quot;proper&quot; coroutines and iterator-style &quot;generator&quot; coroutines. As long as no value must be sent <em>into</em> the coroutine, it is functionally equivalent to an iterator. Python has good inbuilt support for working with iterators:</p>\n<pre class=\"lang-py prettyprint-override\"><code>for e in validator.iter_errors(something):\n    if isinstance(e, ErrorB):\n        continue  # continue even if ErrorB happens\n    raise e\n</code></pre>\n<p>Similarly, one could <code>filter</code> the iterator or use comprehensions. Iterators easily compose and gracefully terminate, making them suitable for iterating exception cases.</p>\n<hr />\n<h4>Effect Handling</h4>\n<p>Exception handling is just the common use case for the more generic <em>effect handling</em>. While Python has no builtin effect handling support, simple handlers that address only the origin or sink of an effect can be modelled just as functions:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def default_handler(failure: BaseException):\n    raise failure\n\ndef validate(something, failure_handler = default_handler) -&gt; None:\n    if a:\n        failure_handler(ErrorA())\n    if b:\n        failure_handler(ErrorB())\n    if c:\n        failure_handler(ErrorC())\n</code></pre>\n<p>This allows the caller to change the effect handling by supplying a different handler.</p>\n<pre class=\"lang-py prettyprint-override\"><code>def ignore_b_handler(failure: BaseException):\n    if not isinstance(failure, ErrorB):\n        raise failure\n\nvalidate(..., ignore_b_handler)\n</code></pre>\n<p>This might seem familiar to dependency inversion and is in fact related to it.</p>\n<p>There are various stages of buying into effect handling, and it is possible to reproduce much if not all features via classes. Aside from technical functionality, one can implement ambient effect handlers (similar to how <code>try</code> &quot;connects&quot; to <code>raise</code> automatically) via <a href=\"https://docs.python.org/3/library/threading.html#threading.local\" rel=\"nofollow noreferrer\">thread local</a> or <a href=\"https://docs.python.org/3/library/contextvars.html\" rel=\"nofollow noreferrer\">context-local</a> variables.</p>\n"}
{"Id": 73719101, "PostTypeId": 1, "Title": "Connecting a C++ program to a Python script with shared memory", "Body": "<p>I'm trying to connect a C++ program to python using shared memory but I don't know how to pass the name of the memory segment to python.</p>\n<p>Here is my C++ code:</p>\n<pre><code>key_t key = ftok(&quot;address&quot;, 1);\nint shm_o;\nchar* msg = &quot;hello there&quot;;\nint len = strlen(msg) + 1;\nvoid* addr;\n\nshm_o = shmget(key, 20, IPC_CREAT | 0600);\nif(shm_o == -1)\n{\n    std::cout &lt;&lt; &quot;Failed: shmget.\\n&quot;;\n    return 1;\n}\n\naddr = shmat(shm_o, NULL, 0);\nif(addr == (void*) -1)\n{\n    std::cout &lt;&lt; &quot;Failed: shmat.\\n&quot;;\n    return 1;\n}\n\nstd::cout &lt;&lt; &quot;Shared memory segment created successfully with id: &quot; &lt;&lt; shm_o;\nmemcpy(addr, msg, len);\n\ngetchar();\nreturn 0;\n</code></pre>\n<p>I'm trying to get python to read from the shared memory segment like so:</p>\n<pre><code>shm_a = shared_memory.SharedMemory(name=&quot;address&quot;, create=False, size=20)\n\nprint(bytes(shm_a.buf[:11]))\n</code></pre>\n<p>but it throws an exception saying there is no file or directory called 'address'.</p>\n<p>Am I going about this correctly or is there another way to attach python to the shared memory segment?</p>\n<p>Any help would be much appreciated.</p>\n", "AcceptedAnswerId": 73720808, "AcceptedAnswer": "<p>Taking the liberty to post a working example here for POSIX shared memory segments, which will work across C/C++ and Python on Linux/UNIX-like systems. This will <strong>not</strong> work on Windows.</p>\n<h2>C++ code to create and write data into a shared memory segment (name provided on command line):</h2>\n<pre><code>#include &lt;sys/mman.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;string.h&gt;\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nint main(int argc, char * argv[])\n{\n    if (argc != 2) {\n         std::cerr &lt;&lt; &quot;Argument &lt;shmem_name&gt; required&quot; &lt;&lt; std::endl;\n         return 1;\n    }\n    const char * shmem_name = argv[1];\n    size_t shm_size = 4096;\n    int shmem_fd = shm_open(shmem_name, O_CREAT|O_RDWR, S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP);\n    if (shmem_fd == -1) {\n         perror(&quot;shm_open&quot;);\n         return 1;\n    }\n    std::cout &lt;&lt; &quot;Shared Memory segment created with fd &quot; &lt;&lt; shmem_fd &lt;&lt; std::endl;\n    if (ftruncate(shmem_fd, shm_size) == -1) {\n        perror(&quot;ftruncate&quot;);\n        return 1;\n    }\n    std::cout &lt;&lt; &quot;Shared Memory segment resized to &quot; &lt;&lt; shm_size &lt;&lt; std::endl;\n    void * addr = mmap(0, shm_size, PROT_WRITE, MAP_SHARED, shmem_fd, 0);\n    if (addr == MAP_FAILED) {\n        perror(&quot;mmap&quot;);\n        return 1;\n    }\n    std::cout &lt;&lt; &quot;Please enter some text to write to shared memory segment\\n&quot;;\n    std::string text;\n    std::getline(std::cin, text);\n    while (! text.empty()) {\n        strncpy((char *)addr, text.data(), shm_size);\n        std::cout &lt;&lt; &quot;Written '&quot; &lt;&lt; text &lt;&lt; &quot;' to shared memory segment\\n&quot;;\n        std::getline(std::cin, text);\n    }\n    std::cout &lt;&lt; &quot;Unlinking shared memory segment.&quot; &lt;&lt; std::endl;\n    shm_unlink(shmem_name) ;\n}\n</code></pre>\n<h2>Python code to read any string from the beginning of the shared memory segment:</h2>\n<pre><code>import sys\nfrom multiprocessing import shared_memory, resource_tracker\n\nif len(sys.argv) != 2:\n    print(&quot;Argument &lt;shmem_name&gt; required&quot;)\n    sys.exit(1)\n\nshm_seg = shared_memory.SharedMemory(name=sys.argv[1])\nprint(bytes(shm_seg.buf).strip(b'\\x00').decode('ascii'))\nshm_seg.close()\n# Manually remove segment from resource_tracker, otherwise shmem segment\n# will be unlinked upon program exit\nresource_tracker.unregister(shm_seg._name, &quot;shared_memory&quot;)\n</code></pre>\n"}
{"Id": 73566474, "PostTypeId": 1, "Title": "Unable to locate package python-openssl", "Body": "<p>I'm trying to install Pyenv, and I'm running on Ubuntu 22.04 LTS. but whenever I run this command</p>\n<pre><code>sudo apt install -y make build-essential libssl-dev zlib1g-dev \\ libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev \\ libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python-openssl \\ git\n</code></pre>\n<p>I get this error</p>\n<pre class=\"lang-none prettyprint-override\"><code>Unable to locate package python-openssl\n</code></pre>\n<p>I've tried searching for solutions online, but I think they have encountered it on older versions of Ubuntu and not on the latest version.</p>\n", "AcceptedAnswerId": 73566675, "AcceptedAnswer": "<p>Make sure your list of packages is updated (<code>sudo apt update</code>). Python openssl bindings are available in 22.04 in <code>python3-openssl</code> (<a href=\"https://packages.ubuntu.com/jammy/python3-openssl\" rel=\"noreferrer\">link</a>), so you can install it by running</p>\n<pre><code>sudo apt install python3-openssl\n</code></pre>\n"}
{"Id": 74405180, "PostTypeId": 1, "Title": "Why cpython exposes 'PyTuple_SetItem' as C-API if tuple is immutable by design?", "Body": "<p>Tuple in python is immutable by design, so if we try to mutate a tuple object python emits following <code>TypeError</code> which make sense.</p>\n<pre><code>&gt;&gt;&gt; a = (1, 2, 3)\n&gt;&gt;&gt; a[0] = 12\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nTypeError: 'tuple' object does not support item assignment\n</code></pre>\n<p>So my question is, if tuple is immutable by design why cpython exposes <code>PyTuple_SetItem</code> as C-API?.</p>\n<p>From the documentation it's described as</p>\n<blockquote>\n<p><code>int PyTuple_SetItem(PyObject *p, Py_ssize_t pos, PyObject *o)</code></p>\n<p>Insert a reference to object <code>o</code> at position pos of the tuple pointed to\nby <code>p</code>. Return 0 on success. If pos is out of bounds, return -1 and set\nan IndexError exception.</p>\n</blockquote>\n<p>Isn't this statement exactly equal to <code>tuple[index] = value</code> in python layer?. If the goal was to create a tuple from collection of items we could have use <a href=\"https://docs.python.org/3/c-api/tuple.html#c.PyTuple_Pack\" rel=\"nofollow noreferrer\"><code>PyTuple_Pack</code></a>.</p>\n<p>Additional note:</p>\n<p>After lot of trial and error with <code>ctypes.pythonapi</code> I managed to mutate tuple object using <code>PyTuple_SetItem</code></p>\n<pre><code>import ctypes\n\nfrom ctypes import py_object\n\nmy_tuple = (1, 2, 3)\nnewObj = py_object(my_tuple)\n\nm = &quot;hello&quot;\n\n# I don't know why I need to Py_DecRef here. \n# Although to reproduce this in your system,  no of times you have \n# to do `Py_DecRef` depends on no of ref count of `newObj` in your system\nctypes.pythonapi.Py_DecRef(newObj)\nctypes.pythonapi.Py_DecRef(newObj)\nctypes.pythonapi.Py_DecRef(newObj)\n\nctypes.pythonapi.Py_IncRef(m)\n\n\n\nPyTuple_SetItem = ctypes.pythonapi.PyTuple_SetItem\nPyTuple_SetItem.argtypes = ctypes.py_object, ctypes.c_size_t, ctypes.py_object\n\nPyTuple_SetItem(newObj, 0, m)\nprint(my_tuple) # this will print `('hello', 2, 3)`\n</code></pre>\n", "AcceptedAnswerId": 74405544, "AcceptedAnswer": "<p>Similarly, there is a <a href=\"https://docs.python.org/3/c-api/tuple.html#c._PyTuple_Resize\" rel=\"noreferrer\"><code>PyTuple_Resize</code></a> function with the warning</p>\n<blockquote>\n<p>Because tuples are supposed to be immutable, this should only be used\nif there is only one reference to the object. Do not use this if the\ntuple may already be known to some other part of the code. The tuple\nwill always grow or shrink at the end. Think of this as destroying the\nold tuple and creating a new one, only more efficiently.</p>\n</blockquote>\n<p>Looking at the source, there is a guard on the function</p>\n<pre><code>if (!PyTuple_Check(op) || Py_REFCNT(op) != 1) {\n    .... error ....\n</code></pre>\n<p>Sure enough, this is only allowed when there is only 1 reference to the tuple - that reference being the thing that thinks its a good idea to change it. So, a tuple is &quot;mostly immutable&quot; but C code can change it in limited circumstances to avoid the penalty of creating a new tuple.</p>\n"}
{"Id": 73711633, "PostTypeId": 1, "Title": "How to calculate and store results based upon the Matching Rows of two different Pandas Dataframes in Python", "Body": "<p>I have three DataFrames which I am importing from Excel Files.\nThe dataframes are given below as HTML Tables,</p>\n<p><code>Season Wise Record</code> (this contains a Column <code>Reward</code> which is initialized with <code>0</code> initially)</p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Unnamed: 0&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Team&lt;/th&gt;&lt;th&gt;Position&lt;/th&gt;&lt;th&gt;Games Played&lt;/th&gt;&lt;th&gt;PassingCompletions&lt;/th&gt;&lt;th&gt;PassingYards&lt;/th&gt;&lt;th&gt;PassingTouchdowns&lt;/th&gt;&lt;th&gt;RushingYards&lt;/th&gt;&lt;th&gt;RushingTouchdowns&lt;/th&gt;&lt;th&gt;ReceivingYards&lt;/th&gt;&lt;th&gt;Receptions&lt;/th&gt;&lt;th&gt;Touchdowns&lt;/th&gt;&lt;th&gt;Type&lt;/th&gt;&lt;th&gt;Sacks&lt;/th&gt;&lt;th&gt;SoloTackles&lt;/th&gt;&lt;th&gt;TacklesForLoss&lt;/th&gt;&lt;th&gt;FumblesForced&lt;/th&gt;&lt;th&gt;DefensiveTouchdowns&lt;/th&gt;&lt;th&gt;Interceptions&lt;/th&gt;&lt;th&gt;PassesDefended&lt;/th&gt;&lt;th&gt;ReceivingTouchdowns&lt;/th&gt;&lt;th&gt;Reward&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;Tom Brady&lt;/td&gt;&lt;td&gt;TAM&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;485&lt;/td&gt;&lt;td&gt;5316&lt;/td&gt;&lt;td&gt;43&lt;/td&gt;&lt;td&gt;81&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Justin Herbert&lt;/td&gt;&lt;td&gt;LAC&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;443&lt;/td&gt;&lt;td&gt;5014&lt;/td&gt;&lt;td&gt;38&lt;/td&gt;&lt;td&gt;302&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;Matthew Stafford&lt;/td&gt;&lt;td&gt;LAR&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;404&lt;/td&gt;&lt;td&gt;4886&lt;/td&gt;&lt;td&gt;41&lt;/td&gt;&lt;td&gt;43&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;Patrick Mahomes&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;436&lt;/td&gt;&lt;td&gt;4839&lt;/td&gt;&lt;td&gt;37&lt;/td&gt;&lt;td&gt;381&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;Derek Carr&lt;/td&gt;&lt;td&gt;LVR&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;428&lt;/td&gt;&lt;td&gt;4804&lt;/td&gt;&lt;td&gt;23&lt;/td&gt;&lt;td&gt;108&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Joe Burrow&lt;/td&gt;&lt;td&gt;CIN&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;366&lt;/td&gt;&lt;td&gt;4611&lt;/td&gt;&lt;td&gt;34&lt;/td&gt;&lt;td&gt;118&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;Dak Prescott&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;410&lt;/td&gt;&lt;td&gt;4449&lt;/td&gt;&lt;td&gt;37&lt;/td&gt;&lt;td&gt;146&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;Josh Allen&lt;/td&gt;&lt;td&gt;BUF&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;409&lt;/td&gt;&lt;td&gt;4407&lt;/td&gt;&lt;td&gt;36&lt;/td&gt;&lt;td&gt;763&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;88&lt;/td&gt;&lt;td&gt;Ezekiel Elliott&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;RB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1002&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;287&lt;/td&gt;&lt;td&gt;47&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;89&lt;/td&gt;&lt;td&gt;Marcus Mariota&lt;/td&gt;&lt;td&gt;LVR&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;87&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;90&lt;/td&gt;&lt;td&gt;Johnny Hekker&lt;/td&gt;&lt;td&gt;LAR&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;91&lt;/td&gt;&lt;td&gt;Greg Ward&lt;/td&gt;&lt;td&gt;PHI&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;95&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;92&lt;/td&gt;&lt;td&gt;Kendall Hinton&lt;/td&gt;&lt;td&gt;DEN&lt;/td&gt;&lt;td&gt;WR&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;175&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;93&lt;/td&gt;&lt;td&gt;Keenan Allen&lt;/td&gt;&lt;td&gt;LAC&lt;/td&gt;&lt;td&gt;WR&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1138&lt;/td&gt;&lt;td&gt;106&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;94&lt;/td&gt;&lt;td&gt;Danny Amendola&lt;/td&gt;&lt;td&gt;HOU&lt;/td&gt;&lt;td&gt;QB&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;248&lt;/td&gt;&lt;td&gt;24&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;95&lt;/td&gt;&lt;td&gt;Cole Beasley&lt;/td&gt;&lt;td&gt;BUF&lt;/td&gt;&lt;td&gt;WR&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;693&lt;/td&gt;&lt;td&gt;82&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;OFFENSE&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</code></pre>\r\n</div>\r\n</div>\r\n</p>\n<p><code>Game Wise Record</code> (I am only adding some  sample rows, there are 20k+ rows in it)</p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Index&lt;/th&gt;&lt;th&gt;Week&lt;/th&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Team&lt;/th&gt;&lt;th&gt;Starter&lt;/th&gt;&lt;th&gt;Interceptions&lt;/th&gt;&lt;th&gt;PassesDefended&lt;/th&gt;&lt;th&gt;Sacks&lt;/th&gt;&lt;th&gt;SoloTackles&lt;/th&gt;&lt;th&gt;TacklesForLoss&lt;/th&gt;&lt;th&gt;FumblesForced&lt;/th&gt;&lt;th&gt;PassesCompletions&lt;/th&gt;&lt;th&gt;PassingYards&lt;/th&gt;&lt;th&gt;PassingTouchdowns&lt;/th&gt;&lt;th&gt;PassingInterceptions&lt;/th&gt;&lt;th&gt;RushingYards&lt;/th&gt;&lt;th&gt;RushingTouchdowns&lt;/th&gt;&lt;th&gt;Receptions&lt;/th&gt;&lt;th&gt;ReceivingYards&lt;/th&gt;&lt;th&gt;ReceivingTouchdowns&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Jourdan Lewis&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Trevon Diggs&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Anthony Brown&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Jayron Kearse&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Micah Parsons&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Keanu Neal&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;DeMarcus Lawrence&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Jaylon Smith&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Dorance Armstrong Jr.&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Tarell Basham&lt;/td&gt;&lt;td&gt;DAL&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5175&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Patrick Mahomes&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;33&lt;/td&gt;&lt;td&gt;272&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;61&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5176&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Darrel Williams&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;27&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5177&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Tyreek Hill&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;63&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5178&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Clyde Edwards-Helaire&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;13&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5179&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Jerick McKinnon&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;13&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5180&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Michael Burton&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5181&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Mecole Hardman&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;76&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5182&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Travis Kelce&lt;/td&gt;&lt;td&gt;KAN&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;57&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</code></pre>\r\n</div>\r\n</div>\r\n</p>\n<p>And lastly, there's a <code>Player Goals File</code> (<strong>this is an Excel File containing Sheets for each of the position, I am only sharing for QB sheet, to keep the question short. IF needed, I can share the rest too)</strong></p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Goal&lt;/th&gt;&lt;th&gt;Goal Type&lt;/th&gt;&lt;th&gt;PCC Reward&lt;/th&gt;&lt;th&gt;Target&lt;/th&gt;&lt;th&gt;Min Value&lt;/th&gt;&lt;th&gt;Max Value&lt;/th&gt;&lt;th&gt;Games Required&lt;/th&gt;&lt;th&gt;Started&lt;/th&gt;&lt;th&gt;Level 99 PCC Reward x4 (current series)&lt;/th&gt;&lt;th&gt;TImes achieved&lt;/th&gt;&lt;th&gt;PCC Rewarded&lt;/th&gt;&lt;th&gt; &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 300-399 yds&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;25&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;300&lt;/td&gt;&lt;td&gt;399&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 400-499 yds&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;50&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;400&lt;/td&gt;&lt;td&gt;499&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;250&lt;/td&gt;&lt;td&gt;1000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 500+ yds&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;150&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;500&lt;/td&gt;&lt;td&gt;99999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;600&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 2 TDs&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;50&lt;/td&gt;&lt;td&gt;Touchdowns&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;450&lt;/td&gt;&lt;td&gt;1800&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 3 TDs&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;75&lt;/td&gt;&lt;td&gt;Touchdowns&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;300&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;300&lt;/td&gt;&lt;td&gt;1200&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 4 TDs&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;td&gt;Touchdowns&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;400&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;800&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Throw 5+ TDs&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;300&lt;/td&gt;&lt;td&gt;Touchdowns&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;10000&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1200&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;30-39 Completions&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;50&lt;/td&gt;&lt;td&gt;PassingCompletions&lt;/td&gt;&lt;td&gt;30&lt;/td&gt;&lt;td&gt;39&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;250&lt;/td&gt;&lt;td&gt;1000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;40+ Completions&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;PassingCompletions&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;td&gt;9999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;800&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;800&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0 INTs (must have been designated starter)&lt;/td&gt;&lt;td&gt;Game&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;td&gt;PassingInterceptions&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;800&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;1400&lt;/td&gt;&lt;td&gt;5600&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3500-3999 Passing YDs&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;500&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;3500&lt;/td&gt;&lt;td&gt;3999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4000-4999 Passing YDS&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;750&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;4000&lt;/td&gt;&lt;td&gt;4999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5000+ Passing YDS&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;1250&lt;/td&gt;&lt;td&gt;PassingYards&lt;/td&gt;&lt;td&gt;5000&lt;/td&gt;&lt;td&gt;99999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;5000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;30-39 Passing TDS&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;750&lt;/td&gt;&lt;td&gt;PassingTouchdowns&lt;/td&gt;&lt;td&gt;30&lt;/td&gt;&lt;td&gt;39&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;40-45 Passing TDS&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;1250&lt;/td&gt;&lt;td&gt;PassingTouchdowns&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;td&gt;49&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;5000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;50+ Passing TDS&lt;/td&gt;&lt;td&gt;Season&lt;/td&gt;&lt;td&gt;2000&lt;/td&gt;&lt;td&gt;PassingTouchdowns&lt;/td&gt;&lt;td&gt;50&lt;/td&gt;&lt;td&gt;99999&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;8000&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</code></pre>\r\n</div>\r\n</div>\r\n</p>\n<p>What I want to do is analyze the Records of the Season Wise Records and the Game Wise Records, and based upon the <code>Goals given</code> in the Player Goals File, I want to add the <strong>Reward</strong> for all the players.</p>\n<p>This is player position dependent so I made the following function to calculate Rewards for all the players (for the Season Records only)</p>\n<pre><code>def calculatePointsSeason(target, min_value, games_played_condition, max_value, tier_position, player_position, reward, games_played):\n    if player_position in positions[tier_position]:\n        if games_played &gt; games_played_condition:\n            if target &gt;= min_value and target &lt;= max_value:\n                return reward \n    return 0 \n</code></pre>\n<p>Similarly, I made this function to calculate Game wise Record,</p>\n<pre><code>def calculatePointsGame(target, min_value, max_value, tier_position, player_position, reward, started, started_condition):\n    if player_position in positions[tier_position]:\n        if started == started_condition:\n            if target &gt;= min_value and target &lt;= max_value:\n                return reward \n    return 0 \n</code></pre>\n<p>Following is the function in which I am applying these two functions to calculate the Reward for each player,</p>\n<pre><code>for key, value in positions.items(): # Positions has a list of all the positions \n    for (idx, row) in rewards[key].iterrows(): # Rewards is a Dict containing Pandas Dataframes against each position\n        if row['Goal Type'] == 'Season':\n            df = df.copy(deep=True) # df contains the Season Wise Record Dataframe\n            df['Reward'] += df.apply(lambda x: calculatePointsSeason(x[row['Target']], row['Min Value'], row['Games Required'],\n                                                               row['Max Value'], key, x['Position'],\n                                                                row['PCC Reward'], x['Games Played']), axis=1)\n        else: # For Game wise points\n            for (i, main_player) in df.iterrows():\n                for (j, game_player) in data.iterrows(): # data contains the Game Wise Record dataframe\n                    if main_player['Name'] == game_player['Name']:\n                        main_player['Reward'] += calculatePointsGame(main_player[row['Target']], \n                                                                    row['Min Value'], row['Max Value'], \n                                                                    key, main_player['Position'], row['PCC Reward'], \n                                                                    game_player['Starter'], row['Started'])\n</code></pre>\n<p>This function works well for the <code>Season Wise Records</code>, but for the <code>Game Wise</code>, I couldn't come up with any Pandas way to do it (eliminating the need of iteration of two Dataframes). I want some way to,</p>\n<ul>\n<li><p>Match the Rows given in the <code>Game Wise Record</code> file with the <code>Season Wise Record</code> file, <strong>based upon the Name attribute</strong></p>\n</li>\n<li><p>Send the Values from the <code>Game Wise Record</code> to the Custom Function and the <code>Position</code> of the player from the <code>Season Wise Record</code> (so that, only the specific reward is calculated for the player, e.g. if player is QB, so only QB Rewards will be match with him and etc. There are Excel Sheets for each position rewards)</p>\n</li>\n<li><p>Get the Reward Value back and add it to the <code>Reward</code> in the <code>Season Wise Record</code> against that specific player record.</p>\n</li>\n</ul>\n<p>I previously tried to do it by comparing the Name of the Player in the Season Wise Record with the Game Wise Record, but it didn't work. Is there any Pandas way to solve this issue? (where you don't have to iterate all the rows two times)</p>\n", "AcceptedAnswerId": 73819986, "AcceptedAnswer": "<p>I hope I understood correctly your intentions. To avoid double <code>for</code> loops, you need to use <code>groupby()</code> method and then apply the desired function to every row of the group; finally the aggregation function (<code>sum()</code>) should be applied to the group. Although you can use the <code>Name</code> as a key for grouping, I recommend to add <code>PlayerID</code>.</p>\n<p>The approach needs little preparation:</p>\n<pre><code>data = data.join(\n    df.reset_index().set_index(['Name', 'Team'], drop=False)[['index','Position']],\n    on=['Name','Team'],\n    how='left'\n).rename({'index':'PlayerID'}, axis=1)\n</code></pre>\n<p>We add 2 columns to <code>data</code> DataFrame, namely <code>Position</code> and <code>PlayerID</code> which is the index of the first DataFrame <code>df</code>. We search for the ID checking <code>Name</code> and <code>Team</code> that still may cause a collision (when there 2 players with identical name in the same team).</p>\n<p>When it's done the last part of the code will be like this:</p>\n<pre><code>for key, value in positions.items(): # Positions has a list of all the positions \n    for (_, row) in rewards[key].iterrows(): # Rewards is a Dict containing Pandas Dataframes against each position\n        if row['Goal Type'] == 'Season':\n            if row['Target'] in df.columns:\n                df['Reward'] += df.apply(lambda x: calculatePointsSeason(\n                    x[row['Target']], row['Min Value'], row['Games Required'],\n                    row['Max Value'], key, x['Position'],\n                    row['PCC Reward'], x['Games Played']\n                ), axis=1)\n        else: # For Game wise points\n            if row['Target'] in data.columns: # I added these 2 checks because sometimes target is not presented in the columns which raises the error\n                df['Reward'] = df['Reward'].add(\n                    data.groupby('PlayerID').apply(\n                        lambda group: group.apply(lambda game_player: calculatePointsGame(\n                            game_player[row['Target']], \n                            row['Min Value'], row['Max Value'], \n                            key, game_player['Position'],\n                            row['PCC Reward'], \n                            game_player['Starter'],\n                            row['Started']\n                        ), axis=1).sum()\n                    ),\n                    fill_value=0\n                )\n</code></pre>\n"}
{"Id": 73876937, "PostTypeId": 1, "Title": "What is the difference between keyword pass and ... in python?", "Body": "<p>Is there any significant difference between the two Python keywords (...) and (pass) like in the examples</p>\n<pre><code>def tempFunction():\n    pass \n</code></pre>\n<p>and</p>\n<pre><code>def tempFunction():\n    ...\n</code></pre>\n<p>I should be aware of?</p>\n", "AcceptedAnswerId": 73877007, "AcceptedAnswer": "<p>The <code>...</code> is the shorthand for the <code>Ellipsis</code> global object in python. Similar to <code>None</code> and <code>NotImplemented</code> it can be used as a marker value to indicate the absence of something.</p>\n<p>For example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>print(...)\n# Prints &quot;Ellipsis&quot;\n</code></pre>\n<p>In this case, it has no effect. You could put any constant there and it would do the same. This is valid:</p>\n<pre><code>def function():\n    1\n</code></pre>\n<p>Or</p>\n<pre><code>def function():\n    'this function does nothing'\n</code></pre>\n<p>Note both do nothing and return <code>None</code>. Since there is no return keyword the value won't be returned.</p>\n<p><code>pass</code> explicitly does nothing, so it will have the same effect in this case too.</p>\n"}
{"Id": 73597456, "PostTypeId": 1, "Title": "What is the python-poetry config file after 1.2.0 release?", "Body": "<p>I have been using <a href=\"https://python-poetry.org/\" rel=\"noreferrer\">python-poetry</a> for over a year now. <br/>\nAfter <a href=\"https://github.com/python-poetry/poetry/releases/tag/1.2.0\" rel=\"noreferrer\">poetry 1.2.0</a> release, I get such an info warning:</p>\n<pre><code>Configuration file exists at ~/Library/Application Support/pypoetry,\nreusing this directory.\n\nConsider moving configuration to ~/Library/Preferences/pypoetry,\nas support for the legacy directory will be removed in an upcoming release.\n</code></pre>\n<p>But in docs, it is still indicated for macOS: <code>~/Library/Application Support/pypoetry</code> <br/>\n<a href=\"https://python-poetry.org/docs/configuration/\" rel=\"noreferrer\">https://python-poetry.org/docs/configuration/</a></p>\n<p>My question is that if <code>~/Library/Preferences/pypoetry</code> is the latest decision what should I do for moving configuration to there? <br/>\nIs just copy-pasting enough?</p>\n<p><a href=\"https://python-poetry.org/docs/configuration/\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/54tHz.png\" alt=\"poetry-config-file-for-macos\" /></a></p>\n", "AcceptedAnswerId": 73632457, "AcceptedAnswer": "<p>Looks like it is as simple as copy/pasting to the new directory.</p>\n<p>I got the same error after upgrading to Poetry 1.2.  So I created a <code>pypoetry</code> folder in the new <code>Preferences</code> directory, copy/pasted the <code>config.toml</code> to it, and just to be safe, I renamed the original folder to:</p>\n<p><code>~/Library/Application Support/pypoetry_bak</code></p>\n<p>After doing this and running <code>poetry -V</code>, the error is gone.</p>\n"}
{"Id": 74599713, "PostTypeId": 1, "Title": "Merge two dictionaries in python", "Body": "<p>I'm trying to merge two dictionaries based on key value. However, I'm not able to achieve it. Below is the way I tried solving.</p>\n<pre><code>dict1 = {4: [741, 114, 306, 70],\n         2: [77, 325, 505, 144],\n         3: [937, 339, 612, 100],\n         1: [52, 811, 1593, 350]}\ndict2 = {1: 'A', 2: 'B', 3: 'C', 4: 'D'}\n</code></pre>\n<p>My resultant dictionary should be</p>\n<pre><code>output = {'D': [741, 114, 306, 70],\n          'B': [77, 325, 505, 144],\n          'C': [937, 339, 612, 100],\n          'A': [52, 811, 1593, 350]}\n</code></pre>\n<p>My code</p>\n<pre><code>def mergeDictionary(dict_obj1, dict_obj2):\n    dict_obj3 = {**dict_obj1, **dict_obj2}\n    for key, value in dict_obj3.items():\n        if key in dict_obj1 and key in dict_obj2:\n               dict_obj3[key] = [value , dict_obj1[key]]\n    return dict_obj3\n\ndict_3 = mergeDictionary(dict1, dict2)\n</code></pre>\n<p>But I'm getting this as output</p>\n<pre><code>dict_3={4: ['D', [741, 114, 306, 70]], 2: ['B', [77, 325, 505, 144]], 3: ['C', [937, 339, 612, 100]], 1: ['A', [52, 811, 1593, 350]]}\n</code></pre>\n", "AcceptedAnswerId": 74599751, "AcceptedAnswer": "<p>Use a simple dictionary comprehension:</p>\n<pre><code>output = {dict2[k]: v for k,v in dict1.items()}\n</code></pre>\n<p>Output:</p>\n<pre><code>{'D': [741, 114, 306, 70],\n 'B': [77, 325, 505, 144],\n 'C': [937, 339, 612, 100],\n 'A': [52, 811, 1593, 350]}\n</code></pre>\n"}
{"Id": 73693104, "PostTypeId": 1, "Title": "Python 3.10.7 - ValueError: Exceeds the limit (4300) for integer string conversion", "Body": "<blockquote>\n<pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt; sys.set_int_max_str_digits(4300)  # Illustrative, this is the default.\n&gt;&gt;&gt; _ = int('2' * 5432)\nTraceback (most recent call last):\n...\nValueError: Exceeds the limit (4300) for integer string conversion: value has 5432 digits.\n</code></pre>\n</blockquote>\n<p>Python 3.10.7 introduced this breaking change for type conversion.</p>\n<p>Documentation: <a href=\"https://docs.python.org/3/library/stdtypes.html#integer-string-conversion-length-limitation\" rel=\"noreferrer\">Integer string conversion length limitation</a></p>\n<p>Actually I don't understand why</p>\n<ol>\n<li>this was introduced and</li>\n<li>where does the default value of 4300 come from? Sounds like an arbitrary number.</li>\n</ol>\n", "AcceptedAnswerId": 73693178, "AcceptedAnswer": "<p>See github issue <a href=\"https://github.com/python/cpython/issues/95778\" rel=\"noreferrer\">CVE-2020-10735: Prevent DoS by large int&lt;-&gt;str conversions #95778</a>:</p>\n<blockquote>\n<p><strong>Problem</strong></p>\n<p>A Denial Of Service (DoS) issue was identified in CPython\nbecause we use binary bignum\u2019s for our int implementation. A huge\ninteger will always consume a near-quadratic amount of CPU time in\nconversion to or from a base 10 (decimal) string with a large number\nof digits. No efficient algorithm exists to do otherwise.</p>\n<p>It is quite common for Python code implementing network protocols and\ndata serialization to do int(untrusted_string_or_bytes_value) on input\nto get a numeric value, without having limited the input length or to\ndo <code>log(&quot;processing thing id %s&quot;, unknowingly_huge_integer)</code> or any\nsimilar concept to convert an int to a string without first checking\nits magnitude. (<code>http</code>, <code>json</code>, <code>xmlrpc</code>, <code>logging</code>, loading large values into\ninteger via linear-time conversions such as hexadecimal stored in\nyaml, or anything computing larger values based on user controlled\ninputs\u2026 which then wind up attempting to output as decimal later on).\nAll of these can suffer a CPU consuming DoS in the face of untrusted\ndata.</p>\n<p>Everyone auditing all existing code for this, adding length guards,\nand maintaining that practice everywhere is not feasible nor is it\nwhat we deem the vast majority of our users want to do.</p>\n<p>This issue has been reported to the Python Security Response Team\nmultiple times by a few different people since early 2020, most\nrecently a few weeks ago while I was in the middle of polishing up the\nPR so it\u2019d be ready before 3.11.0rc2.</p>\n<p><strong>Mitigation</strong></p>\n<p>After discussion on the Python Security Response Team\nmailing list the conclusion was that we needed to limit the size of\ninteger to string conversions for non-linear time conversions\n(anything not a power-of-2 base) by default. And offer the ability to\nconfigure or disable this limit.</p>\n<p>The Python Steering Council is aware of this change and accepts it as\nnecessary.</p>\n</blockquote>\n<p>Further discussion can be found on the Python Core Developers Discuss thread <a href=\"https://discuss.python.org/t/int-str-conversions-broken-in-latest-python-bugfix-releases/18889\" rel=\"noreferrer\">Int/str conversions broken in latest Python bugfix releases</a>.</p>\n<p>I found <a href=\"https://discuss.python.org/t/int-str-conversions-broken-in-latest-python-bugfix-releases/18889/2\" rel=\"noreferrer\">this comment</a> by Steve Dower to be informative:</p>\n<blockquote>\n<p>Our apologies for the lack of transparency in the process here. The\nissue was first reported to a number of other security teams, and\nconverged in the Python Security Response Team where we agreed that\nthe correct fix was to modify the runtime.</p>\n<p>The delay between report and fix is entirely our fault. The security\nteam is made up of volunteers, our availability isn\u2019t always reliable,\nand there\u2019s nobody \u201cin charge\u201d to coordinate work. We\u2019ve been\ndiscussing how to improve our processes. However, we did agree that\nthe potential for exploitation is high enough that we didn\u2019t want to\ndisclose the issue without a fix available and ready for use.</p>\n<p>We did work through a number of alternative approaches, implementing\nmany of them. The code doing int(gigabyte_long_untrusted_string) could\nbe anywhere inside a json.load or HTTP header parser, and can run very\ndeep. Parsing libraries are everywhere, and tend to use int\nindiscriminately (though they usually handle ValueError already).\nExpecting every library to add a new argument to every int() call\nwould have led to thousands of vulnerabilities being filed, and made\nit impossible for users to ever trust that their systems could not be\nDoS\u2019d.</p>\n<p>We agree it\u2019s a heavy hammer to do it in the core, but it\u2019s also the\nonly hammer that has a chance of giving users the confidence to keep\nrunning Python at the boundary of their apps.</p>\n<p>Now, I\u2019m personally inclined to agree that int-&gt;str conversions should\ndo something other than raise. I was outvoted because it would break\nround-tripping, which is a reasonable argument that I accepted. We can\nstill improve this over time and make it more usable. However, in most\ncases we saw, rendering an excessively long string isn\u2019t desirable\neither. That should be the opt-in behaviour.</p>\n<p>Raising an exception from str may prove to be too much, and could be\nreconsidered, but we don\u2019t see a feasible way to push out updates to\nevery user of int, so that will surely remain global.</p>\n</blockquote>\n"}
{"Id": 73708478, "PostTypeId": 1, "Title": "The git (or python) command requires the command line developer tools", "Body": "<p><em>This knowledge post isn't a duplication of other similar ones, since it's related to 12/September/2022 Xcode update, which demands a different kind of solution</em></p>\n<p>I have come to my computer today and discovered that nothing runs on my terminal Every time I have opened my IDE (VS Code or PyCharm), it has given me this message in the start of the terminal.</p>\n<p>I saw so many solutions, which have said to uninstall <code>pyenv</code> and install python via brew, which was a terrible idea, because I need different python versions for different projects.</p>\n<p>Also, people spoke a lot about symlinks, which as well did not make any sense, because everything was working until yesterday.</p>\n<p>Furthermore, overwriting <code>.oh-my-zsh</code> with a new built one did not make any difference.</p>\n", "AcceptedAnswerId": 73709260, "AcceptedAnswer": "<p>I was prompted to reinstall commandLine tools over and over when trying to accept the terms</p>\n<p>I FIXED this by opening xcode and confirming the new update information</p>\n"}
{"Id": 74605279, "PostTypeId": 1, "Title": "Python 3.11 worse optimized than 3.10?", "Body": "<p>I run this simple loop with Python 3.10.7 and 3.11.0 on Windows 10.</p>\n<pre><code>import time\na = 'a'\n\nstart = time.time()\nfor _ in range(1000000):\n    a += 'a'\nend = time.time()\n\nprint(a[:5], (end-start) * 1000)\n</code></pre>\n<p>The older version executes in 187ms, Python 3.11 needs about 17000ms. Does 3.10 realize that only the first 5 chars of <code>a</code> are needed, whereas 3.11 executes the whole loop? I confirmed this performance difference on godbolt.</p>\n", "AcceptedAnswerId": 74607850, "AcceptedAnswer": "<p><strong>TL;DR:</strong> you should not use such a loop in any performance critical code but <code>''.join</code> instead. The inefficient execution appears to be related to a regression during the bytecode generation in CPython 3.11 (and missing optimizations during the evaluation of binary add operation on Unicode strings).</p>\n<hr />\n<h2>General guidelines</h2>\n<p>This is an <strong>antipattern</strong>. You should not write such a code if you want this to be fast. This is described in <a href=\"https://peps.python.org/pep-0008/#programming-recommendations\" rel=\"noreferrer\">PEP-8</a>:</p>\n<blockquote>\n<p>Code should be written in a way that does not disadvantage other implementations of Python (PyPy, Jython, IronPython, Cython, Psyco, and such). <br />\nFor example, <strong>do not rely on CPython\u2019s efficient implementation of in-place string concatenation for statements in the form <code>a += b</code> or <code>a = a + b</code></strong>. This optimization is fragile even in CPython (it only works for some types) and isn\u2019t present at all in implementations that don\u2019t use refcounting. In performance sensitive parts of the library, the <strong><code>''.join()</code> form should be used instead</strong>. This will ensure that concatenation occurs in <em>linear time</em> across various implementations.</p>\n</blockquote>\n<p>Indeed, other implementations like PyPy does not perform an efficient in-place string concatenation for example. A new bigger string is created for every iteration (since strings are immutable, the previous one may be referenced and PyPy does not use a reference counting but a <a href=\"https://doc.pypy.org/en/latest/gc_info.html\" rel=\"noreferrer\">garbage collector</a>). This results in a quadratic runtime as opposed to a linear runtime in CPython (at least in past implementation).</p>\n<hr />\n<h2>Deep Analysis</h2>\n<p>I can reproduce the problem on Windows 10 between the embedded (64-bit x86-64) version of CPython <a href=\"https://www.python.org/ftp/python/3.10.8/python-3.10.8-embed-amd64.zip\" rel=\"noreferrer\">3.10.8</a> and the one of <a href=\"https://www.python.org/ftp/python/3.11.0/python-3.11.0-embed-amd64.zip\" rel=\"noreferrer\">3.11.0</a>:</p>\n<pre><code>Timings:\n - CPython 3.10.8:    146.4 ms\n - CPython 3.11.0:  15186.8 ms\n</code></pre>\n<p>It turns out the code has not particularly changed between CPython 3.10 and 3.11 when it comes to Unicode string appending. See for example <code>PyUnicode_Append</code>: <a href=\"https://github.com/python/cpython/blob/3.10/Objects/unicodeobject.c#L11809\" rel=\"noreferrer\">3.10</a> and <a href=\"https://github.com/python/cpython/blob/3.11/Objects/unicodeobject.c#L11476\" rel=\"noreferrer\">3.11</a>.</p>\n<p>A low-level profiling analysis shows that nearly all the time is spent in one unnamed function call of another unnamed function called by <code>PyUnicode_Concat</code> (which is also left unmodified between CPython 3.10.8 and 3.11.0). This slow unnamed function contains a pretty small set of assembly instructions and nearly all the time is spent in one unique x86-64 assembly instruction: <code>rep movsb byte ptr [rdi], byte ptr [rsi]</code>. This instruction is basically meant to copy a buffer pointed by the <code>rsi</code> register to a buffer pointed by the <code>rdi</code> register (the processor copy <code>rcx</code> bytes for the source buffer to the destination buffer and decrement the <code>rcx</code> register for each byte until it reach 0). This information shows that the unnamed function is actually <code>memcpy</code> of the standard MSVC C runtime (ie. CRT) which appears to be called by <code>_copy_characters</code> itself called by <code>_PyUnicode_FastCopyCharacters</code> of <code>PyUnicode_Concat</code> (all the functions are still belonging to the same file). However, these CPython functions are still left unmodified between CPython 3.10.8 and 3.11.0. The non-negligible time spent in malloc/free (about 0.3 seconds) seems to indicate that a lot of new string objects are created -- certainly at least 1 per iteration -- matching with the call to <code>PyUnicode_New</code> in the code of <code>PyUnicode_Concat</code>. All of this indicates that a new bigger string is created and copied as specified above.</p>\n<p>The thing is calling <code>PyUnicode_Concat</code> is certainly the root of the performance issue here and I think CPython 3.10.8 is faster because it certainly calls <code>PyUnicode_Append</code> instead. Both calls are directly performed by the main big interpreter evaluation loop and this loop is driven by the generated bytecode.</p>\n<p>It turns out that the <strong>generated bytecode is different between the two version and it is the root of the performance issue</strong>. Indeed, CPython 3.10 generates an <code>INPLACE_ADD</code> bytecode instruction while CPython 3.11 generates a  <code>BINARY_OP</code> bytecode instruction. Here is the bytecode for the loops in the two versions:</p>\n<pre><code>CPython 3.10 loop:\n\n        &gt;&gt;   28 FOR_ITER                 6 (to 42)\n             30 STORE_NAME               4 (_)\n  6          32 LOAD_NAME                1 (a)\n             34 LOAD_CONST               2 ('a')\n             36 INPLACE_ADD                             &lt;----------\n             38 STORE_NAME               1 (a)\n             40 JUMP_ABSOLUTE           14 (to 28)\n\nCPython 3.11 loop:\n\n        &gt;&gt;   66 FOR_ITER                 7 (to 82)\n             68 STORE_NAME               4 (_)\n  6          70 LOAD_NAME                1 (a)\n             72 LOAD_CONST               2 ('a')\n             74 BINARY_OP               13 (+=)         &lt;----------\n             78 STORE_NAME               1 (a)\n             80 JUMP_BACKWARD            8 (to 66)\n</code></pre>\n<p>This changes appears to come from <a href=\"https://github.com/python/cpython/issues/89799\" rel=\"noreferrer\">this issue</a>. The code of the main interpreter loop (see ceval.c) is different between the two CPython version. Here are the code executed by the two versions:</p>\n<pre class=\"lang-c prettyprint-override\"><code>        // In CPython 3.10.8\n        case TARGET(INPLACE_ADD): {\n            PyObject *right = POP();\n            PyObject *left = TOP();\n            PyObject *sum;\n            if (PyUnicode_CheckExact(left) &amp;&amp; PyUnicode_CheckExact(right)) {\n                sum = unicode_concatenate(tstate, left, right, f, next_instr); // &lt;-----\n                /* unicode_concatenate consumed the ref to left */\n            }\n            else {\n                sum = PyNumber_InPlaceAdd(left, right);\n                Py_DECREF(left);\n            }\n            Py_DECREF(right);\n            SET_TOP(sum);\n            if (sum == NULL)\n                goto error;\n            DISPATCH();\n        }\n\n//----------------------------------------------------------------------------\n\n        // In CPython 3.11.0\n        TARGET(BINARY_OP_ADD_UNICODE) {\n            assert(cframe.use_tracing == 0);\n            PyObject *left = SECOND();\n            PyObject *right = TOP();\n            DEOPT_IF(!PyUnicode_CheckExact(left), BINARY_OP);\n            DEOPT_IF(Py_TYPE(right) != Py_TYPE(left), BINARY_OP);\n            STAT_INC(BINARY_OP, hit);\n            PyObject *res = PyUnicode_Concat(left, right); // &lt;-----\n            STACK_SHRINK(1);\n            SET_TOP(res);\n            _Py_DECREF_SPECIALIZED(left, _PyUnicode_ExactDealloc);\n            _Py_DECREF_SPECIALIZED(right, _PyUnicode_ExactDealloc);\n            if (TOP() == NULL) {\n                goto error;\n            }\n            JUMPBY(INLINE_CACHE_ENTRIES_BINARY_OP);\n            DISPATCH();\n        }\n</code></pre>\n<p>Note that <code>unicode_concatenate</code> calls <code>PyUnicode_Append</code> (and do some reference counting checks before). In the end, CPython 3.10.8 calls <code>PyUnicode_Append</code> which is fast (in-place) and CPython 3.11.0 calls <code>PyUnicode_Concat</code> which is slow (out-of-place). It clearly looks like a regression to me.</p>\n<p>People in the comments reported having no performance issue on Linux. However, experimental tests shows a <code>BINARY_OP</code> instruction is also generated on Linux, and I cannot find so far any Linux-specific optimization regarding string concatenation. Thus, the difference between the platforms is pretty surprising.</p>\n<hr />\n<h2>Update: towards a fix</h2>\n<p>I have opened an issue about this available <a href=\"https://github.com/python/cpython/issues/99862\" rel=\"noreferrer\">here</a>. One should not that <strong>putting the code in a function is significantly faster</strong> due to the variable being local (as pointed out by @Dennis in the comments).</p>\n<hr />\n<p>Related posts:</p>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/3055477/how-slow-is-pythons-string-concatenation-vs-str-join\">How slow is Python&#39;s string concatenation vs. str.join?</a></li>\n<li><a href=\"https://stackoverflow.com/questions/1349311/python-string-join-is-faster-than-but-whats-wrong-here\">Python string &#39;join&#39; is faster (?) than &#39;+&#39;, but what&#39;s wrong here?</a></li>\n<li><a href=\"https://stackoverflow.com/questions/69556269/python-string-concatenation-in-for-loop-in-place\">Python string concatenation in for-loop in-place?</a></li>\n</ul>\n"}
{"Id": 74454587, "PostTypeId": 1, "Title": "sentry sdk custom performance integration for python app", "Body": "<p>Sentry can track performance for celery tasks and API endpoints\n<a href=\"https://docs.sentry.io/product/performance/\" rel=\"noreferrer\">https://docs.sentry.io/product/performance/</a></p>\n<p>I have custom script that are lunching by crone and do set of similar <em><strong>tasks</strong></em></p>\n<p>I want to incorporated sentry_sdk into my script to get performance tracing of my <em><strong>tasks</strong></em></p>\n<p>Any advise how to do it with\n<a href=\"https://getsentry.github.io/sentry-python/api.html#sentry_sdk.capture_event\" rel=\"noreferrer\">https://getsentry.github.io/sentry-python/api.html#sentry_sdk.capture_event</a></p>\n", "AcceptedAnswerId": 74481555, "AcceptedAnswer": "<p>You don't need use <code>capture_event</code><br />\nI would suggest to use <code>sentry_sdk.start_transaction</code> instead. It also allows track your function performance.</p>\n<p>Look at my example</p>\n<pre><code>from time import sleep\nfrom sentry_sdk import Hub, init, start_transaction\n\ninit(\n    dsn=&quot;dsn&quot;,\n    traces_sample_rate=1.0,\n)\n\n\ndef sentry_trace(func):\n    def wrapper(*args, **kwargs):\n        transaction = Hub.current.scope.transaction\n        if transaction:\n            with transaction.start_child(op=func.__name__):\n                return func(*args, **kwargs)\n        else:\n            with start_transaction(op=func.__name__, name=func.__name__):\n                return func(*args, **kwargs)\n\n    return wrapper\n\n\n@sentry_trace\ndef b():\n    for i in range(1000):\n        print(i)\n\n\n@sentry_trace\ndef c():\n    sleep(2)\n    print(1)\n\n\n@sentry_trace\ndef a():\n    sleep(1)\n    b()\n    c()\n\n\nif __name__ == '__main__':\n    a()\n</code></pre>\n<p>After starting this code you can see basic info of transaction <code>a</code> with childs <code>b</code> and <code>c</code>\n<a href=\"https://i.stack.imgur.com/7dR5r.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7dR5r.png\" alt=\"enter image description here\" /></a></p>\n"}
{"Id": 74660176, "PostTypeId": 1, "Title": "Using VisualStudio+ Python -- how to handle \"overriding stdlib module\" Pylance(reportShadowedImports) warning?", "Body": "<p>When running ipynbs in VS Code, I've started noticing Pylance warnings on standard library imports. I am using a conda virtual environment, and I believe the warning is related to that. An example using the glob library reads:</p>\n<p><code> &quot;env\\Lib\\glob.py&quot; is overriding the stdlib &quot;glob&quot; modulePylance(reportShadowedImports)</code></p>\n<p>So far my notebooks run as expected, but I am curious if this warning is indicative of poor layout or is just stating the obvious more of an &quot;FYI you are not using the base install of python&quot;.</p>\n<p>I have turned off linting and the problem stills persists. And almost nothing returns from my searches of the error &quot;reportShadowedImports&quot;.</p>\n", "AcceptedAnswerId": 74675579, "AcceptedAnswer": "<p>The reason you find nothing by searching is because this check has just been implemented recently (see <a href=\"https://github.com/microsoft/pyright/pull/4132\" rel=\"noreferrer\">Github</a>). I ran into the same problem as you because <code>code.py</code> from Micropython/Circuitpython also overrides the module &quot;code&quot; in stdlib.</p>\n<p>The solution is simple, though you then loose out on this specific check. Just add <code>reportShadowedImports</code> to your <a href=\"https://github.com/microsoft/pyright/blob/main/docs/configuration.md#reportShadowedImports\" rel=\"noreferrer\">pyright config</a>. For VS Code, that would be adding it to <code>.vscode/settings.json</code>:</p>\n<pre><code>{\n  &quot;python.languageServer&quot;: &quot;Pylance&quot;,\n  [...]\n  &quot;python.analysis.diagnosticSeverityOverrides&quot;: {\n      &quot;reportShadowedImports&quot;: &quot;none&quot;\n  },\n  [...]\n}\n</code></pre>\n"}
{"Id": 73888639, "PostTypeId": 1, "Title": "Why is this unpacking expression not allowed in python3.10?", "Body": "<p>I used to unpack a long iterable expression like this:</p>\n<p>In python 3.8.7:</p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; _, a, (*_), c = [1,2,3,4,5,6]\n&gt;&gt;&gt; a\n2\n&gt;&gt;&gt; c\n6\n</code></pre>\n<p>In python 3.10.7:</p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; _, a, (*_), c = [1,2,3,4,5,6]\n  File &quot;&lt;stdin&gt;&quot;, line 1\n    _, a, (*_), c = [1,2,3,4,5,6]\n           ^^\nSyntaxError: cannot use starred expression here\n</code></pre>\n<p>I'm not sure which version of python between 3.8.7 and 3.10.7 introduced this backwards breaking behavior. What's the justification for this?</p>\n", "AcceptedAnswerId": 73888752, "AcceptedAnswer": "<p>There's an official discussion <a href=\"https://bugs.python.org/issue40631\" rel=\"nofollow noreferrer\">here</a>. The most relevant quote I can find is:</p>\n<blockquote>\n<blockquote>\n<p>Also the current behavior allows <code>(*x), y = 1</code> assignment. If <code>(*x)</code> is to be totally disallowed, <code>(*x), y = 1</code> should also be rejected.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>I agree.</p>\n</blockquote>\n<p>The final &quot;I agree&quot; is from Guido van Rossum.</p>\n<p>The rationale for rejecting <code>(*x)</code> was:</p>\n<blockquote>\n<p>Honestly this seems like a bug in 3.8 to me (if it indeed behaves like\nthis):</p>\n<pre><code>&gt;&gt;&gt; (*x), y (1, 2, 3)\n</code></pre>\n<p>Every time I mistakenly tried (*x) I really meant (*x,), so it's\nsurprising that (*x), y would be interpreted as (*x, y) rather than\nflagging (*x) as an error.</p>\n<p>Please don't &quot;fix&quot; this even if it is a regression.</p>\n</blockquote>\n<p>Also by Guido van Rossum. So it seems like <code>(*x)</code> was rejected because it looks too similar to unpacking into a singlet tuple.</p>\n"}
{"Id": 74583630, "PostTypeId": 1, "Title": "Why is Python saying modules are imported when they are not?", "Body": "<p>Python 3.6.5</p>\n<p>Using <a href=\"https://stackoverflow.com/a/30483269/20607842\">this answer</a> as a guide, I attempted to see whether some modules, such as <code>math</code> were imported.</p>\n<p>But Python tells me they are all imported when they are not.</p>\n<pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt; 'math' in sys.modules\nTrue\n&gt;&gt;&gt; 'math' not in sys.modules\nFalse\n&gt;&gt;&gt; math.pi\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nNameError: name 'math' is not defined\n&gt;&gt;&gt; import math\n&gt;&gt;&gt; 'math' in sys.modules\nTrue\n&gt;&gt;&gt; math.pi\n3.141592653589793\n</code></pre>\n", "AcceptedAnswerId": 74583684, "AcceptedAnswer": "<p>to explain this, let's define this function:</p>\n<pre class=\"lang-py prettyprint-override\"><code>def import_math():\n    import math\n\nimport_math()\n</code></pre>\n<p>the above function will import the module math, but only in its local scope, anyone that tries to reference <code>math</code> outside of it will get a name error, because <code>math</code> is not defined in the global scope.</p>\n<p>any module that is imported is saved into sys.modules so a call to check</p>\n<pre class=\"lang-py prettyprint-override\"><code>import_math()\nprint(&quot;math&quot; in sys.modules)\n</code></pre>\n<p>will print True, because sys.modules caches any module that is loaded anywhere, whether or not it was available in the global scope, a very simple way to define <code>math</code> in the global scope would then to</p>\n<pre class=\"lang-py prettyprint-override\"><code>import_math()\nmath = sys.modules[&quot;math&quot;]\n</code></pre>\n<p>which will convert it from being only in <code>sys.modules</code> to being in the global scope, this is just equivalent to</p>\n<pre class=\"lang-py prettyprint-override\"><code>import math\n</code></pre>\n<p>which defines a variable <code>math</code> in the global scope that points to the module <code>math</code>.</p>\n<p>now if you want to see whether &quot;math&quot; exists in the global scope is to check if it is in the global scope directly.</p>\n<pre class=\"lang-py prettyprint-override\"><code>print(&quot;math&quot; in globals())\nprint(&quot;math&quot; in locals())\n</code></pre>\n<p>which will print false if &quot;math&quot; wasn't imported into the global or local scope and is therefore inaccessable.</p>\n"}
{"Id": 74798626, "PostTypeId": 1, "Title": "Why is log(inf + inf j) equal to (inf + 0.785398 j), In C++/Python/NumPy?", "Body": "<p>I've been finding a strange behaviour of <code>log</code> functions in C++ and numpy about the behaviour of <code>log</code> function handling complex infinite numbers. Specifically, <code>log(inf + inf * 1j)</code> equals <code>(inf + 0.785398j)</code> when I expect it to be <code>(inf + nan * 1j)</code>.</p>\n<p>When taking the log of a complex number, the real part is the log of the absolute value of the input and the imaginary part is the phase of the input. Returning 0.785398 as the imaginary part of <code>log(inf + inf * 1j)</code> means it assumes the <code>inf</code>s in the real and the imaginary part have the same length.\nThis assumption does not seem to be consistent with other calculation, for example, <code>inf - inf == nan</code>, <code>inf / inf == nan</code> which assumes 2 <code>inf</code>s do not necessarily have the same values.</p>\n<p>Why is the assumption for <code>log(inf + inf * 1j)</code> different?</p>\n<p>Reproducing C++ code:</p>\n<pre><code>#include &lt;complex&gt;\n#include &lt;limits&gt;\n#include &lt;iostream&gt;\nint main() {\n    double inf = std::numeric_limits&lt;double&gt;::infinity();\n    std::complex&lt;double&gt; b(inf, inf);\n    std::complex&lt;double&gt; c = std::log(b);\n    std::cout &lt;&lt; c &lt;&lt; &quot;\\n&quot;;\n}\n</code></pre>\n<p>Reproducing Python code (numpy):</p>\n<pre><code>import numpy as np\n\na = complex(float('inf'), float('inf'))\nprint(np.log(a))\n</code></pre>\n<p>EDIT: Thank you for everyone who's involved in the discussion about the historical reason and the mathematical reason. All of you turn this naive question into a really interesting discussion. The provided answers are all of high quality and I wish I can accept more than 1 answers. However, I've decided to accept @simon's answer as it explains in more detail the mathematical reason and provided a link to the document explaining the logic (although I can't fully understand it).</p>\n", "AcceptedAnswerId": 74799453, "AcceptedAnswer": "<p>The value of 0.785398 (actually pi/4) is consistent with at least <em>some</em> other functions: as you said, the imaginary part of the logarithm of a complex number is identical with the phase angle of the number. This can be reformulated to a question of its own: what is the phase angle of <code>inf + j * inf</code>?</p>\n<p>We can calculate the phase angle of a complex number <code>z</code> by <code>atan2(Im(z), Re(z))</code>. With the given number, this boils down to calculating <code>atan2(inf, inf)</code>, which is also 0.785398 (or pi/4), both for Numpy and C/C++. So now a similar question could be asked: why is <code>atan2(inf, inf) == 0.785398</code>?</p>\n<p>I do not have an answer to the latter (except for &quot;the C/C++ specifications say so&quot;, as others already answered), I only have a guess: as <code>atan2(y, x) == atan(y / x)</code> for <code>x &gt; 0</code>, probably someone made the decision in this context to not interpret <code>inf / inf</code> as &quot;undefined&quot; but instead as &quot;a very large number divided by the same very large number&quot;. The result of this ratio would be 1, and <code>atan(1) == pi/4</code> by the mathematical definition of <code>atan</code>.</p>\n<p>Probably this is not a satisfying answer, but at least I could hopefully show that the <code>log</code> definition in the given edge case is not completely inconsistent with similar edge cases of related function definitions.</p>\n<p><strong>Edit</strong>: As I said, consistent with <em>some</em> other functions: it is also consistent with <code>np.angle(complex(np.inf, np.inf)) == 0.785398</code>, for example.</p>\n<p><strong>Edit 2</strong>: Looking at the <a href=\"https://opensource.apple.com/source/Libm/Libm-93/ppc.subproj/atan2.c.auto.html\" rel=\"noreferrer\">source code of an actual <code>atan2</code> implementation</a> brought up the following code comment:</p>\n<blockquote>\n<p>note that the non obvious cases are y and x both infinite or both zero. for more information, see <em>Branch Cuts for Complex Elementary Functions, or Much Ado About Nothing's Sign Bit</em>, by W. Kahan</p>\n</blockquote>\n<p>I dug up the referenced document, you can find a copy <a href=\"https://people.freebsd.org/%7Edas/kahan86branch.pdf\" rel=\"noreferrer\">here</a>. In Chapter 8 of this reference, called &quot;Complex zeros and infinities&quot;, <a href=\"https://en.wikipedia.org/wiki/William_Kahan\" rel=\"noreferrer\">William Kahan</a> (who is both mathematician and computer scientist and, according to Wikipedia, the &quot;Father of Floating Point&quot;) covers the zero and infinity edge cases of complex numbers and arrives at pi/4 for feeding <code>inf + j * inf</code> into the <code>arg</code> function (<code>arg</code> being the function that calculates the phase angle of a complex number, just like <code>np.angle</code> above). You will find this result on page 17 in the linked PDF. I am not mathematician enough for being able to summarize Kahan's rationale (which is to say: I don't really understand it), but maybe someone else can.</p>\n"}
{"Id": 73902642, "PostTypeId": 1, "Title": "Office 365 IMAP authentication via OAuth2 and python MSAL library", "Body": "<p>I'm trying to upgrade a legacy mail bot to authenticate via Oauth2 instead of Basic authentication, as it's <a href=\"https://learn.microsoft.com/en-us/exchange/clients-and-mobile-in-exchange-online/deprecation-of-basic-authentication-exchange-online\" rel=\"noreferrer\">now deprecated two days from now</a>.</p>\n<p>The document states applications can retain their original logic, while swapping out only the authentication bit</p>\n<blockquote>\n<p>Application developers who have built apps that send, read, or\notherwise process email using these protocols will be able to keep the\nsame protocol, but need to implement secure, Modern authentication\nexperiences for their users. This functionality is built on top of\nMicrosoft Identity platform v2.0 and supports access to Microsoft 365\nemail accounts.</p>\n</blockquote>\n<p>Note I've explicitly chosen the <a href=\"https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow\" rel=\"noreferrer\">client credentials flow</a>, because the documentation states</p>\n<blockquote>\n<p>This type of grant is commonly used for server-to-server interactions\nthat must run in the background, without immediate interaction with a\nuser.</p>\n</blockquote>\n<p>So I've got a python script that retrieves an Access Token using the <a href=\"https://github.com/AzureAD/microsoft-authentication-library-for-python\" rel=\"noreferrer\">MSAL python library</a>. Now I'm trying to authenticate with the IMAP server, using that Access Token. There's some existing threads out there showing how to connect to Google, I imagine my case is pretty close to <a href=\"https://stackoverflow.com/q/5193707/680920\">this one</a>, except I'm connecting to a Office 365 IMAP server. Here's my script</p>\n<pre class=\"lang-py prettyprint-override\"><code>import imaplib\nimport msal\nimport logging\n\napp = msal.ConfidentialClientApplication(\n    'client-id',\n    authority='https://login.microsoftonline.com/tenant-id',\n    client_credential='secret-key'\n)\n\nresult = app.acquire_token_for_client(scopes=['https://graph.microsoft.com/.default'])\n\ndef generate_auth_string(user, token):\n  return 'user=%s\\1auth=Bearer %s\\1\\1' % (user, token)\n\n# IMAP time!\nmailserver = 'outlook.office365.com'\nimapport = 993\nM = imaplib.IMAP4_SSL(mailserver,imapport)\nM.debug = 4\nM.authenticate('XOAUTH2', lambda x: generate_auth_string('user@mydomain.com', result['access_token']))\n\nprint(result)\n</code></pre>\n<p>The IMAP authentication is failing and despite setting <code>M.debug = 4</code>, the output isn't very helpful</p>\n<pre><code>  22:56.53 &gt; b'DBDH1 AUTHENTICATE XOAUTH2'\n  22:56.53 &lt; b'+ '\n  22:56.53 write literal size 2048\n  22:57.84 &lt; b'DBDH1 NO AUTHENTICATE failed.'\n  22:57.84 NO response: b'AUTHENTICATE failed.'\nTraceback (most recent call last):\n  File &quot;/home/ubuntu/mini-oauth.py&quot;, line 21, in &lt;module&gt;\n    M.authenticate(&quot;XOAUTH2&quot;, lambda x: generate_auth_string('user@mydomain.com', result['access_token']))\n  File &quot;/usr/lib/python3.10/imaplib.py&quot;, line 444, in authenticate\n    raise self.error(dat[-1].decode('utf-8', 'replace'))\nimaplib.IMAP4.error: AUTHENTICATE failed.\n</code></pre>\n<p>Any idea where I might be going wrong, or how to get more robust information from the IMAP server about why the authentication is failing?</p>\n<p><strong>Things I've looked at</strong></p>\n<ul>\n<li><p>Note <a href=\"https://stackoverflow.com/a/60773366/680920\">this answer</a> no longer works as the suggested scopes fail to generate an Access Token.</p>\n</li>\n<li><p>The client credentials flow seems to <a href=\"https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow#first-case-access-token-request-with-a-shared-secret\" rel=\"noreferrer\">mandate the <code>https://graph.microsoft.com/.default</code> grant</a>. I'm not sure if that includes the <a href=\"https://learn.microsoft.com/en-us/exchange/client-developer/legacy-protocols/how-to-authenticate-an-imap-pop-smtp-application-by-using-oauth#get-an-access-token\" rel=\"noreferrer\">scope required for the IMAP resource</a>\n<code>https://outlook.office.com/IMAP.AccessAsUser.All</code>?</p>\n</li>\n<li><p>Verified the code lifted from the Google thread produces the SASL XOAUTH2 string correctly, per <a href=\"https://learn.microsoft.com/en-us/exchange/client-developer/legacy-protocols/how-to-authenticate-an-imap-pop-smtp-application-by-using-oauth#sasl-xoauth2\" rel=\"noreferrer\">example on the MS docs</a></p>\n</li>\n</ul>\n<pre><code>import base64\n\nuser = 'test@contoso.onmicrosoft.com'\ntoken = 'EwBAAl3BAAUFFpUAo7J3Ve0bjLBWZWCclRC3EoAA'\n\nxoauth = &quot;user=%s\\1auth=Bearer %s\\1\\1&quot; % (user, token)\n\nxoauth = xoauth.encode('ascii')\nxoauth = base64.b64encode(xoauth)\nxoauth = xoauth.decode('ascii')\n\nxsanity = 'dXNlcj10ZXN0QGNvbnRvc28ub25taWNyb3NvZnQuY29tAWF1dGg9QmVhcmVyIEV3QkFBbDNCQUFVRkZwVUFvN0ozVmUwYmpMQldaV0NjbFJDM0VvQUEBAQ=='\n\nprint(xoauth == xsanity) # prints True\n</code></pre>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/61597263/office-365-xoauth2-for-imap-and-smtp-authentication-fails\">This thread</a> seems to suggest multiple tokens need to be fetched, one for graph, then another for the IMAP connection; could that be what I'm missing?</li>\n</ul>\n", "AcceptedAnswerId": 74131277, "AcceptedAnswer": "<p>The <code>imaplib.IMAP4.error: AUTHENTICATE failed</code> Error occured because one point in the documentation is not that clear.</p>\n<p>When setting up the the Service Principal via Powershell you need to enter the App-ID and an Object-ID. Many people will think, it is the Object-ID you see on the overview page of the registered App, but its not!\nAt this point you need the Object-ID from <strong>&quot;Azure Active Directory -&gt; Enterprise Applications --&gt; Your-App --&gt; Object-ID&quot;</strong></p>\n<pre><code>New-ServicePrincipal -AppId &lt;APPLICATION_ID&gt; -ServiceId &lt;OBJECT_ID&gt; [-Organization &lt;ORGANIZATION_ID&gt;]\n</code></pre>\n<p>Microsoft says:</p>\n<blockquote>\n<p>The OBJECT_ID is the Object ID from the Overview page of the\nEnterprise Application node (Azure Portal) for the application\nregistration. It is not the Object ID from the Overview of the App\nRegistrations node. Using the incorrect Object ID will cause an\nauthentication failure.</p>\n</blockquote>\n<p>Ofcourse you need to take care for the API-permissions and the other stuff, but this was for me the point.\nSo lets go trough it again, like it is explained on the documentation page.\n<a href=\"https://learn.microsoft.com/en-us/exchange/client-developer/legacy-protocols/how-to-authenticate-an-imap-pop-smtp-application-by-using-oauth\" rel=\"noreferrer\">Authenticate an IMAP, POP or SMTP connection using OAuth</a></p>\n<ol>\n<li>Register the Application in your Tenant</li>\n<li>Setup a Client-Key for the application</li>\n<li>Setup the API permissions, select the APIs my organization uses tab and search for &quot;Office 365 Exchange Online&quot; -&gt; Application permissions -&gt; Choose IMAP and IMAP.AccessAsApp</li>\n<li>Setup the Service Principal and full access for your Application on the mailbox</li>\n<li>Check if IMAP is activated for the mailbox</li>\n</ol>\n<p>Thats the code I use to test it:</p>\n<pre><code>import imaplib\nimport msal\nimport pprint\n\nconf = {\n    &quot;authority&quot;: &quot;https://login.microsoftonline.com/XXXXyourtenantIDXXXXX&quot;,\n    &quot;client_id&quot;: &quot;XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXX&quot;, #AppID\n    &quot;scope&quot;: ['https://outlook.office365.com/.default'],\n    &quot;secret&quot;: &quot;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;, #Key-Value\n    &quot;secret-id&quot;: &quot;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;, #Key-ID\n}\n    \ndef generate_auth_string(user, token):\n    return f&quot;user={user}\\x01auth=Bearer {token}\\x01\\x01&quot;    \n\nif __name__ == &quot;__main__&quot;:\n    app = msal.ConfidentialClientApplication(conf['client_id'], authority=conf['authority'],\n                                             client_credential=conf['secret'])\n\n    result = app.acquire_token_silent(conf['scope'], account=None)\n\n    if not result:\n        print(&quot;No suitable token in cache.  Get new one.&quot;)\n        result = app.acquire_token_for_client(scopes=conf['scope'])\n\n    if &quot;access_token&quot; in result:\n        print(result['token_type'])\n        pprint.pprint(result)\n    else:\n        print(result.get(&quot;error&quot;))\n        print(result.get(&quot;error_description&quot;))\n        print(result.get(&quot;correlation_id&quot;))\n        \n    imap = imaplib.IMAP4('outlook.office365.com')\n    imap.starttls()\n    imap.authenticate(&quot;XOAUTH2&quot;, lambda x: generate_auth_string(&quot;target_mailbox@example.com&quot;, result['access_token']).encode(&quot;utf-8&quot;))\n</code></pre>\n<p>After setting up the Service Principal and giving the App full access on the mailbox, wait 15 - 30 minutes for the changes to take effect and test it.</p>\n"}
{"Id": 74206978, "PostTypeId": 1, "Title": "Why does this specific code run faster in Python 3.11?", "Body": "<p>I have the following code in a Python file called <code>benchmark.py</code>.</p>\n<pre><code>source = &quot;&quot;&quot;\nfor i in range(1000):\n    a = len(str(i)) \n&quot;&quot;&quot;\n\nimport timeit\n\nprint(timeit.timeit(stmt=source, number=100000))\n</code></pre>\n<p>When I tried to run with multiple python versions I am seeing a drastic performance difference.</p>\n<pre><code>C:\\Users\\Username\\Desktop&gt;py -3.10 benchmark.py\n16.79652149998583\n\nC:\\Users\\Username\\Desktop&gt;py -3.11 benchmark.py\n10.92280820000451\n</code></pre>\n<p>As you can see this code runs faster with python 3.11 than previous Python versions. I tried to disassemble the bytecode to understand the reason for this behaviour but I could only see a difference in opcode names (<code>CALL_FUNCTION</code> is replaced by <code>PRECALL</code> and <code>CALL</code> opcodes).</p>\n<p>I am quite not sure if that's the reason for this performance change. so I am looking for an answer that <strong>justifies with reference to cpython\nsource code</strong>.</p>\n<p><strong><code>python 3.11</code> bytecode</strong></p>\n<pre><code>  0           0 RESUME                   0\n\n  2           2 PUSH_NULL\n              4 LOAD_NAME                0 (range)\n              6 LOAD_CONST               0 (1000)\n              8 PRECALL                  1\n             12 CALL                     1\n             22 GET_ITER\n        &gt;&gt;   24 FOR_ITER                22 (to 70)\n             26 STORE_NAME               1 (i)\n\n  3          28 PUSH_NULL\n             30 LOAD_NAME                2 (len)\n             32 PUSH_NULL\n             34 LOAD_NAME                3 (str)\n             36 LOAD_NAME                1 (i)\n             38 PRECALL                  1\n             42 CALL                     1\n             52 PRECALL                  1\n             56 CALL                     1\n             66 STORE_NAME               4 (a)\n             68 JUMP_BACKWARD           23 (to 24)\n\n  2     &gt;&gt;   70 LOAD_CONST               1 (None)\n             72 RETURN_VALUE\n</code></pre>\n<p><strong><code>python 3.10</code> bytecode</strong></p>\n<pre><code>  2           0 LOAD_NAME                0 (range)\n              2 LOAD_CONST               0 (1000)\n              4 CALL_FUNCTION            1\n              6 GET_ITER\n        &gt;&gt;    8 FOR_ITER                 8 (to 26)\n             10 STORE_NAME               1 (i)\n\n  3          12 LOAD_NAME                2 (len)\n             14 LOAD_NAME                3 (str)\n             16 LOAD_NAME                1 (i)\n             18 CALL_FUNCTION            1\n             20 CALL_FUNCTION            1\n             22 STORE_NAME               4 (a)\n             24 JUMP_ABSOLUTE            4 (to 8)\n\n  2     &gt;&gt;   26 LOAD_CONST               1 (None)\n             28 RETURN_VALUE\n</code></pre>\n<p>PS: I understand that <em>python 3.11</em> introduced bunch of performance improvements but I am curios to understand what optimization makes this code run faster in python 3.11</p>\n", "AcceptedAnswerId": 74220032, "AcceptedAnswer": "<p>There's a big section in the <a href=\"https://docs.python.org/3.11/whatsnew/3.11.html\" rel=\"noreferrer\">&quot;what's new&quot;</a> page labeled <a href=\"https://docs.python.org/3.11/whatsnew/3.11.html#faster-cpython\" rel=\"noreferrer\">&quot;faster runtime&quot;</a>. It looks like the most likely cause of the speedup here is <a href=\"https://docs.python.org/3.11/whatsnew/3.11.html#pep-659-specializing-adaptive-interpreter\" rel=\"noreferrer\">PEP 659</a>, which is a first start towards JIT optimization (perhaps not quite JIT <em>compilation</em>, but definitely JIT <em>optimization</em>).</p>\n<p>Particularly, the lookup and call for <code>len</code> and <code>str</code> now bypass a lot of dynamic machinery in the overwhelmingly common case where the built-ins aren't shadowed or overridden. The global and builtin dict lookups to resolve the name get skipped in a fast path, and the underlying C routines for <code>len</code> and <code>str</code> are called directly, instead of going through the general-purpose function call handling.</p>\n<p>You wanted source references, so here's one. The <code>str</code> call will get specialized in <a href=\"https://github.com/python/cpython/blob/v3.11.0/Python/specialize.c#L1356\" rel=\"noreferrer\"><code>specialize_class_call</code></a>:</p>\n<pre><code>    if (tp-&gt;tp_flags &amp; Py_TPFLAGS_IMMUTABLETYPE) {\n        if (nargs == 1 &amp;&amp; kwnames == NULL &amp;&amp; oparg == 1) {\n            if (tp == &amp;PyUnicode_Type) {\n                _Py_SET_OPCODE(*instr, PRECALL_NO_KW_STR_1);\n                return 0;\n            }\n</code></pre>\n<p>where it detects that the call is a call to the <code>str</code> builtin with 1 positional argument and no keywords, and replaces the corresponding <code>PRECALL</code> opcode with <code>PRECALL_NO_KW_STR_1</code>. The handling for the <code>PRECALL_NO_KW_STR_1</code> opcode in the bytecode evaluation loop looks like <a href=\"https://github.com/python/cpython/blob/v3.11.0/Python/ceval.c#L4931\" rel=\"noreferrer\">this</a>:</p>\n<pre><code>        TARGET(PRECALL_NO_KW_STR_1) {\n            assert(call_shape.kwnames == NULL);\n            assert(cframe.use_tracing == 0);\n            assert(oparg == 1);\n            DEOPT_IF(is_method(stack_pointer, 1), PRECALL);\n            PyObject *callable = PEEK(2);\n            DEOPT_IF(callable != (PyObject *)&amp;PyUnicode_Type, PRECALL);\n            STAT_INC(PRECALL, hit);\n            SKIP_CALL();\n            PyObject *arg = TOP();\n            PyObject *res = PyObject_Str(arg);\n            Py_DECREF(arg);\n            Py_DECREF(&amp;PyUnicode_Type);\n            STACK_SHRINK(2);\n            SET_TOP(res);\n            if (res == NULL) {\n                goto error;\n            }\n            CHECK_EVAL_BREAKER();\n            DISPATCH();\n        }\n</code></pre>\n<p>which consists mostly of a bunch of safety prechecks and reference fiddling wrapped around a call to <code>PyObject_Str</code>, the C routine for calling <code>str</code> on an object.</p>\n<p>Python 3.11 includes many other performance enhancements besides the above, including optimizations to stack frame creation, method lookup, common arithmetic operations, interpreter startup, and more. Most code should run much faster now, barring things like I/O-bound workloads and code that spent most of its time in C library code (like NumPy).</p>\n"}
{"Id": 74307236, "PostTypeId": 1, "Title": "Python: Why do functools.partial functions not become bound methods when set as class attributes?", "Body": "<p>I was reading about how <a href=\"https://stackoverflow.com/questions/35321744/python-function-as-class-attribute-becomes-a-bound-method\">functions become bound methods when being set as class atrributes</a>. I then observed that this is not the case for functions that are wrapped by <code>functools.partial</code>. What is the explanation for this?</p>\n<p>Simple example:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from functools import partial\n\ndef func1():\n    print(&quot;foo&quot;)\n\nfunc1_partial = partial(func1)\n\nclass A:\n    f = func1\n    g = func1_partial\n\na = A()\n\n\na.f() # TypeError: func1() takes 0 positional arguments but 1 was given\n\na.g() # prints &quot;foo&quot;\n\n</code></pre>\n<p>I kind of expected them both to behave in the same way.</p>\n", "AcceptedAnswerId": 74307329, "AcceptedAnswer": "<p>The trick that allows functions to become bound methods is the <a href=\"https://docs.python.org/3/howto/descriptor.html\" rel=\"noreferrer\"><code>__get__</code> magic method</a>.</p>\n<p>To <em>very</em> briefly summarize that page, when you access a field on an instance, say <code>foo.bar</code>, Python first checks whether <code>bar</code> exists in <code>foo</code>'s <code>__dict__</code> (or <code>__slots__</code>, if it has one). If it does, we return it, no harm done. If not, then we look on <code>type(foo)</code>. <em>However,</em> when we access the field <code>Foo.bar</code> on the <em>class</em> <code>Foo</code> through an instance, something magical happens. When we write <code>foo.bar</code>, assuming there is no <code>bar</code> on <code>foo</code>'s <code>__dict__</code> (resp. <code>__slots__</code>), then we actually call <code>Foo.bar.__get__(foo, Foo)</code>. That is, Python calls a magic method asking the object how it would like to be retrieved.</p>\n<p>This is how <a href=\"https://docs.python.org/3/library/functions.html#property\" rel=\"noreferrer\">properties</a> are implemented, and it's also how bound methods are implemented. Somewhere deep down (probably written in C), there's a <code>__get__</code> function on the <em>type</em> <code>function</code> that binds the method when accessed through an instance.</p>\n<p><code>functools.partial</code>, despite looking a lot like a function, is not an instance of the type <code>function</code>. It's just a random class that happens to implement <code>__call__</code>, and it doesn't implement <code>__get__</code>. Why doesn't it? Well, they probably just didn't think it was worth it, or it's possible nobody even considered it. Regardless, the &quot;bound method&quot; trick applies to the type called <code>function</code>, not to all callable objects.</p>\n<hr />\n<p>Another useful resource on magic methods, and <code>__get__</code> in particular: <a href=\"https://rszalski.github.io/magicmethods/#descriptor\" rel=\"noreferrer\">https://rszalski.github.io/magicmethods/#descriptor</a></p>\n"}
{"Id": 74500614, "PostTypeId": 1, "Title": "Python Decimal - multiplication by zero", "Body": "<p>Why does the following code:</p>\n<pre><code>from decimal import Decimal\nresult = Decimal('0') * Decimal('0.8881783462119193534061639577')\nprint(result)\n</code></pre>\n<p>return <strong>0E-28</strong> ?</p>\n<p>I've traced it to the following code in the <a href=\"https://github.com/python/cpython/edit/main/Lib/_pydecimal.py\" rel=\"noreferrer\">module</a>:</p>\n<pre><code>if not self or not other:\n    ans = _dec_from_triple(resultsign, '0', resultexp)\n    # Fixing in case the exponent is out of bounds\n    ans = ans._fix(context)\n    return ans\n</code></pre>\n<p>The code appears to follow <a href=\"https://speleotrove.com/decimal/daops.html#refmult\" rel=\"noreferrer\">Decimal Arithmetic Specification</a>, which doesn't explicitly suggest what to do when we multiply by zero, referring to 'special numbers' from <a href=\"https://ieeexplore.ieee.org/document/27840\" rel=\"noreferrer\">another standard</a>, which also doesn't specify what we do when we multiply an integer by zero  :)\nSo the <strong>decimal</strong> library does the thing that <em><strong>is</strong></em> explicitly specified:</p>\n<ul>\n<li>The coefficient of the result, before rounding, is computed by multiplying together the coefficients of the operands.</li>\n<li>The exponent of the result, before rounding, is the sum of the exponents of the two operands.</li>\n<li>The sign of the result is the exclusive or of the signs of the operands.</li>\n</ul>\n<p><strong>Question:</strong> what is the need to return the coefficient and exponent (i.e, 0E-28) if one of the operands is a zero? We already know what that coefficient is when calling the multiplication function. Why not just return zero?</p>\n", "AcceptedAnswerId": 74515870, "AcceptedAnswer": "<p><a href=\"https://github.com/rhettinger\" rel=\"nofollow noreferrer\">Raymond Hettinger</a> has given a comprehensive explanation at <a href=\"https://github.com/python/cpython/pull/99604\" rel=\"nofollow noreferrer\">cpython github</a>:</p>\n<p>In <a href=\"https://speleotrove.com/decimal/daops.html\" rel=\"nofollow noreferrer\">Arithmetic Operations</a>, the section on Arithmetic operations rules tells us:</p>\n<blockquote>\n<p>Trailing zeros are not removed after operations.</p>\n</blockquote>\n<p>There are test cases covering multiplication by zero. Here are some from multiply.decTest:</p>\n<pre><code>-- zeros, etc.\nmulx021 multiply  0      0     -&gt;  0\nmulx022 multiply  0     -0     -&gt; -0\nmulx023 multiply -0      0     -&gt; -0\nmulx024 multiply -0     -0     -&gt;  0\nmulx025 multiply -0.0   -0.0   -&gt;  0.00\nmulx026 multiply -0.0   -0.0   -&gt;  0.00\nmulx027 multiply -0.0   -0.0   -&gt;  0.00\nmulx028 multiply -0.0   -0.0   -&gt;  0.00\nmulx030 multiply  5.00   1E-3  -&gt;  0.00500\nmulx031 multiply  00.00  0.000 -&gt;  0.00000\nmulx032 multiply  00.00  0E-3  -&gt;  0.00000     -- rhs is 0\nmulx033 multiply  0E-3   00.00 -&gt;  0.00000     -- lhs is 0\nmulx034 multiply -5.00   1E-3  -&gt; -0.00500\nmulx035 multiply -00.00  0.000 -&gt; -0.00000\nmulx036 multiply -00.00  0E-3  -&gt; -0.00000     -- rhs is 0\nmulx037 multiply -0E-3   00.00 -&gt; -0.00000     -- lhs is 0\nmulx038 multiply  5.00  -1E-3  -&gt; -0.00500\nmulx039 multiply  00.00 -0.000 -&gt; -0.00000\nmulx040 multiply  00.00 -0E-3  -&gt; -0.00000     -- rhs is 0\nmulx041 multiply  0E-3  -00.00 -&gt; -0.00000     -- lhs is 0\nmulx042 multiply -5.00  -1E-3  -&gt;  0.00500\nmulx043 multiply -00.00 -0.000 -&gt;  0.00000\nmulx044 multiply -00.00 -0E-3  -&gt;  0.00000     -- rhs is 0\nmulx045 multiply -0E-3  -00.00 -&gt;  0.00000     -- lhs is 0\n</code></pre>\n<p>And this from the examples:</p>\n<pre><code>mulx053 multiply 0.9 -0 -&gt; -0.0\n</code></pre>\n<p>In the Summary of Arithmetic section, the motivation is explained at a high level:</p>\n<blockquote>\n<p>The arithmetic was designed as a decimal extended floating-point arithmetic, directly implementing the rules that people are taught at\nschool. Up to a given working precision, exact unrounded results are\ngiven when possible (for instance, 0.9 \u00f7 10 gives 0.09, not\n0.089999996), and trailing zeros are correctly preserved in most operations (1.23 + 1.27 gives 2.50, not 2.5). Where results would\nexceed the working precision, floating-point rules apply.</p>\n</blockquote>\n<p>More detail in given in the FAQ section <a href=\"https://speleotrove.com/decimal/decifaq1.html#tzeros\" rel=\"nofollow noreferrer\">Why are trailing fractional zeros important?</a>.</p>\n"}
{"Id": 71248521, "PostTypeId": 1, "Title": "Why \" NumExpr defaulting to 8 threads. \" warning message shown in python?", "Body": "<p>I am trying to use the lux library in python to get visualization recommendations. It shows warnings like <strong>NumExpr defaulting to 8 threads.</strong>.</p>\n<pre><code>import pandas as pd\nimport numpy as np\nimport opendatasets as od\npip install lux-api\nimport lux\nimport matplotlib\n</code></pre>\n<p>And then:</p>\n<pre><code>link = &quot;https://www.kaggle.com/noordeen/insurance-premium-prediction&quot;\nod.download(link) \ndf = pd.read_csv(&quot;./insurance-premium-prediction/insurance.csv&quot;)\n</code></pre>\n<p>But, everything is working fine. Is there any problem or should I ignore it?\nWarning shows like this:\n<a href=\"https://i.stack.imgur.com/UAKDS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/UAKDS.png\" alt=\"enter image description here\" /></a></p>\n", "AcceptedAnswerId": 74656206, "AcceptedAnswer": "<p>This is not really something to worry about in most cases. The warning comes from <a href=\"https://github.com/pydata/numexpr/blob/b68de57bfed90684b3ea79060c3a7953b9629429/numexpr/utils.py#L119-L164\" rel=\"nofollow noreferrer\">this function</a>, here the most important part:</p>\n<pre class=\"lang-py prettyprint-override\"><code>...\n    env_configured = False\n    n_cores = detect_number_of_cores()\n    if 'NUMEXPR_MAX_THREADS' in os.environ:\n        # The user has configured NumExpr in the expected way, so suppress logs.\n        env_configured = True\n        n_cores = MAX_THREADS\n...\n    if 'NUMEXPR_NUM_THREADS' in os.environ:\n        requested_threads = int(os.environ['NUMEXPR_NUM_THREADS'])\n    elif 'OMP_NUM_THREADS' in os.environ:\n        requested_threads = int(os.environ['OMP_NUM_THREADS'])\n    else:\n        requested_threads = n_cores\n        if not env_configured:\n            log.info('NumExpr defaulting to %d threads.'%n_cores)\n</code></pre>\n<p>So if neither <code>NUMEXPR_MAX_THREADS</code> nor <code>NUMEXPR_NUM_THREADS</code> nor <code>OMP_NUM_THREADS</code> are set, NumExpr uses so many threads as there are cores (even if <a href=\"https://numexpr.readthedocs.io/projects/NumExpr3/en/latest/user_guide.html#threadpool-configuration\" rel=\"nofollow noreferrer\">the documentation says</a> &quot;at most 8&quot;, yet this is not what I see <a href=\"https://github.com/pydata/numexpr/blob/b68de57bfed90684b3ea79060c3a7953b9629429/numexpr/utils.py#L167-L187\" rel=\"nofollow noreferrer\">in the code</a>).</p>\n<p>You might want to use another number of threads, e.g. while really huge matrices are calculated and one could profit from it or to use less threads, because there is no improvement. Set the environment variables either in the shell or prior to importing numexpr, e.g.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nos.environ['NUMEXPR_MAX_THREADS'] = '4'\nos.environ['NUMEXPR_NUM_THREADS'] = '2'\nimport numexpr as ne \n</code></pre>\n"}
{"Id": 74717007, "PostTypeId": 1, "Title": "Why does a python function work in parallel even if it should not?", "Body": "<p>I am running this code using the <em>healpy</em> package. I am not using multiprocessing and I need it to run on a single core. It worked for a certain amount of time, but, when I run it now, the function <code>healpy.projector.GnomonicProj.projmap</code> takes all the available cores.</p>\n<p>This is the incriminated code block:</p>\n<pre><code>def Stacking () :\n\n    f = lambda x,y,z: pixelfunc.vec2pix(xsize,x,y,z,nest=False)\n    map_array = pixelfunc.ma_to_array(data)\n    im = np.zeros((xsize, xsize))\n    plt.figure()\n\n    for i in range (nvoids) :\n        sys.stdout.write(&quot;\\r&quot; + str(i+1) + &quot;/&quot; + str(nvoids))\n        sys.stdout.flush()\n        proj = hp.projector.GnomonicProj(rot=[rav[i],decv[i]], xsize=xsize, reso=2*nRad*rad_deg[i]*60/(xsize))\n        im += proj.projmap(map_array, f)\n\n    im/=nvoids\n    plt.imshow(im)\n    plt.colorbar()\n    plt.title(title + &quot; (Map)&quot;)\n    plt.savefig(&quot;../Plots/stackedMap_&quot;+name+&quot;.png&quot;)\n\n    return im\n</code></pre>\n<p>Does someone know why this function is running in parallel? And most important, does someone know a way to run it in a single core?</p>\n<p>Thank you!</p>\n", "AcceptedAnswerId": 74717228, "AcceptedAnswer": "<p><a href=\"https://github.com/healpy/healpy/issues/558\" rel=\"nofollow noreferrer\">In this thread</a> they recommend to set the environment variable <code>OMP_NUM_THREADS</code> accordingly:</p>\n<blockquote>\n<p>Worked with:</p>\n<pre><code>import os\nos.environ['OMP_NUM_THREADS'] = '1'\nimport healpy as hp\nimport numpy as np\n</code></pre>\n<p><code>os.environ['OMP_NUM_THREADS'] = '1'</code> have to be done before import numpy and healpy libraries.</p>\n</blockquote>\n<p>As to the why: probably they use some parallelization techniques wrapped within their implementation of the functions you use. According to the name of the variable, I would guess <a href=\"https://en.wikipedia.org/wiki/OpenMP\" rel=\"nofollow noreferrer\">OpenMP</a> it is.</p>\n"}
{"Id": 74717893, "PostTypeId": 1, "Title": "How to efficiently search for similar substring in a large text python?", "Body": "<p>Let me try to explain my issue with an example, I have a large corpus and a substring like below,</p>\n<pre><code>corpus = &quot;&quot;&quot;very quick service, polite workers(cory, i think that's his name), i basically just drove there and got a quote(which seems to be very fair priced), then dropped off my car 4 days later(because they were fully booked until then), then i dropped off my car on my appointment day, then the same day the shop called me and notified me that the the job is done i can go pickup my car. when i go checked out my car i was amazed by the job they've done to it, and they even gave that dirty car a wash( prob even waxed it or coated it, cuz it was shiny as hell), tires shine, mats were vacuumed too. i gave them a dirty, broken car, they gave me back a what seems like a brand new car. i'm happy with the result, and i will def have all my car's work done by this place from now.&quot;&quot;&quot;\n\nsubstring = &quot;&quot;&quot;until then then i dropped off my car on my appointment day then the same day the shop called me and notified me that the the job is done i can go pickup my car when i go checked out my car i was amazed by the job they ve done to it and they even gave that dirty car a wash prob even waxed it or coated it cuz it was shiny as hell tires shine mats were vacuumed too i gave them a dirty broken car they gave me back a what seems like a brand new car i m happy with the result and i will def have all my car s work done by this place from now&quot;&quot;&quot;\n</code></pre>\n<p>Both the substring and corpus are very similar but it not exact,</p>\n<p>If I do something like,</p>\n<pre><code>import re\nre.search(substring, corpus, flags=re.I) # this will fail substring is not exact but rather very similar\n</code></pre>\n<p>In the corpus the substring is like below which is bit different from the substring I have because of that regular expression search is failing, can someone suggest a really good alternative for similar substring lookup,</p>\n<pre><code>until then), then i dropped off my car on my appointment day, then the same day the shop called me and notified me that the the job is done i can go pickup my car. when i go checked out my car i was amazed by the job they've done to it, and they even gave that dirty car a wash( prob even waxed it or coated it, cuz it was shiny as hell), tires shine, mats were vacuumed too. i gave them a dirty, broken car, they gave me back a what seems like a brand new car. i'm happy with the result, and i will def have all my car's work done by this place from now\n</code></pre>\n<p>I did try difflib library but it was not satisfying my use-case.</p>\n<p>Some background information,</p>\n<p>The substring I have right now, is obtained some time ago from pre-processed corpus using this regex <code>re.sub(&quot;[^a-zA-Z]&quot;, &quot; &quot;, corpus)</code>.</p>\n<p>But now I need to use that substring I have to do the reverse lookup in the corpus text and find the start and ending index in the corpus.</p>\n", "AcceptedAnswerId": 74719826, "AcceptedAnswer": "<p>You don't actually need to fuzzy match all that much, at least for the example given; text can only change in spaces within <code>substring</code>, and it can only change by adding at least one non-alphabetic character (which can replace a space, but the space can't be deleted without a replacement). This means you can construct a regex directly  from substring with wildcards between words, <code>search</code> (or <code>finditer</code>) the <code>corpus</code> for it, and the resulting match object will tell you where the match(es) begin and end:</p>\n<pre><code>import re\n\n# Allow any character between whitespace-separated &quot;words&quot; except ASCII\n# alphabetic characters\nssre = re.compile(r'[^a-z]+'.join(substring.split()), re.IGNORECASE)\n\nif m := ssre.search(corpus):\n    print(m.start(), m.end())\n\n    print(repr(m.group(0)))\n</code></pre>\n<p><a href=\"https://tio.run/##vVXBatwwEL37K4btYb10YwrtoQRyCCGUXFpojqWFsTy7VlaWVElex/n57ZO9TVJISJtDF9aspZk3b948af2YWmfff/ThoFzwfaQzWiwWewkj/ey12lGUsNdK1uSd0UlocGEnIZYIH9ekKbXa7vDktIzU6kiWO1nlnZqjVmzMSDd9TNQEtxcEShBi29DWJWIUcUnKodWqRSnpIiVHtdDEYMM6kA8o3wARqTajeC8Nuc2GupEUB/pADY@RDCcJZS2K@zjVGWnItTZ9plA7t0Nab5M2E9JvQP0UpLP5F3vvtE2d2JRLHBPwoIge89L80jpPuVFgdHNv1iW90fN7lmaKy98bVxM0apwVVFZsIQN56Nz7Y@2KhpkWNlQrKrN2ffrNTNPAkbjjO6zX4z1o7ncJfSdkSKjTemIy6SB7IG55fyTT6JBmNM5obQmNATFFDXwLYJ3IBVIOkjYTlOrv8mKuHTFwaINhizFZRR1kXoVJOk5xln3Pqu87pCfnqtzOXF46FJ0IrKkOmInNRNYzzykGktUM44FbJjubwugdlEXGpK4Ms1J62VGLKWHSOrWTFuDSm2Pv0EobQ41sEAVkjOgoI6yafTyrNamIoXjDCnYJrsP8hgrHoChiX8cUtN3O5@LBPv9qnv/inddbh/6wzl875yXjPOubx655xjRPeeaRZV7jGEA@Y5gX/EIv@wXuOOjOu5AAWRRv6NwYNwAXAC0HVridcLGlQcA/eqSeRPHYyEotgN7EBcmtEp/o/Pri6grlfcvI0OoBIRYxQqcz1KiU67w2Uobltx98cvf97bK6geXKe89W0ePKLlc4pAi/@vT5y9fLi/Pry1VRaLiVTs8oo1VROKi2nP8AVqcF4YNb16ayq2LiAAic7EpsA6zi0XYQHxCzDa735bvVanU4/AI\" rel=\"nofollow noreferrer\" title=\"Python 3.8 (pre-release) \u2013 Try It Online\">Try it online!</a></p>\n<p>which correctly identifies where the match began (index 217) and ended (index 771) in <code>corpus</code>; <code>.group(0)</code> can directly extract the matching text for you if you prefer (it's uncommon to need the indices, so there's a decent chance you were asking for them solely to extract the real text, and <code>.group(0)</code> does that directly). The output is:</p>\n<pre class=\"lang-none prettyprint-override\"><code>217 771\n&quot;until then), then i dropped off my car on my appointment day, then the same day the shop called me and notified me that the the job is done i can go pickup my car. when i go checked out my car i was amazed by the job they've done to it, and they even gave that dirty car a wash( prob even waxed it or coated it, cuz it was shiny as hell), tires shine, mats were vacuumed too. i gave them a dirty, broken car, they gave me back a what seems like a brand new car. i'm happy with the result, and i will def have all my car's work done by this place from now&quot;\n</code></pre>\n<p>If spaces might be deleted without being replaced, just change the <code>+</code> quantifier to <code>*</code> (the regex will run a little slower since it can't short-circuit as easily, but would still work, and should run fast enough).</p>\n<p>If you need to handle non-ASCII alphabetic characters, the regex joiner can change from <code>r'[^a-z]+'</code> to the equivalent <code>r'[\\W\\d_]+'</code> (which means &quot;match all non-word characters [non-alphanumeric and not underscore], plus numeric characters and underscores&quot;); it's a little more awkward to read, but it handles stuff like <code>\u00e9</code> properly (treating it as part of a word, not a connector character).</p>\n<p>While it's not going to be as flexible as <code>difflib</code>, when you know no words are removed or added, it's just a matter of spacing and punctuation, this works perfectly, and should run significantly faster than a true fuzzy matching solution (that has to do far more work to handle the concept of close matches).</p>\n"}
{"Id": 74948525, "PostTypeId": 1, "Title": "FutureWarning: save is not part of the public API in Python", "Body": "<p>I am using Python to convert Pandas df to .xlsx (in Plotly-Dash app.). All working well so far but with this warning tho:</p>\n<p><strong>&quot;FutureWarning:\nsave is not part of the public API, usage can give unexpected results and will be removed in a future version&quot;</strong></p>\n<p>How should I modify the code below in order to keep its functionality and stability in future? Thanks!</p>\n<pre><code> writer = pd.ExcelWriter(&quot;File.xlsx&quot;, engine = &quot;xlsxwriter&quot;)\n\n workbook  = writer.book\n\n df.to_excel(writer, sheet_name = 'Sheet', index = False)\n  \n writer.save()\n</code></pre>\n", "AcceptedAnswerId": 74948596, "AcceptedAnswer": "<p>just replace save with close.</p>\n<pre><code> writer = pd.ExcelWriter(&quot;File.xlsx&quot;, engine = &quot;xlsxwriter&quot;)\n\n workbook  = writer.book\n\n df.to_excel(writer, sheet_name = 'Sheet', index = False)\n  \n writer.close()\n</code></pre>\n"}
